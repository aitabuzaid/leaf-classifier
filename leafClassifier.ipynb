{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Nanodegree Capstone Project \n",
    "## Leaf Classification - Kaggle Competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all images to the images folder\n",
    "\n",
    "#import zipfile\n",
    "#zipp = zipfile.ZipFile('images/images.zip')\n",
    "#zipp.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting with:\n",
    "#### - Loading Python packages\n",
    "#### - Loading tabular and image data,\n",
    "#### - Data preprocessing\n",
    "#### - Splitting training data into training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular data:\n",
      "Model training tabular features - shape:  (792, 192)\n",
      "Model validation tabular features - shape:  (198, 192)\n",
      "Model training tabular label - shape:  (792,)\n",
      "Model validation tabular label - shape:  (198,)\n",
      "Source training tabular features - shape:  (990, 192)\n",
      "Source training tabular features - shape:  (990, 192)\n",
      "Source testing tabular features - shape:  (594, 192)\n",
      "\n",
      "Image data:\n",
      "Model training image data shape:  (792, 256, 256, 1)\n",
      "Model validation image data shape:  (198, 256, 256, 1)\n",
      "Source testing image data shape:  (594, 256, 256, 1)\n",
      "Source training image data shape:  (990, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# import all required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# setting random_state reduce result randomness\n",
    "random_state = 123\n",
    "\n",
    "# Loading source tabular data for training and testing\n",
    "df_train = pd.read_csv('train.csv',index_col= 'id')\n",
    "X_test_org = pd.read_csv('test.csv',index_col = 'id')\n",
    "\n",
    "# Defining training features and labels\n",
    "y_train = df_train[\"species\"]\n",
    "X_train_org = df_train.drop([\"species\"],axis = 1)\n",
    "\n",
    "# Preprocessing training and testing data \n",
    "X_train = pd.DataFrame(MinMaxScaler().fit(X_train_org).transform(X_train_org),index=X_train_org.index,columns=X_train_org.columns)\n",
    "X_test = pd.DataFrame(MinMaxScaler().fit(X_test_org).transform(X_test_org),index=X_test_org.index,columns=X_test_org.columns)\n",
    "\n",
    "\n",
    "# Splitting the provided training data into training and validation in order to assess the proposed models \n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=.2, random_state = random_state, stratify = y_train)\n",
    "\n",
    "print(\"Tabular data:\")\n",
    "print(\"Model training tabular features - shape: \",X_train2.shape)\n",
    "print(\"Model validation tabular features - shape: \",X_val.shape)\n",
    "print(\"Model training tabular label - shape: \",y_train2.shape)\n",
    "print(\"Model validation tabular label - shape: \",y_val.shape)\n",
    "print(\"Source training tabular features - shape: \",X_train.shape)\n",
    "print(\"Source training tabular features - shape: \",X_train.shape)\n",
    "print(\"Source testing tabular features - shape: \",X_test.shape)\n",
    "\n",
    "\n",
    "# Preparing to read image files\n",
    "train_file_list = pd.Series(X_train.index).apply(lambda x: \"./images/\"+str(x)+'.jpg')\n",
    "train2_file_list = pd.Series(X_train2.index).apply(lambda x: \"./images/\"+str(x)+'.jpg')\n",
    "val_file_list = pd.Series(X_val.index).apply(lambda x: \"./images/\"+str(x)+'.jpg')\n",
    "test_file_list = pd.Series(X_test.index).apply(lambda x: \"./images/\"+str(x)+'.jpg')\n",
    "\n",
    "def paths_to_tensor(img_path):\n",
    "    a = image.load_img(img_path, target_size=(256,256),grayscale=True)\n",
    "    x = image.img_to_array(a)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "# Read all image files\n",
    "\n",
    "train2_images = [paths_to_tensor(path) for path in train2_file_list]\n",
    "\n",
    "train2_images = np.vstack(train2_images).astype('float32')/255\n",
    "\n",
    "train_images = [paths_to_tensor(path) for path in train_file_list]\n",
    "\n",
    "train_images = np.vstack(train_images).astype('float32')/255\n",
    "\n",
    "val_images = [paths_to_tensor(path) for path in val_file_list]\n",
    "\n",
    "val_images = np.vstack(val_images).astype('float32')/255\n",
    "\n",
    "test_images = [paths_to_tensor(path) for path in test_file_list]\n",
    "\n",
    "test_images = np.vstack(test_images).astype('float32')/255\n",
    "\n",
    "print()\n",
    "print(\"Image data:\")\n",
    "print(\"Model training image data shape: \",train2_images.shape)\n",
    "print(\"Model validation image data shape: \",val_images.shape)\n",
    "print(\"Source testing image data shape: \",test_images.shape)\n",
    "print(\"Source training image data shape: \",train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin32</th>\n",
       "      <th>margin64</th>\n",
       "      <th>shape1</th>\n",
       "      <th>shape32</th>\n",
       "      <th>shape64</th>\n",
       "      <th>texture1</th>\n",
       "      <th>texture32</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.049805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     margin1  margin32  margin64    shape1   shape32   shape64  texture1  \\\n",
       "id                                                                         \n",
       "1   0.007812  0.003906  0.001953  0.000647  0.000500  0.000661  0.049805   \n",
       "2   0.005859  0.027344  0.000000  0.000749  0.000884  0.000747  0.000000   \n",
       "3   0.005859  0.000000  0.007812  0.000973  0.001178  0.000971  0.003906   \n",
       "5   0.000000  0.027344  0.005859  0.000453  0.000487  0.000443  0.023438   \n",
       "6   0.005859  0.013672  0.000000  0.000682  0.000594  0.000755  0.039062   \n",
       "\n",
       "    texture32  texture64  \n",
       "id                        \n",
       "1    0.000000   0.025391  \n",
       "2    0.000000   0.022461  \n",
       "3    0.000000   0.002930  \n",
       "5    0.009766   0.047852  \n",
       "6    0.000000   0.031250  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "1              Acer_Opalus\n",
       "2    Pterocarya_Stenoptera\n",
       "3     Quercus_Hartwissiana\n",
       "5          Tilia_Tomentosa\n",
       "6       Quercus_Variabilis\n",
       "Name: species, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a sample of the image extracted features (the tabular data)\n",
    "display(X_train_org[[\"margin1\",\"margin32\",\"margin64\",\"shape1\",\"shape32\",\"shape64\",\n",
    "                \"texture1\",\"texture32\",\"texture64\"]].head())\n",
    "display(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin32</th>\n",
       "      <th>margin64</th>\n",
       "      <th>shape1</th>\n",
       "      <th>shape32</th>\n",
       "      <th>shape64</th>\n",
       "      <th>texture1</th>\n",
       "      <th>texture32</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.009691</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.019420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.019739</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.044043</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.022768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.029297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.126950</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.413090</td>\n",
       "      <td>0.125980</td>\n",
       "      <td>0.141600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          margin1    margin32    margin64      shape1     shape32     shape64  \\\n",
       "count  990.000000  990.000000  990.000000  990.000000  990.000000  990.000000   \n",
       "mean     0.017412    0.009691    0.004374    0.000739    0.000734    0.000732   \n",
       "std      0.019739    0.019291    0.009252    0.000272    0.000274    0.000268   \n",
       "min      0.000000    0.000000    0.000000    0.000168    0.000053    0.000166   \n",
       "25%      0.001953    0.000000    0.000000    0.000518    0.000521    0.000513   \n",
       "50%      0.009766    0.001953    0.001953    0.000716    0.000723    0.000711   \n",
       "75%      0.025391    0.009766    0.003906    0.000928    0.000923    0.000924   \n",
       "max      0.087891    0.126950    0.089844    0.002390    0.002124    0.002431   \n",
       "\n",
       "         texture1   texture32   texture64  \n",
       "count  990.000000  990.000000  990.000000  \n",
       "mean     0.021944    0.006048    0.019420  \n",
       "std      0.044043    0.015114    0.022768  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000977  \n",
       "50%      0.006836    0.000000    0.011719  \n",
       "75%      0.020508    0.002930    0.029297  \n",
       "max      0.413090    0.125980    0.141600  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin32</th>\n",
       "      <th>margin64</th>\n",
       "      <th>shape1</th>\n",
       "      <th>shape32</th>\n",
       "      <th>shape64</th>\n",
       "      <th>texture1</th>\n",
       "      <th>texture32</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.198113</td>\n",
       "      <td>0.076334</td>\n",
       "      <td>0.048681</td>\n",
       "      <td>0.257162</td>\n",
       "      <td>0.328607</td>\n",
       "      <td>0.250020</td>\n",
       "      <td>0.053122</td>\n",
       "      <td>0.048006</td>\n",
       "      <td>0.137146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.224585</td>\n",
       "      <td>0.151956</td>\n",
       "      <td>0.102973</td>\n",
       "      <td>0.122555</td>\n",
       "      <td>0.132298</td>\n",
       "      <td>0.118452</td>\n",
       "      <td>0.106618</td>\n",
       "      <td>0.119969</td>\n",
       "      <td>0.160789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.022221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157534</td>\n",
       "      <td>0.225772</td>\n",
       "      <td>0.153075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.111115</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>0.021738</td>\n",
       "      <td>0.246640</td>\n",
       "      <td>0.323647</td>\n",
       "      <td>0.240730</td>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.288892</td>\n",
       "      <td>0.076928</td>\n",
       "      <td>0.043475</td>\n",
       "      <td>0.341882</td>\n",
       "      <td>0.419912</td>\n",
       "      <td>0.334592</td>\n",
       "      <td>0.049645</td>\n",
       "      <td>0.023258</td>\n",
       "      <td>0.206900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          margin1    margin32    margin64      shape1     shape32     shape64  \\\n",
       "count  990.000000  990.000000  990.000000  990.000000  990.000000  990.000000   \n",
       "mean     0.198113    0.076334    0.048681    0.257162    0.328607    0.250020   \n",
       "std      0.224585    0.151956    0.102973    0.122555    0.132298    0.118452   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.022221    0.000000    0.000000    0.157534    0.225772    0.153075   \n",
       "50%      0.111115    0.015384    0.021738    0.246640    0.323647    0.240730   \n",
       "75%      0.288892    0.076928    0.043475    0.341882    0.419912    0.334592   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         texture1   texture32   texture64  \n",
       "count  990.000000  990.000000  990.000000  \n",
       "mean     0.053122    0.048006    0.137146  \n",
       "std      0.106618    0.119969    0.160789  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.006900  \n",
       "50%      0.016548    0.000000    0.082761  \n",
       "75%      0.049645    0.023258    0.206900  \n",
       "max      1.000000    1.000000    1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_org[[\"margin1\",\"margin32\",\"margin64\",\"shape1\",\"shape32\",\"shape64\",\n",
    "                \"texture1\",\"texture32\",\"texture64\"]].describe())\n",
    "display(X_train[[\"margin1\",\"margin32\",\"margin64\",\"shape1\",\"shape32\",\"shape64\",\n",
    "                \"texture1\",\"texture32\",\"texture64\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff70c63b780>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a sample image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.imshow(1-train_images[3,:,:,0],cmap='Greys')\n",
    "plt.title(y_train[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff730885748>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Constructing a scatter plot for a sample of nine features\n",
    "\n",
    "X_train_eda = pd.DataFrame(X_train[['margin1','margin32','margin64','shape1','shape32','shape64','texture1','texture32','texture64']])\n",
    "\n",
    "pd.plotting.scatter_matrix(X_train_eda, alpha = 0.3, figsize = (14,14), diagonal = 'kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.227671\n",
       "2     0.366516\n",
       "3     0.427271\n",
       "4     0.487533\n",
       "5     0.530399\n",
       "6     0.569413\n",
       "7     0.604153\n",
       "8     0.631987\n",
       "9     0.655624\n",
       "10    0.673711\n",
       "11    0.691072\n",
       "12    0.707747\n",
       "13    0.723133\n",
       "14    0.737339\n",
       "15    0.748845\n",
       "16    0.760082\n",
       "17    0.770560\n",
       "18    0.780021\n",
       "19    0.789238\n",
       "20    0.797641\n",
       "21    0.805419\n",
       "22    0.812648\n",
       "23    0.819791\n",
       "24    0.826371\n",
       "25    0.832524\n",
       "26    0.838257\n",
       "27    0.843672\n",
       "28    0.848929\n",
       "29    0.854039\n",
       "30    0.858645\n",
       "Name: Explained Variance for number of components, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6cab6b5c0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyzing dimnesionality reduction effect on the tabular source training data\n",
    "n_components = 192\n",
    "pca = PCA(n_components=n_components,random_state=random_state).fit(X_train)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "\n",
    "#pca = PCA(n_components=n_components,random_state=random_state).fit(X_train2)\n",
    "\n",
    "#X_train2_pca = pca.transform(X_train2)\n",
    "\n",
    "#pca = PCA(n_components=n_components,random_state=random_state).fit(X_val)\n",
    "\n",
    "#X_val_pca = pca.transform(X_val)\n",
    "\n",
    "#pca = PCA(n_components=n_components,random_state=random_state).fit(X_test)\n",
    "\n",
    "#X_test_pca = pca.transform(X_test)\n",
    "\n",
    "explained_variance = pd.Series(pca.explained_variance_ratio_.cumsum(),\n",
    "          index=np.arange(1,n_components+1),\n",
    "         name=\"Explained Variance for number of components\")\n",
    "\n",
    "display(explained_variance[:30])\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum());\n",
    "plt.xlabel(\"Number of Componenets\");\n",
    "plt.ylabel(\"Cummulative Explained Variance Ratio\");\n",
    "plt.title(\"PCA for Leaf Tabular Data\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the performance of different classifier algorithms on the tabular data:\n",
    "\n",
    "## 1- Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = np.zeros(5)\n",
    "log_loss_train_scores = np.zeros(5)\n",
    "log_loss_test_scores = np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on training data: 0.962626262626\n",
      "Log Loss Score on training data: 0.0658413505449\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state= random_state)\n",
    "\n",
    "parameters = {'max_depth' : [ 10,30,35], 'max_features' : [25,35,40], 'min_samples_split' : [3,5,6]}\n",
    "\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "grid_obj = GridSearchCV(clf, param_grid = parameters, scoring = scorer, cv = skf)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "predictions = best_clf.predict(X_train)\n",
    "print(\"Accuracy Score on training data:\", accuracy_score(predictions,y_train))\n",
    "accuracy_scores[0] = accuracy_score(predictions,y_train)\n",
    "\n",
    "predictions = best_clf.predict_proba(X_train)\n",
    "print(\"Log Loss Score on training data:\", log_loss(pd.get_dummies(y_train).values,predictions))\n",
    "log_loss_train_scores[0]= log_loss(pd.get_dummies(y_train).values,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score on testing data: 14.75\n"
     ]
    }
   ],
   "source": [
    "# Getting log loss score on test data\n",
    "predictions = best_clf.predict_proba(X_test)\n",
    "\n",
    "submission = pd.DataFrame(predictions,index=X_test.index,columns=best_clf.classes_)\n",
    "\n",
    "submission.to_csv(r'submission_DT.csv')\n",
    "\n",
    "# Getting the multi-class log-loss from Kaggle submission\n",
    "log_loss_DT = 14.75\n",
    "\n",
    "print(\"Log loss score on testing data:\", log_loss_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Decision Tree Classifier had the following parameters:\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=30,\n",
      "            max_features=25, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(\"The best Decision Tree Classifier had the following parameters:\")\n",
    "print()\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on training data: 0.616161616162\n",
      "Log Loss Score on training data: 2.0899938625\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(random_state= random_state)\n",
    "\n",
    "parameters = {'n_estimators' : [90,100,150,200], 'learning_rate' : [.001, .01, .1]}\n",
    "\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "grid_obj = GridSearchCV(clf, param_grid = parameters, scoring = scorer, cv = skf)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "predictions = best_clf.predict(X_train)\n",
    "accuracy_scores[1] = accuracy_score(predictions,y_train)\n",
    "print(\"Accuracy Score on training data:\", accuracy_scores[1])\n",
    "\n",
    "\n",
    "predictions = best_clf.predict_proba(X_train)\n",
    "log_loss_train_scores[1]= log_loss(pd.get_dummies(y_train).values,predictions)\n",
    "print(\"Log Loss Score on training data:\", log_loss_train_scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score on testing data: 2.5\n"
     ]
    }
   ],
   "source": [
    "# Getting log loss score on test data\n",
    "predictions = best_clf.predict_proba(X_test)\n",
    "\n",
    "submission = pd.DataFrame(predictions,index=X_test.index,columns=best_clf.classes_)\n",
    "\n",
    "submission.to_csv(r'submission_Ada.csv')\n",
    "\n",
    "log_loss_Ada = 2.5\n",
    "\n",
    "print(\"Log loss score on testing data:\", log_loss_Ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best AdaBoost Classifier had the following parameters:\n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.01, n_estimators=150, random_state=123)\n"
     ]
    }
   ],
   "source": [
    "print(\"The best AdaBoost Classifier had the following parameters:\")\n",
    "print()\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on training data: 1.0\n",
      "Log Loss Score on training data: 1.96785374076\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(random_state= random_state,probability=True)\n",
    "\n",
    "parameters = {'C' : [1,10,50], 'gamma' : [.01,0.1]}\n",
    "\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "grid_obj = GridSearchCV(clf, param_grid = parameters, scoring = scorer, cv = skf)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "predictions = best_clf.predict(X_train)\n",
    "accuracy_scores[2] = accuracy_score(predictions,y_train)\n",
    "print(\"Accuracy Score on training data:\", accuracy_scores[2])\n",
    "\n",
    "predictions = best_clf.predict_proba(X_train)\n",
    "log_loss_train_scores[2]= log_loss(pd.get_dummies(y_train).values,predictions)\n",
    "print(\"Log Loss Score on training data:\", log_loss_train_scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score on testing data: 1.99\n"
     ]
    }
   ],
   "source": [
    "# Getting log loss score on test data\n",
    "predictions = best_clf.predict_proba(X_test)\n",
    "\n",
    "submission = pd.DataFrame(predictions,index=X_test.index,columns=best_clf.classes_)\n",
    "\n",
    "submission.to_csv(r'submission_SVC.csv')\n",
    "\n",
    "log_loss_SVC = 1.99\n",
    "\n",
    "print(\"Log loss score on testing data:\", log_loss_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM Classifier had the following parameters:\n",
      "\n",
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"The best SVM Classifier had the following parameters:\")\n",
    "print()\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on training data: 0.988888888889\n",
      "Log Loss Score on training data: 0.0476985030164\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors' : [3,5,10],'leaf_size': [5,10,20]}\n",
    "\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "grid_obj = GridSearchCV(clf, param_grid = parameters, scoring = scorer, cv = skf)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions = best_clf.predict(X_train)\n",
    "accuracy_scores[3] = accuracy_score(predictions,y_train)\n",
    "print(\"Accuracy Score on training data:\", accuracy_scores[3])\n",
    "\n",
    "predictions = best_clf.predict_proba(X_train)\n",
    "log_loss_train_scores[3]= log_loss(pd.get_dummies(y_train).values,predictions)\n",
    "print(\"Log Loss Score on training data:\", log_loss_train_scores[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score on testing data: 0.14\n"
     ]
    }
   ],
   "source": [
    "# Getting log loss score on test data\n",
    "predictions = best_clf.predict_proba(X_test)\n",
    "\n",
    "submission = pd.DataFrame(predictions,index=X_test.index,columns=best_clf.classes_)\n",
    "\n",
    "submission.to_csv(r'submission_KNN.csv')\n",
    "\n",
    "log_loss_KNN = 0.14\n",
    "\n",
    "print(\"Log loss score on testing data:\", log_loss_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best KNN Classifier had the following parameters:\n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=5, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(\"The best KNN Classifier had the following parameters:\")\n",
    "print()\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the performance of different classifier algorithms on image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train3_images = np.reshape(train_images,(990,256*256))\n",
    "#test3_images = np.reshape(test_images,(594,256*256))\n",
    "\n",
    "\n",
    "\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(100,100),max_iter=200,random_state=random_state)\n",
    "\n",
    "#parameters = {'learning_rate_init' : [.001],'activation':['relu']}\n",
    "\n",
    "#scorer = make_scorer(accuracy_score)\n",
    "\n",
    "#skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "#grid_obj = GridSearchCV(clf, param_grid = parameters, scoring = scorer, cv = skf)\n",
    "\n",
    "#grid_fit = grid_obj.fit(train3_images,y_train)\n",
    "\n",
    "#best_clf = grid_fit.best_estimator_\n",
    "\n",
    "#predictions = best_clf.predict(train3_images)\n",
    "#accuracy_score(predictions,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = best_clf.predict_proba(X_test)\n",
    "\n",
    "#submission = pd.DataFrame(predictions,index=X_test.index,columns=best_clf.classes_)\n",
    "\n",
    "#submission.to_csv(r'submission_MLP.csv')\n",
    "\n",
    "#best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Implementation on image data alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading keras packages \n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D,Activation\n",
    "from keras.layers import Dropout, Flatten, Dense, Add,BatchNormalization,Merge\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 99)                19899     \n",
      "=================================================================\n",
      "Total params: 235,315\n",
      "Trainable params: 235,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining keras model\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "model.add(Conv2D(filters=16, kernel_size=2,strides=2, padding='same', activation='tanh', \n",
    "                        input_shape=train2_images.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(filters=32, kernel_size=2,strides=2, padding='same', activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(filters=64, kernel_size=2,strides=2, padding='same', activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(99, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the optimizer and compiling the model\n",
    "optimizer = RMSprop(lr=.001, rho=0.9, epsilon=1e-08, decay=0)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 792 samples, validate on 198 samples\n",
      "Epoch 1/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7740 - acc: 0.0082Epoch 00001: val_loss improved from inf to 4.58056, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 4s 6ms/step - loss: 4.7792 - acc: 0.0076 - val_loss: 4.5806 - val_acc: 0.0101\n",
      "Epoch 2/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6578 - acc: 0.0177Epoch 00002: val_loss improved from 4.58056 to 4.55901, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 949us/step - loss: 4.6603 - acc: 0.0177 - val_loss: 4.5590 - val_acc: 0.0253\n",
      "Epoch 3/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6138 - acc: 0.0163Epoch 00003: val_loss improved from 4.55901 to 4.54102, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 954us/step - loss: 4.6095 - acc: 0.0164 - val_loss: 4.5410 - val_acc: 0.0404\n",
      "Epoch 4/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5572 - acc: 0.0190Epoch 00004: val_loss improved from 4.54102 to 4.51370, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 946us/step - loss: 4.5547 - acc: 0.0189 - val_loss: 4.5137 - val_acc: 0.0455\n",
      "Epoch 5/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5464 - acc: 0.0245Epoch 00005: val_loss improved from 4.51370 to 4.46347, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 951us/step - loss: 4.5402 - acc: 0.0253 - val_loss: 4.4635 - val_acc: 0.0707\n",
      "Epoch 6/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4449 - acc: 0.0312Epoch 00006: val_loss improved from 4.46347 to 4.38470, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 949us/step - loss: 4.4491 - acc: 0.0354 - val_loss: 4.3847 - val_acc: 0.0960\n",
      "Epoch 7/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3548 - acc: 0.0598Epoch 00007: val_loss improved from 4.38470 to 4.24168, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 949us/step - loss: 4.3424 - acc: 0.0619 - val_loss: 4.2417 - val_acc: 0.1061\n",
      "Epoch 8/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2195 - acc: 0.0734Epoch 00008: val_loss improved from 4.24168 to 4.04649, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 950us/step - loss: 4.2111 - acc: 0.0770 - val_loss: 4.0465 - val_acc: 0.1566\n",
      "Epoch 9/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9820 - acc: 0.1101Epoch 00009: val_loss improved from 4.04649 to 3.79878, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 953us/step - loss: 3.9846 - acc: 0.1098 - val_loss: 3.7988 - val_acc: 0.2121\n",
      "Epoch 10/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8041 - acc: 0.1114Epoch 00010: val_loss improved from 3.79878 to 3.54161, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 947us/step - loss: 3.8186 - acc: 0.1073 - val_loss: 3.5416 - val_acc: 0.2475\n",
      "Epoch 11/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6678 - acc: 0.1223Epoch 00011: val_loss improved from 3.54161 to 3.34334, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 950us/step - loss: 3.6545 - acc: 0.1263 - val_loss: 3.3433 - val_acc: 0.2677\n",
      "Epoch 12/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4794 - acc: 0.1644Epoch 00012: val_loss improved from 3.34334 to 3.22794, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 953us/step - loss: 3.5001 - acc: 0.1604 - val_loss: 3.2279 - val_acc: 0.2929\n",
      "Epoch 13/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3493 - acc: 0.1821Epoch 00013: val_loss improved from 3.22794 to 3.06583, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 946us/step - loss: 3.3737 - acc: 0.1768 - val_loss: 3.0658 - val_acc: 0.3283\n",
      "Epoch 14/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2097 - acc: 0.2052Epoch 00014: val_loss improved from 3.06583 to 2.97969, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 949us/step - loss: 3.2552 - acc: 0.1982 - val_loss: 2.9797 - val_acc: 0.3232\n",
      "Epoch 15/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1288 - acc: 0.2228Epoch 00015: val_loss improved from 2.97969 to 2.80943, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 948us/step - loss: 3.1047 - acc: 0.2260 - val_loss: 2.8094 - val_acc: 0.3586\n",
      "Epoch 16/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0033 - acc: 0.2568Epoch 00016: val_loss improved from 2.80943 to 2.75747, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 953us/step - loss: 2.9900 - acc: 0.2563 - val_loss: 2.7575 - val_acc: 0.3788\n",
      "Epoch 17/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9727 - acc: 0.2228Epoch 00017: val_loss improved from 2.75747 to 2.68055, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 947us/step - loss: 2.9609 - acc: 0.2247 - val_loss: 2.6805 - val_acc: 0.3838\n",
      "Epoch 18/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8467 - acc: 0.2772Epoch 00018: val_loss improved from 2.68055 to 2.56979, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 946us/step - loss: 2.8526 - acc: 0.2715 - val_loss: 2.5698 - val_acc: 0.3939\n",
      "Epoch 19/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8549 - acc: 0.2921Epoch 00019: val_loss improved from 2.56979 to 2.52806, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 944us/step - loss: 2.8434 - acc: 0.2917 - val_loss: 2.5281 - val_acc: 0.3990\n",
      "Epoch 20/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6803 - acc: 0.2812Epoch 00020: val_loss improved from 2.52806 to 2.46101, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 949us/step - loss: 2.6890 - acc: 0.2778 - val_loss: 2.4610 - val_acc: 0.4545\n",
      "Epoch 21/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6603 - acc: 0.3125Epoch 00021: val_loss improved from 2.46101 to 2.43346, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 946us/step - loss: 2.6601 - acc: 0.3157 - val_loss: 2.4335 - val_acc: 0.4646\n",
      "Epoch 22/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6217 - acc: 0.3234Epoch 00022: val_loss improved from 2.43346 to 2.40600, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 953us/step - loss: 2.6181 - acc: 0.3245 - val_loss: 2.4060 - val_acc: 0.4141\n",
      "Epoch 23/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5397 - acc: 0.3247Epoch 00023: val_loss improved from 2.40600 to 2.37211, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 950us/step - loss: 2.5203 - acc: 0.3308 - val_loss: 2.3721 - val_acc: 0.4343\n",
      "Epoch 24/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4894 - acc: 0.3207Epoch 00024: val_loss improved from 2.37211 to 2.31838, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 945us/step - loss: 2.5106 - acc: 0.3131 - val_loss: 2.3184 - val_acc: 0.4394\n",
      "Epoch 25/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4379 - acc: 0.3410Epoch 00025: val_loss improved from 2.31838 to 2.29200, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 950us/step - loss: 2.4060 - acc: 0.3460 - val_loss: 2.2920 - val_acc: 0.4343\n",
      "Epoch 26/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3821 - acc: 0.3818Epoch 00026: val_loss improved from 2.29200 to 2.24976, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 944us/step - loss: 2.4002 - acc: 0.3737 - val_loss: 2.2498 - val_acc: 0.4949\n",
      "Epoch 27/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3467 - acc: 0.3723Epoch 00027: val_loss improved from 2.24976 to 2.24575, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 959us/step - loss: 2.3453 - acc: 0.3699 - val_loss: 2.2458 - val_acc: 0.4596\n",
      "Epoch 28/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2459 - acc: 0.4103Epoch 00028: val_loss improved from 2.24575 to 2.20185, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 946us/step - loss: 2.2600 - acc: 0.4015 - val_loss: 2.2018 - val_acc: 0.4697\n",
      "Epoch 29/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2385 - acc: 0.4022Epoch 00029: val_loss improved from 2.20185 to 2.18295, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 951us/step - loss: 2.2218 - acc: 0.4116 - val_loss: 2.1829 - val_acc: 0.4798\n",
      "Epoch 30/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1455 - acc: 0.4402Epoch 00030: val_loss did not improve\n",
      "792/792 [==============================] - 1s 919us/step - loss: 2.1536 - acc: 0.4369 - val_loss: 2.2033 - val_acc: 0.4495\n",
      "Epoch 31/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1487 - acc: 0.4185Epoch 00031: val_loss improved from 2.18295 to 2.15134, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 973us/step - loss: 2.1506 - acc: 0.4205 - val_loss: 2.1513 - val_acc: 0.4646\n",
      "Epoch 32/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1071 - acc: 0.4171Epoch 00032: val_loss improved from 2.15134 to 2.11355, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 985us/step - loss: 2.1078 - acc: 0.4192 - val_loss: 2.1136 - val_acc: 0.4747\n",
      "Epoch 33/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0571 - acc: 0.4321Epoch 00033: val_loss improved from 2.11355 to 2.04194, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 977us/step - loss: 2.0663 - acc: 0.4255 - val_loss: 2.0419 - val_acc: 0.5000\n",
      "Epoch 34/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0097 - acc: 0.4674Epoch 00034: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 2.0209 - acc: 0.4672 - val_loss: 2.1027 - val_acc: 0.4596\n",
      "Epoch 35/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0112 - acc: 0.4592Epoch 00035: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 2.0189 - acc: 0.4558 - val_loss: 2.0561 - val_acc: 0.4747\n",
      "Epoch 36/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9878 - acc: 0.4592Epoch 00036: val_loss improved from 2.04194 to 2.00723, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 960us/step - loss: 1.9871 - acc: 0.4583 - val_loss: 2.0072 - val_acc: 0.5202\n",
      "Epoch 37/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9068 - acc: 0.4728Epoch 00037: val_loss improved from 2.00723 to 1.93100, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 977us/step - loss: 1.9078 - acc: 0.4785 - val_loss: 1.9310 - val_acc: 0.5455\n",
      "Epoch 38/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8827 - acc: 0.4864Epoch 00038: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 1.8835 - acc: 0.4874 - val_loss: 1.9767 - val_acc: 0.5152\n",
      "Epoch 39/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8506 - acc: 0.4891Epoch 00039: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 1.8605 - acc: 0.4886 - val_loss: 2.0150 - val_acc: 0.5000\n",
      "Epoch 40/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8408 - acc: 0.5041Epoch 00040: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 1.8337 - acc: 0.5038 - val_loss: 1.9543 - val_acc: 0.5000\n",
      "Epoch 41/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7481 - acc: 0.5231Epoch 00041: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 1.7608 - acc: 0.5164 - val_loss: 1.9789 - val_acc: 0.5101\n",
      "Epoch 42/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7357 - acc: 0.5489Epoch 00042: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 1.7248 - acc: 0.5505 - val_loss: 1.9396 - val_acc: 0.5051\n",
      "Epoch 43/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7456 - acc: 0.5367Epoch 00043: val_loss improved from 1.93100 to 1.89817, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 971us/step - loss: 1.7446 - acc: 0.5366 - val_loss: 1.8982 - val_acc: 0.5051\n",
      "Epoch 44/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6852 - acc: 0.5557Epoch 00044: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 1.7054 - acc: 0.5518 - val_loss: 1.9300 - val_acc: 0.4798\n",
      "Epoch 45/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6698 - acc: 0.5625Epoch 00045: val_loss improved from 1.89817 to 1.89495, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 972us/step - loss: 1.6687 - acc: 0.5644 - val_loss: 1.8949 - val_acc: 0.4949\n",
      "Epoch 46/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6470 - acc: 0.5679Epoch 00046: val_loss improved from 1.89495 to 1.87488, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 972us/step - loss: 1.6479 - acc: 0.5631 - val_loss: 1.8749 - val_acc: 0.4949\n",
      "Epoch 47/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6725 - acc: 0.5353Epoch 00047: val_loss improved from 1.87488 to 1.85814, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 977us/step - loss: 1.6604 - acc: 0.5404 - val_loss: 1.8581 - val_acc: 0.5202\n",
      "Epoch 48/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5948 - acc: 0.5652Epoch 00048: val_loss improved from 1.85814 to 1.85261, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 979us/step - loss: 1.5817 - acc: 0.5669 - val_loss: 1.8526 - val_acc: 0.4697\n",
      "Epoch 49/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6002 - acc: 0.5625Epoch 00049: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 1.5884 - acc: 0.5631 - val_loss: 1.8914 - val_acc: 0.5051\n",
      "Epoch 50/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5539 - acc: 0.5734Epoch 00050: val_loss did not improve\n",
      "792/792 [==============================] - 1s 931us/step - loss: 1.5609 - acc: 0.5644 - val_loss: 1.8620 - val_acc: 0.5101\n",
      "Epoch 51/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5650 - acc: 0.5910Epoch 00051: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 1.5511 - acc: 0.5934 - val_loss: 1.8580 - val_acc: 0.4848\n",
      "Epoch 52/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5302 - acc: 0.5842Epoch 00052: val_loss improved from 1.85261 to 1.85045, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 978us/step - loss: 1.5434 - acc: 0.5846 - val_loss: 1.8504 - val_acc: 0.5202\n",
      "Epoch 53/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5337 - acc: 0.5870Epoch 00053: val_loss improved from 1.85045 to 1.81283, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 978us/step - loss: 1.5310 - acc: 0.5871 - val_loss: 1.8128 - val_acc: 0.4848\n",
      "Epoch 54/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4626 - acc: 0.6073Epoch 00054: val_loss improved from 1.81283 to 1.78564, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 975us/step - loss: 1.4637 - acc: 0.6048 - val_loss: 1.7856 - val_acc: 0.5354\n",
      "Epoch 55/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4604 - acc: 0.6046Epoch 00055: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 1.4685 - acc: 0.6023 - val_loss: 1.8035 - val_acc: 0.5202\n",
      "Epoch 56/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4139 - acc: 0.6250Epoch 00056: val_loss improved from 1.78564 to 1.72720, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 969us/step - loss: 1.4054 - acc: 0.6199 - val_loss: 1.7272 - val_acc: 0.5253\n",
      "Epoch 57/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4180 - acc: 0.5978Epoch 00057: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 1.4233 - acc: 0.6010 - val_loss: 1.7703 - val_acc: 0.5253\n",
      "Epoch 58/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4190 - acc: 0.6264Epoch 00058: val_loss improved from 1.72720 to 1.70943, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 973us/step - loss: 1.4032 - acc: 0.6313 - val_loss: 1.7094 - val_acc: 0.5455\n",
      "Epoch 59/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3744 - acc: 0.6128Epoch 00059: val_loss improved from 1.70943 to 1.70344, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 977us/step - loss: 1.3972 - acc: 0.6010 - val_loss: 1.7034 - val_acc: 0.5505\n",
      "Epoch 60/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4353 - acc: 0.5924Epoch 00060: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 1.4418 - acc: 0.5947 - val_loss: 1.7370 - val_acc: 0.5303\n",
      "Epoch 61/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4118 - acc: 0.6114Epoch 00061: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 1.4038 - acc: 0.6098 - val_loss: 1.7314 - val_acc: 0.4899\n",
      "Epoch 62/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3174 - acc: 0.6250Epoch 00062: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 1.3412 - acc: 0.6174 - val_loss: 1.7209 - val_acc: 0.4899\n",
      "Epoch 63/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3245 - acc: 0.6495Epoch 00063: val_loss improved from 1.70344 to 1.68303, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 988us/step - loss: 1.3106 - acc: 0.6490 - val_loss: 1.6830 - val_acc: 0.5202\n",
      "Epoch 64/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2877 - acc: 0.6467Epoch 00064: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 1.2965 - acc: 0.6439 - val_loss: 1.7749 - val_acc: 0.5152\n",
      "Epoch 65/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2721 - acc: 0.6535Epoch 00065: val_loss improved from 1.68303 to 1.65338, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.2854 - acc: 0.6503 - val_loss: 1.6534 - val_acc: 0.5657\n",
      "Epoch 66/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2669 - acc: 0.6726Epoch 00066: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 1.2558 - acc: 0.6780 - val_loss: 1.6725 - val_acc: 0.5354\n",
      "Epoch 67/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2762 - acc: 0.6454Epoch 00067: val_loss improved from 1.65338 to 1.64916, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 985us/step - loss: 1.2889 - acc: 0.6465 - val_loss: 1.6492 - val_acc: 0.5253\n",
      "Epoch 68/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2155 - acc: 0.6630Epoch 00068: val_loss improved from 1.64916 to 1.63193, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 980us/step - loss: 1.2174 - acc: 0.6604 - val_loss: 1.6319 - val_acc: 0.5556\n",
      "Epoch 69/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2463 - acc: 0.6617Epoch 00069: val_loss improved from 1.63193 to 1.58668, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 984us/step - loss: 1.2491 - acc: 0.6566 - val_loss: 1.5867 - val_acc: 0.5859\n",
      "Epoch 70/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2505 - acc: 0.6535Epoch 00070: val_loss improved from 1.58668 to 1.57500, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 973us/step - loss: 1.2605 - acc: 0.6490 - val_loss: 1.5750 - val_acc: 0.5606\n",
      "Epoch 71/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1943 - acc: 0.6712Epoch 00071: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 1.1829 - acc: 0.6742 - val_loss: 1.5996 - val_acc: 0.5303\n",
      "Epoch 72/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1926 - acc: 0.6780Epoch 00072: val_loss improved from 1.57500 to 1.56600, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 984us/step - loss: 1.1933 - acc: 0.6780 - val_loss: 1.5660 - val_acc: 0.5404\n",
      "Epoch 73/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2123 - acc: 0.6780Epoch 00073: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 1.2152 - acc: 0.6793 - val_loss: 1.6337 - val_acc: 0.5253\n",
      "Epoch 74/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1948 - acc: 0.6617Epoch 00074: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 1.1937 - acc: 0.6629 - val_loss: 1.5790 - val_acc: 0.5505\n",
      "Epoch 75/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2150 - acc: 0.6630Epoch 00075: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 1.1955 - acc: 0.6692 - val_loss: 1.5770 - val_acc: 0.5354\n",
      "Epoch 76/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1723 - acc: 0.6957Epoch 00076: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 1.1828 - acc: 0.6869 - val_loss: 1.6318 - val_acc: 0.5707\n",
      "Epoch 77/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1569 - acc: 0.6848Epoch 00077: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 1.1579 - acc: 0.6869 - val_loss: 1.5842 - val_acc: 0.5808\n",
      "Epoch 78/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1561 - acc: 0.6916Epoch 00078: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 1.1471 - acc: 0.6919 - val_loss: 1.5833 - val_acc: 0.5657\n",
      "Epoch 79/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0482 - acc: 0.7147Epoch 00079: val_loss improved from 1.56600 to 1.56019, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 987us/step - loss: 1.0615 - acc: 0.7083 - val_loss: 1.5602 - val_acc: 0.5859\n",
      "Epoch 80/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0340 - acc: 0.7323Epoch 00080: val_loss improved from 1.56019 to 1.54910, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 983us/step - loss: 1.0277 - acc: 0.7361 - val_loss: 1.5491 - val_acc: 0.5657\n",
      "Epoch 81/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1203 - acc: 0.6807Epoch 00081: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 1.1233 - acc: 0.6831 - val_loss: 1.5594 - val_acc: 0.5404\n",
      "Epoch 82/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0645 - acc: 0.6929Epoch 00082: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 1.0674 - acc: 0.6932 - val_loss: 1.5968 - val_acc: 0.5455\n",
      "Epoch 83/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0336 - acc: 0.7174Epoch 00083: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 1.0436 - acc: 0.7109 - val_loss: 1.5503 - val_acc: 0.5707\n",
      "Epoch 84/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0672 - acc: 0.7188Epoch 00084: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 1.0622 - acc: 0.7235 - val_loss: 1.5953 - val_acc: 0.5455\n",
      "Epoch 85/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0348 - acc: 0.7079Epoch 00085: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 1.0391 - acc: 0.7096 - val_loss: 1.5927 - val_acc: 0.5505\n",
      "Epoch 86/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9887 - acc: 0.7568Epoch 00086: val_loss improved from 1.54910 to 1.50521, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 986us/step - loss: 0.9865 - acc: 0.7538 - val_loss: 1.5052 - val_acc: 0.5707\n",
      "Epoch 87/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9719 - acc: 0.7446Epoch 00087: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.9682 - acc: 0.7424 - val_loss: 1.5283 - val_acc: 0.5657\n",
      "Epoch 88/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0148 - acc: 0.7160Epoch 00088: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 1.0337 - acc: 0.7058 - val_loss: 1.5270 - val_acc: 0.5707\n",
      "Epoch 89/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9632 - acc: 0.7486Epoch 00089: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.9830 - acc: 0.7424 - val_loss: 1.5750 - val_acc: 0.5505\n",
      "Epoch 90/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9503 - acc: 0.7446Epoch 00090: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.9727 - acc: 0.7348 - val_loss: 1.5210 - val_acc: 0.5505\n",
      "Epoch 91/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9628 - acc: 0.7351Epoch 00091: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.9470 - acc: 0.7374 - val_loss: 1.5133 - val_acc: 0.5758\n",
      "Epoch 92/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9591 - acc: 0.7378Epoch 00092: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.9566 - acc: 0.7386 - val_loss: 1.5383 - val_acc: 0.5657\n",
      "Epoch 93/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8876 - acc: 0.7799Epoch 00093: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.8899 - acc: 0.7727 - val_loss: 1.5176 - val_acc: 0.5909\n",
      "Epoch 94/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9771 - acc: 0.7351Epoch 00094: val_loss improved from 1.50521 to 1.47554, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 989us/step - loss: 0.9645 - acc: 0.7412 - val_loss: 1.4755 - val_acc: 0.5758\n",
      "Epoch 95/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9288 - acc: 0.7364Epoch 00095: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.9082 - acc: 0.7449 - val_loss: 1.5203 - val_acc: 0.5707\n",
      "Epoch 96/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9291 - acc: 0.7473Epoch 00096: val_loss improved from 1.47554 to 1.44892, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.9271 - acc: 0.7449 - val_loss: 1.4489 - val_acc: 0.5859\n",
      "Epoch 97/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9451 - acc: 0.7323Epoch 00097: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.9357 - acc: 0.7386 - val_loss: 1.4761 - val_acc: 0.5859\n",
      "Epoch 98/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9212 - acc: 0.7418Epoch 00098: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.9136 - acc: 0.7449 - val_loss: 1.4784 - val_acc: 0.5909\n",
      "Epoch 99/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9214 - acc: 0.7554Epoch 00099: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.9180 - acc: 0.7563 - val_loss: 1.4600 - val_acc: 0.6061\n",
      "Epoch 100/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8822 - acc: 0.7690Epoch 00100: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.8605 - acc: 0.7753 - val_loss: 1.5249 - val_acc: 0.5707\n",
      "Epoch 101/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8980 - acc: 0.7677Epoch 00101: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.8803 - acc: 0.7727 - val_loss: 1.4713 - val_acc: 0.5707\n",
      "Epoch 102/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9082 - acc: 0.7568Epoch 00102: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.9136 - acc: 0.7563 - val_loss: 1.4681 - val_acc: 0.6061\n",
      "Epoch 103/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8655 - acc: 0.7609Epoch 00103: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.8627 - acc: 0.7626 - val_loss: 1.4971 - val_acc: 0.5657\n",
      "Epoch 104/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8907 - acc: 0.7622Epoch 00104: val_loss improved from 1.44892 to 1.44365, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 978us/step - loss: 0.9088 - acc: 0.7563 - val_loss: 1.4437 - val_acc: 0.5909\n",
      "Epoch 105/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8337 - acc: 0.7853Epoch 00105: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.8244 - acc: 0.7891 - val_loss: 1.5536 - val_acc: 0.5404\n",
      "Epoch 106/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8324 - acc: 0.7745Epoch 00106: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.8397 - acc: 0.7702 - val_loss: 1.4923 - val_acc: 0.5758\n",
      "Epoch 107/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8538 - acc: 0.7677Epoch 00107: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.8689 - acc: 0.7626 - val_loss: 1.4724 - val_acc: 0.6111\n",
      "Epoch 108/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8735 - acc: 0.7677Epoch 00108: val_loss improved from 1.44365 to 1.41968, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 991us/step - loss: 0.8743 - acc: 0.7689 - val_loss: 1.4197 - val_acc: 0.6010\n",
      "Epoch 109/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8625 - acc: 0.7731Epoch 00109: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.8737 - acc: 0.7677 - val_loss: 1.4436 - val_acc: 0.5606\n",
      "Epoch 110/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8395 - acc: 0.7486Epoch 00110: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.8533 - acc: 0.7437 - val_loss: 1.4823 - val_acc: 0.5960\n",
      "Epoch 111/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7912 - acc: 0.7908Epoch 00111: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.7879 - acc: 0.7891 - val_loss: 1.4559 - val_acc: 0.6111\n",
      "Epoch 112/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7782 - acc: 0.7799Epoch 00112: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.7781 - acc: 0.7803 - val_loss: 1.4382 - val_acc: 0.5808\n",
      "Epoch 113/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8131 - acc: 0.7772Epoch 00113: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.8217 - acc: 0.7778 - val_loss: 1.4540 - val_acc: 0.6263\n",
      "Epoch 114/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7977 - acc: 0.7921Epoch 00114: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.8075 - acc: 0.7879 - val_loss: 1.4332 - val_acc: 0.5859\n",
      "Epoch 115/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8245 - acc: 0.7704Epoch 00115: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.8185 - acc: 0.7753 - val_loss: 1.4925 - val_acc: 0.5556\n",
      "Epoch 116/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7858 - acc: 0.7677Epoch 00116: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.7829 - acc: 0.7715 - val_loss: 1.4215 - val_acc: 0.5758\n",
      "Epoch 117/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.8229 - acc: 0.7758Epoch 00117: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.8259 - acc: 0.7727 - val_loss: 1.4504 - val_acc: 0.5758\n",
      "Epoch 118/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7655 - acc: 0.8084Epoch 00118: val_loss improved from 1.41968 to 1.39606, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 987us/step - loss: 0.7652 - acc: 0.8093 - val_loss: 1.3961 - val_acc: 0.5859\n",
      "Epoch 119/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7178 - acc: 0.8220Epoch 00119: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.7276 - acc: 0.8157 - val_loss: 1.4633 - val_acc: 0.5606\n",
      "Epoch 120/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7934 - acc: 0.7840Epoch 00120: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.7922 - acc: 0.7866 - val_loss: 1.4369 - val_acc: 0.6010\n",
      "Epoch 121/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7195 - acc: 0.8179Epoch 00121: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.7210 - acc: 0.8194 - val_loss: 1.4115 - val_acc: 0.5758\n",
      "Epoch 122/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7887 - acc: 0.7704Epoch 00122: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.7949 - acc: 0.7727 - val_loss: 1.4485 - val_acc: 0.5859\n",
      "Epoch 123/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7056 - acc: 0.8247Epoch 00123: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.7140 - acc: 0.8207 - val_loss: 1.4934 - val_acc: 0.5909\n",
      "Epoch 124/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6830 - acc: 0.8288Epoch 00124: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.6987 - acc: 0.8232 - val_loss: 1.4973 - val_acc: 0.5657\n",
      "Epoch 125/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7248 - acc: 0.7962Epoch 00125: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.7233 - acc: 0.7980 - val_loss: 1.4053 - val_acc: 0.5808\n",
      "Epoch 126/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7385 - acc: 0.8057Epoch 00126: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.7448 - acc: 0.8005 - val_loss: 1.4657 - val_acc: 0.5758\n",
      "Epoch 127/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7052 - acc: 0.8179Epoch 00127: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.7231 - acc: 0.8081 - val_loss: 1.4183 - val_acc: 0.5758\n",
      "Epoch 128/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6942 - acc: 0.8139Epoch 00128: val_loss improved from 1.39606 to 1.39119, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 980us/step - loss: 0.6826 - acc: 0.8194 - val_loss: 1.3912 - val_acc: 0.5909\n",
      "Epoch 129/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6962 - acc: 0.8030Epoch 00129: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.7017 - acc: 0.7992 - val_loss: 1.4046 - val_acc: 0.5859\n",
      "Epoch 130/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6881 - acc: 0.8370Epoch 00130: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.6805 - acc: 0.8396 - val_loss: 1.3956 - val_acc: 0.5707\n",
      "Epoch 131/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7190 - acc: 0.8125Epoch 00131: val_loss improved from 1.39119 to 1.36555, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 984us/step - loss: 0.7240 - acc: 0.8119 - val_loss: 1.3655 - val_acc: 0.5859\n",
      "Epoch 132/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6846 - acc: 0.8274Epoch 00132: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.7097 - acc: 0.8182 - val_loss: 1.4101 - val_acc: 0.5808\n",
      "Epoch 133/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6999 - acc: 0.7989Epoch 00133: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.6955 - acc: 0.8018 - val_loss: 1.4340 - val_acc: 0.5859\n",
      "Epoch 134/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6817 - acc: 0.8247Epoch 00134: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.6861 - acc: 0.8220 - val_loss: 1.4463 - val_acc: 0.6010\n",
      "Epoch 135/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6762 - acc: 0.8329Epoch 00135: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.6864 - acc: 0.8283 - val_loss: 1.3980 - val_acc: 0.6061\n",
      "Epoch 136/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6841 - acc: 0.8220Epoch 00136: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.6895 - acc: 0.8220 - val_loss: 1.4500 - val_acc: 0.5707\n",
      "Epoch 137/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6861 - acc: 0.8125Epoch 00137: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.6796 - acc: 0.8157 - val_loss: 1.4368 - val_acc: 0.5859\n",
      "Epoch 138/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7052 - acc: 0.8166Epoch 00138: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.6992 - acc: 0.8169 - val_loss: 1.4627 - val_acc: 0.5657\n",
      "Epoch 139/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7010 - acc: 0.8125Epoch 00139: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.7096 - acc: 0.8119 - val_loss: 1.4206 - val_acc: 0.5808\n",
      "Epoch 140/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6468 - acc: 0.8397Epoch 00140: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.6529 - acc: 0.8371 - val_loss: 1.4375 - val_acc: 0.5556\n",
      "Epoch 141/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6140 - acc: 0.8356Epoch 00141: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.6253 - acc: 0.8308 - val_loss: 1.4476 - val_acc: 0.5707\n",
      "Epoch 142/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5844 - acc: 0.8546Epoch 00142: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.6036 - acc: 0.8422 - val_loss: 1.3782 - val_acc: 0.5960\n",
      "Epoch 143/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6561 - acc: 0.8207Epoch 00143: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.6562 - acc: 0.8220 - val_loss: 1.3927 - val_acc: 0.5758\n",
      "Epoch 144/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6076 - acc: 0.8410Epoch 00144: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.6107 - acc: 0.8409 - val_loss: 1.4222 - val_acc: 0.5909\n",
      "Epoch 145/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6405 - acc: 0.8179Epoch 00145: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.6305 - acc: 0.8245 - val_loss: 1.4546 - val_acc: 0.5707\n",
      "Epoch 146/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6183 - acc: 0.8397Epoch 00146: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.6062 - acc: 0.8447 - val_loss: 1.3978 - val_acc: 0.6111\n",
      "Epoch 147/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6174 - acc: 0.8424Epoch 00147: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.6160 - acc: 0.8447 - val_loss: 1.4096 - val_acc: 0.5960\n",
      "Epoch 148/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6436 - acc: 0.8370Epoch 00148: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.6462 - acc: 0.8359 - val_loss: 1.4949 - val_acc: 0.5606\n",
      "Epoch 149/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5975 - acc: 0.8492Epoch 00149: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.5996 - acc: 0.8485 - val_loss: 1.4242 - val_acc: 0.5909\n",
      "Epoch 150/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6042 - acc: 0.8410Epoch 00150: val_loss improved from 1.36555 to 1.32033, saving model to weights.best1.hdf5\n",
      "792/792 [==============================] - 1s 986us/step - loss: 0.6115 - acc: 0.8333 - val_loss: 1.3203 - val_acc: 0.6162\n",
      "Epoch 151/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6188 - acc: 0.8356Epoch 00151: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.6077 - acc: 0.8422 - val_loss: 1.4312 - val_acc: 0.5859\n",
      "Epoch 152/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6016 - acc: 0.8315Epoch 00152: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.6004 - acc: 0.8295 - val_loss: 1.3816 - val_acc: 0.6061\n",
      "Epoch 153/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5829 - acc: 0.8533Epoch 00153: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.5923 - acc: 0.8485 - val_loss: 1.4298 - val_acc: 0.5859\n",
      "Epoch 154/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6406 - acc: 0.8315Epoch 00154: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.6478 - acc: 0.8295 - val_loss: 1.4347 - val_acc: 0.5859\n",
      "Epoch 155/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5929 - acc: 0.8451Epoch 00155: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.5894 - acc: 0.8434 - val_loss: 1.3812 - val_acc: 0.5859\n",
      "Epoch 156/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6197 - acc: 0.8329Epoch 00156: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.6090 - acc: 0.8359 - val_loss: 1.4012 - val_acc: 0.5808\n",
      "Epoch 157/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5775 - acc: 0.8438Epoch 00157: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.5810 - acc: 0.8422 - val_loss: 1.3876 - val_acc: 0.5758\n",
      "Epoch 158/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6013 - acc: 0.8342Epoch 00158: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.5949 - acc: 0.8346 - val_loss: 1.4091 - val_acc: 0.6111\n",
      "Epoch 159/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6216 - acc: 0.8370Epoch 00159: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.5950 - acc: 0.8460 - val_loss: 1.4183 - val_acc: 0.5909\n",
      "Epoch 160/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6038 - acc: 0.8370Epoch 00160: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.6050 - acc: 0.8346 - val_loss: 1.4346 - val_acc: 0.6111\n",
      "Epoch 161/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5843 - acc: 0.8247Epoch 00161: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.5909 - acc: 0.8270 - val_loss: 1.4778 - val_acc: 0.5758\n",
      "Epoch 162/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6149 - acc: 0.8234Epoch 00162: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.6221 - acc: 0.8220 - val_loss: 1.4061 - val_acc: 0.5758\n",
      "Epoch 163/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5814 - acc: 0.8397Epoch 00163: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.5888 - acc: 0.8396 - val_loss: 1.4846 - val_acc: 0.5758\n",
      "Epoch 164/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5549 - acc: 0.8601Epoch 00164: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.5490 - acc: 0.8611 - val_loss: 1.4017 - val_acc: 0.5960\n",
      "Epoch 165/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5862 - acc: 0.8342Epoch 00165: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.5824 - acc: 0.8384 - val_loss: 1.3675 - val_acc: 0.5909\n",
      "Epoch 166/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5221 - acc: 0.8736Epoch 00166: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.5160 - acc: 0.8750 - val_loss: 1.3431 - val_acc: 0.5960\n",
      "Epoch 167/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5505 - acc: 0.8601Epoch 00167: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.5492 - acc: 0.8586 - val_loss: 1.3915 - val_acc: 0.6162\n",
      "Epoch 168/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6043 - acc: 0.8383Epoch 00168: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.6045 - acc: 0.8396 - val_loss: 1.4080 - val_acc: 0.6212\n",
      "Epoch 169/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5589 - acc: 0.8492Epoch 00169: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.5511 - acc: 0.8535 - val_loss: 1.4237 - val_acc: 0.6061\n",
      "Epoch 170/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5677 - acc: 0.8587Epoch 00170: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.5754 - acc: 0.8548 - val_loss: 1.4542 - val_acc: 0.6212\n",
      "Epoch 171/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5748 - acc: 0.8465Epoch 00171: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.5639 - acc: 0.8523 - val_loss: 1.4177 - val_acc: 0.5909\n",
      "Epoch 172/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5474 - acc: 0.8505Epoch 00172: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.5511 - acc: 0.8497 - val_loss: 1.4131 - val_acc: 0.5808\n",
      "Epoch 173/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5135 - acc: 0.8641Epoch 00173: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.5194 - acc: 0.8636 - val_loss: 1.3797 - val_acc: 0.6212\n",
      "Epoch 174/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5258 - acc: 0.8505Epoch 00174: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.5325 - acc: 0.8472 - val_loss: 1.4705 - val_acc: 0.5859\n",
      "Epoch 175/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5157 - acc: 0.8641Epoch 00175: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.5115 - acc: 0.8649 - val_loss: 1.4164 - val_acc: 0.6010\n",
      "Epoch 176/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5242 - acc: 0.8750Epoch 00176: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.5414 - acc: 0.8687 - val_loss: 1.5151 - val_acc: 0.5859\n",
      "Epoch 177/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5635 - acc: 0.8438Epoch 00177: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.5608 - acc: 0.8460 - val_loss: 1.4199 - val_acc: 0.5859\n",
      "Epoch 178/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4776 - acc: 0.8886Epoch 00178: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.5096 - acc: 0.8737 - val_loss: 1.4166 - val_acc: 0.5758\n",
      "Epoch 179/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5134 - acc: 0.8682Epoch 00179: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.5053 - acc: 0.8687 - val_loss: 1.4075 - val_acc: 0.5960\n",
      "Epoch 180/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5797 - acc: 0.8356Epoch 00180: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.5722 - acc: 0.8422 - val_loss: 1.4029 - val_acc: 0.6212\n",
      "Epoch 181/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5401 - acc: 0.8628Epoch 00181: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.5370 - acc: 0.8624 - val_loss: 1.4231 - val_acc: 0.5707\n",
      "Epoch 182/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5403 - acc: 0.8614Epoch 00182: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.5425 - acc: 0.8636 - val_loss: 1.3756 - val_acc: 0.6061\n",
      "Epoch 183/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5169 - acc: 0.8628Epoch 00183: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.5078 - acc: 0.8662 - val_loss: 1.3542 - val_acc: 0.6111\n",
      "Epoch 184/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5078 - acc: 0.8641Epoch 00184: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.5216 - acc: 0.8611 - val_loss: 1.4155 - val_acc: 0.5758\n",
      "Epoch 185/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5322 - acc: 0.8478Epoch 00185: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.5225 - acc: 0.8523 - val_loss: 1.4214 - val_acc: 0.6111\n",
      "Epoch 186/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5216 - acc: 0.8614Epoch 00186: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.5249 - acc: 0.8598 - val_loss: 1.3840 - val_acc: 0.6212\n",
      "Epoch 187/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5060 - acc: 0.8601Epoch 00187: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 0.5001 - acc: 0.8624 - val_loss: 1.4354 - val_acc: 0.5960\n",
      "Epoch 188/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5343 - acc: 0.8546Epoch 00188: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.5299 - acc: 0.8586 - val_loss: 1.3794 - val_acc: 0.6162\n",
      "Epoch 189/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5097 - acc: 0.8519Epoch 00189: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.5039 - acc: 0.8561 - val_loss: 1.4110 - val_acc: 0.5707\n",
      "Epoch 190/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5219 - acc: 0.8628Epoch 00190: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.5072 - acc: 0.8699 - val_loss: 1.4107 - val_acc: 0.6061\n",
      "Epoch 191/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4851 - acc: 0.8709Epoch 00191: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.4900 - acc: 0.8725 - val_loss: 1.4218 - val_acc: 0.5808\n",
      "Epoch 192/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4517 - acc: 0.8872Epoch 00192: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.4438 - acc: 0.8927 - val_loss: 1.4440 - val_acc: 0.5808\n",
      "Epoch 193/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4880 - acc: 0.8872Epoch 00193: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.4773 - acc: 0.8914 - val_loss: 1.4292 - val_acc: 0.6212\n",
      "Epoch 194/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4925 - acc: 0.8655Epoch 00194: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.4796 - acc: 0.8712 - val_loss: 1.4267 - val_acc: 0.6061\n",
      "Epoch 195/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4842 - acc: 0.8764Epoch 00195: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.4967 - acc: 0.8750 - val_loss: 1.4412 - val_acc: 0.5909\n",
      "Epoch 196/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4731 - acc: 0.8845Epoch 00196: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.4667 - acc: 0.8864 - val_loss: 1.4549 - val_acc: 0.5859\n",
      "Epoch 197/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5063 - acc: 0.8709Epoch 00197: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.5062 - acc: 0.8699 - val_loss: 1.4325 - val_acc: 0.5909\n",
      "Epoch 198/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4351 - acc: 0.8845Epoch 00198: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.4610 - acc: 0.8737 - val_loss: 1.4044 - val_acc: 0.6061\n",
      "Epoch 199/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5171 - acc: 0.8655Epoch 00199: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.5133 - acc: 0.8636 - val_loss: 1.3589 - val_acc: 0.6010\n",
      "Epoch 200/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4342 - acc: 0.8927Epoch 00200: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.4367 - acc: 0.8889 - val_loss: 1.4640 - val_acc: 0.5859\n",
      "Epoch 201/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4651 - acc: 0.8655Epoch 00201: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.4617 - acc: 0.8636 - val_loss: 1.3815 - val_acc: 0.6263\n",
      "Epoch 202/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4492 - acc: 0.8804Epoch 00202: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.4524 - acc: 0.8788 - val_loss: 1.4348 - val_acc: 0.5808\n",
      "Epoch 203/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4893 - acc: 0.8587Epoch 00203: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.5013 - acc: 0.8548 - val_loss: 1.4332 - val_acc: 0.5707\n",
      "Epoch 204/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4949 - acc: 0.8655Epoch 00204: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.4816 - acc: 0.8687 - val_loss: 1.4071 - val_acc: 0.6162\n",
      "Epoch 205/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4814 - acc: 0.8709Epoch 00205: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.4757 - acc: 0.8737 - val_loss: 1.4206 - val_acc: 0.6212\n",
      "Epoch 206/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5001 - acc: 0.8573Epoch 00206: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.5040 - acc: 0.8535 - val_loss: 1.3922 - val_acc: 0.6162\n",
      "Epoch 207/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4523 - acc: 0.8777Epoch 00207: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.4455 - acc: 0.8813 - val_loss: 1.4276 - val_acc: 0.6414\n",
      "Epoch 208/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4609 - acc: 0.8791Epoch 00208: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.4622 - acc: 0.8763 - val_loss: 1.3938 - val_acc: 0.6263\n",
      "Epoch 209/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4475 - acc: 0.8832Epoch 00209: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.4469 - acc: 0.8826 - val_loss: 1.4992 - val_acc: 0.6061\n",
      "Epoch 210/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4439 - acc: 0.8859Epoch 00210: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.4468 - acc: 0.8851 - val_loss: 1.3915 - val_acc: 0.6010\n",
      "Epoch 211/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4815 - acc: 0.8723Epoch 00211: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.4926 - acc: 0.8674 - val_loss: 1.4774 - val_acc: 0.5657\n",
      "Epoch 212/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4722 - acc: 0.8696Epoch 00212: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.4824 - acc: 0.8636 - val_loss: 1.3831 - val_acc: 0.6162\n",
      "Epoch 213/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4535 - acc: 0.8682Epoch 00213: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.4755 - acc: 0.8573 - val_loss: 1.4200 - val_acc: 0.6263\n",
      "Epoch 214/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4404 - acc: 0.8777Epoch 00214: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.4401 - acc: 0.8775 - val_loss: 1.4367 - val_acc: 0.5808\n",
      "Epoch 215/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4748 - acc: 0.8628Epoch 00215: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.4725 - acc: 0.8636 - val_loss: 1.4311 - val_acc: 0.6212\n",
      "Epoch 216/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4321 - acc: 0.8872Epoch 00216: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.4414 - acc: 0.8826 - val_loss: 1.4196 - val_acc: 0.6162\n",
      "Epoch 217/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4341 - acc: 0.8845Epoch 00217: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.4439 - acc: 0.8801 - val_loss: 1.3560 - val_acc: 0.6212\n",
      "Epoch 218/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4499 - acc: 0.8818Epoch 00218: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.4434 - acc: 0.8851 - val_loss: 1.4712 - val_acc: 0.6010\n",
      "Epoch 219/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4240 - acc: 0.8927Epoch 00219: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 0.4173 - acc: 0.8952 - val_loss: 1.4523 - val_acc: 0.6061\n",
      "Epoch 220/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4956 - acc: 0.8546Epoch 00220: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.4853 - acc: 0.8598 - val_loss: 1.4362 - val_acc: 0.6010\n",
      "Epoch 221/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4235 - acc: 0.8967Epoch 00221: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.4310 - acc: 0.8939 - val_loss: 1.4129 - val_acc: 0.6212\n",
      "Epoch 222/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4142 - acc: 0.8940Epoch 00222: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.4175 - acc: 0.8914 - val_loss: 1.4505 - val_acc: 0.5960\n",
      "Epoch 223/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4409 - acc: 0.8818Epoch 00223: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.4471 - acc: 0.8775 - val_loss: 1.5023 - val_acc: 0.5606\n",
      "Epoch 224/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4331 - acc: 0.8804Epoch 00224: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.4349 - acc: 0.8813 - val_loss: 1.4692 - val_acc: 0.6061\n",
      "Epoch 225/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4103 - acc: 0.8967Epoch 00225: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.4244 - acc: 0.8939 - val_loss: 1.5153 - val_acc: 0.5859\n",
      "Epoch 226/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4067 - acc: 0.8995Epoch 00226: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.4105 - acc: 0.8990 - val_loss: 1.4434 - val_acc: 0.6111\n",
      "Epoch 227/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3813 - acc: 0.9008Epoch 00227: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.3946 - acc: 0.8990 - val_loss: 1.4754 - val_acc: 0.6061\n",
      "Epoch 228/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4285 - acc: 0.8872Epoch 00228: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.4243 - acc: 0.8914 - val_loss: 1.4293 - val_acc: 0.5960\n",
      "Epoch 229/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4602 - acc: 0.8709Epoch 00229: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.4536 - acc: 0.8763 - val_loss: 1.4890 - val_acc: 0.6010\n",
      "Epoch 230/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4220 - acc: 0.8967Epoch 00230: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.4142 - acc: 0.9003 - val_loss: 1.4733 - val_acc: 0.6162\n",
      "Epoch 231/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4062 - acc: 0.8913Epoch 00231: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.4113 - acc: 0.8902 - val_loss: 1.4527 - val_acc: 0.6263\n",
      "Epoch 232/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4040 - acc: 0.8845Epoch 00232: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.4012 - acc: 0.8876 - val_loss: 1.4468 - val_acc: 0.6061\n",
      "Epoch 233/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4219 - acc: 0.8818Epoch 00233: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.4178 - acc: 0.8838 - val_loss: 1.4782 - val_acc: 0.5859\n",
      "Epoch 234/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4156 - acc: 0.8913Epoch 00234: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.4087 - acc: 0.8939 - val_loss: 1.4199 - val_acc: 0.6263\n",
      "Epoch 235/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4053 - acc: 0.8940Epoch 00235: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3983 - acc: 0.8977 - val_loss: 1.4921 - val_acc: 0.6111\n",
      "Epoch 236/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4261 - acc: 0.8859Epoch 00236: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.4258 - acc: 0.8851 - val_loss: 1.4813 - val_acc: 0.6162\n",
      "Epoch 237/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4569 - acc: 0.8682Epoch 00237: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.4609 - acc: 0.8674 - val_loss: 1.4282 - val_acc: 0.6212\n",
      "Epoch 238/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4103 - acc: 0.8940Epoch 00238: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.4037 - acc: 0.8965 - val_loss: 1.4629 - val_acc: 0.6162\n",
      "Epoch 239/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4802 - acc: 0.8723Epoch 00239: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.4732 - acc: 0.8712 - val_loss: 1.4934 - val_acc: 0.5960\n",
      "Epoch 240/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4284 - acc: 0.8913Epoch 00240: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.4287 - acc: 0.8902 - val_loss: 1.4231 - val_acc: 0.5960\n",
      "Epoch 241/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4088 - acc: 0.8845Epoch 00241: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.4137 - acc: 0.8851 - val_loss: 1.4613 - val_acc: 0.5909\n",
      "Epoch 242/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3883 - acc: 0.8940Epoch 00242: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.3845 - acc: 0.8965 - val_loss: 1.4564 - val_acc: 0.6111\n",
      "Epoch 243/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4001 - acc: 0.8954Epoch 00243: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.3967 - acc: 0.8952 - val_loss: 1.4823 - val_acc: 0.6111\n",
      "Epoch 244/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3685 - acc: 0.9062Epoch 00244: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.3705 - acc: 0.9066 - val_loss: 1.4705 - val_acc: 0.6010\n",
      "Epoch 245/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3929 - acc: 0.9076Epoch 00245: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.3971 - acc: 0.9028 - val_loss: 1.4712 - val_acc: 0.6162\n",
      "Epoch 246/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3753 - acc: 0.9076Epoch 00246: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.3746 - acc: 0.9091 - val_loss: 1.4194 - val_acc: 0.6313\n",
      "Epoch 247/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3679 - acc: 0.8954Epoch 00247: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.3685 - acc: 0.8914 - val_loss: 1.4799 - val_acc: 0.6313\n",
      "Epoch 248/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4035 - acc: 0.8927Epoch 00248: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.3971 - acc: 0.8952 - val_loss: 1.4375 - val_acc: 0.6364\n",
      "Epoch 249/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3951 - acc: 0.9090Epoch 00249: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.3882 - acc: 0.9104 - val_loss: 1.4527 - val_acc: 0.6212\n",
      "Epoch 250/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4245 - acc: 0.8859Epoch 00250: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.4215 - acc: 0.8889 - val_loss: 1.4751 - val_acc: 0.6313\n",
      "Epoch 251/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3901 - acc: 0.8954Epoch 00251: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.3929 - acc: 0.8939 - val_loss: 1.4694 - val_acc: 0.6263\n",
      "Epoch 252/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4088 - acc: 0.8832Epoch 00252: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.4101 - acc: 0.8813 - val_loss: 1.4722 - val_acc: 0.6364\n",
      "Epoch 253/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3792 - acc: 0.9049Epoch 00253: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.3840 - acc: 0.9015 - val_loss: 1.5167 - val_acc: 0.6111\n",
      "Epoch 254/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3050 - acc: 0.9361Epoch 00254: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.3044 - acc: 0.9356 - val_loss: 1.5049 - val_acc: 0.6010\n",
      "Epoch 255/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3851 - acc: 0.9090Epoch 00255: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3835 - acc: 0.9091 - val_loss: 1.4950 - val_acc: 0.6212\n",
      "Epoch 256/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3589 - acc: 0.9022Epoch 00256: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.3645 - acc: 0.9003 - val_loss: 1.5362 - val_acc: 0.6111\n",
      "Epoch 257/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3593 - acc: 0.9022Epoch 00257: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.3643 - acc: 0.9015 - val_loss: 1.4861 - val_acc: 0.6111\n",
      "Epoch 258/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3723 - acc: 0.9008- ETA: 0s - loss: 0.3841 - accEpoch 00258: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.3732 - acc: 0.9003 - val_loss: 1.4925 - val_acc: 0.6111\n",
      "Epoch 259/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3609 - acc: 0.9090Epoch 00259: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.3598 - acc: 0.9104 - val_loss: 1.4843 - val_acc: 0.6212\n",
      "Epoch 260/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3642 - acc: 0.9008Epoch 00260: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.3644 - acc: 0.9015 - val_loss: 1.4900 - val_acc: 0.6111\n",
      "Epoch 261/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3672 - acc: 0.9008Epoch 00261: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3599 - acc: 0.9015 - val_loss: 1.4616 - val_acc: 0.6364\n",
      "Epoch 262/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3364 - acc: 0.9171Epoch 00262: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.3388 - acc: 0.9154 - val_loss: 1.4833 - val_acc: 0.6010\n",
      "Epoch 263/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3791 - acc: 0.9008Epoch 00263: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.3801 - acc: 0.9003 - val_loss: 1.4651 - val_acc: 0.6364\n",
      "Epoch 264/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3372 - acc: 0.9076Epoch 00264: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.3445 - acc: 0.9078 - val_loss: 1.4877 - val_acc: 0.6313\n",
      "Epoch 265/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3859 - acc: 0.9008Epoch 00265: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.3832 - acc: 0.9040 - val_loss: 1.4499 - val_acc: 0.6263\n",
      "Epoch 266/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4032 - acc: 0.8981Epoch 00266: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.4060 - acc: 0.8977 - val_loss: 1.4672 - val_acc: 0.6212\n",
      "Epoch 267/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3461 - acc: 0.9103Epoch 00267: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.3463 - acc: 0.9091 - val_loss: 1.4794 - val_acc: 0.6212\n",
      "Epoch 268/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3526 - acc: 0.9090Epoch 00268: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.3611 - acc: 0.9091 - val_loss: 1.4943 - val_acc: 0.6162\n",
      "Epoch 269/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3685 - acc: 0.8967Epoch 00269: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.3778 - acc: 0.8965 - val_loss: 1.5355 - val_acc: 0.6111\n",
      "Epoch 270/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3669 - acc: 0.9008Epoch 00270: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.3773 - acc: 0.9015 - val_loss: 1.4876 - val_acc: 0.6212\n",
      "Epoch 271/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3513 - acc: 0.9103Epoch 00271: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.3447 - acc: 0.9141 - val_loss: 1.4688 - val_acc: 0.6162\n",
      "Epoch 272/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3671 - acc: 0.9103Epoch 00272: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.3685 - acc: 0.9116 - val_loss: 1.4830 - val_acc: 0.6263\n",
      "Epoch 273/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3471 - acc: 0.9090Epoch 00273: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.3468 - acc: 0.9091 - val_loss: 1.4706 - val_acc: 0.6212\n",
      "Epoch 274/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3577 - acc: 0.9022Epoch 00274: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.3560 - acc: 0.9028 - val_loss: 1.5102 - val_acc: 0.6162\n",
      "Epoch 275/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3510 - acc: 0.9008Epoch 00275: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3593 - acc: 0.8990 - val_loss: 1.5006 - val_acc: 0.6111\n",
      "Epoch 276/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3392 - acc: 0.9022Epoch 00276: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.3360 - acc: 0.9053 - val_loss: 1.4893 - val_acc: 0.6414\n",
      "Epoch 277/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3563 - acc: 0.9103Epoch 00277: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.3571 - acc: 0.9116 - val_loss: 1.4757 - val_acc: 0.6414\n",
      "Epoch 278/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3860 - acc: 0.8791Epoch 00278: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.4026 - acc: 0.8737 - val_loss: 1.4873 - val_acc: 0.6263\n",
      "Epoch 279/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3982 - acc: 0.8995Epoch 00279: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.3996 - acc: 0.8990 - val_loss: 1.5073 - val_acc: 0.6010\n",
      "Epoch 280/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3938 - acc: 0.8899Epoch 00280: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.3900 - acc: 0.8902 - val_loss: 1.5478 - val_acc: 0.6111\n",
      "Epoch 281/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3914 - acc: 0.9008Epoch 00281: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.3965 - acc: 0.8990 - val_loss: 1.5168 - val_acc: 0.5960\n",
      "Epoch 282/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3514 - acc: 0.9144Epoch 00282: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.3623 - acc: 0.9091 - val_loss: 1.4537 - val_acc: 0.6111\n",
      "Epoch 283/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3619 - acc: 0.9062Epoch 00283: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 0.3527 - acc: 0.9091 - val_loss: 1.5037 - val_acc: 0.6061\n",
      "Epoch 284/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3500 - acc: 0.9198Epoch 00284: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.3495 - acc: 0.9205 - val_loss: 1.4709 - val_acc: 0.6212\n",
      "Epoch 285/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4007 - acc: 0.8913Epoch 00285: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.3979 - acc: 0.8876 - val_loss: 1.4683 - val_acc: 0.6111\n",
      "Epoch 286/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3244 - acc: 0.9144Epoch 00286: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.3259 - acc: 0.9154 - val_loss: 1.4810 - val_acc: 0.6010\n",
      "Epoch 287/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3394 - acc: 0.9158Epoch 00287: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.3337 - acc: 0.9167 - val_loss: 1.5101 - val_acc: 0.6111\n",
      "Epoch 288/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3548 - acc: 0.9226Epoch 00288: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3675 - acc: 0.9167 - val_loss: 1.4684 - val_acc: 0.6263\n",
      "Epoch 289/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4163 - acc: 0.8696Epoch 00289: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.4293 - acc: 0.8674 - val_loss: 1.4702 - val_acc: 0.6465\n",
      "Epoch 290/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3248 - acc: 0.9185Epoch 00290: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3220 - acc: 0.9217 - val_loss: 1.5058 - val_acc: 0.6212\n",
      "Epoch 291/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3532 - acc: 0.9158Epoch 00291: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.3499 - acc: 0.9167 - val_loss: 1.5128 - val_acc: 0.6313\n",
      "Epoch 292/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3647 - acc: 0.8940Epoch 00292: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.3732 - acc: 0.8939 - val_loss: 1.6028 - val_acc: 0.6111\n",
      "Epoch 293/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3329 - acc: 0.9049Epoch 00293: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.3275 - acc: 0.9066 - val_loss: 1.5206 - val_acc: 0.6364\n",
      "Epoch 294/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3506 - acc: 0.9171Epoch 00294: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.3476 - acc: 0.9192 - val_loss: 1.4883 - val_acc: 0.6414\n",
      "Epoch 295/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3945 - acc: 0.9103Epoch 00295: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.3926 - acc: 0.9091 - val_loss: 1.5313 - val_acc: 0.6313\n",
      "Epoch 296/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3168 - acc: 0.9226Epoch 00296: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3284 - acc: 0.9217 - val_loss: 1.5078 - val_acc: 0.6465\n",
      "Epoch 297/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3270 - acc: 0.9158Epoch 00297: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.3426 - acc: 0.9104 - val_loss: 1.4870 - val_acc: 0.6212\n",
      "Epoch 298/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3462 - acc: 0.9103Epoch 00298: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.3402 - acc: 0.9104 - val_loss: 1.4715 - val_acc: 0.6414\n",
      "Epoch 299/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3231 - acc: 0.9171Epoch 00299: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.3365 - acc: 0.9154 - val_loss: 1.4876 - val_acc: 0.6263\n",
      "Epoch 300/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3376 - acc: 0.9212Epoch 00300: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.3585 - acc: 0.9129 - val_loss: 1.5403 - val_acc: 0.6010\n",
      "Epoch 301/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3258 - acc: 0.9062Epoch 00301: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.3218 - acc: 0.9104 - val_loss: 1.4685 - val_acc: 0.6263\n",
      "Epoch 302/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3279 - acc: 0.9185Epoch 00302: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.3244 - acc: 0.9205 - val_loss: 1.4992 - val_acc: 0.6313\n",
      "Epoch 303/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3091 - acc: 0.9198Epoch 00303: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 0.3076 - acc: 0.9192 - val_loss: 1.4942 - val_acc: 0.6162\n",
      "Epoch 304/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3207 - acc: 0.9144Epoch 00304: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.3260 - acc: 0.9129 - val_loss: 1.4822 - val_acc: 0.6010\n",
      "Epoch 305/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3060 - acc: 0.9144Epoch 00305: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.3118 - acc: 0.9141 - val_loss: 1.5012 - val_acc: 0.6212\n",
      "Epoch 306/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3029 - acc: 0.9239Epoch 00306: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.3004 - acc: 0.9230 - val_loss: 1.5125 - val_acc: 0.6313\n",
      "Epoch 307/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3566 - acc: 0.8995Epoch 00307: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.3510 - acc: 0.8990 - val_loss: 1.5104 - val_acc: 0.6061\n",
      "Epoch 308/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3394 - acc: 0.9130Epoch 00308: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.3362 - acc: 0.9129 - val_loss: 1.5411 - val_acc: 0.6111\n",
      "Epoch 309/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2931 - acc: 0.9307Epoch 00309: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3005 - acc: 0.9280 - val_loss: 1.4675 - val_acc: 0.6313\n",
      "Epoch 310/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3315 - acc: 0.9090Epoch 00310: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.3184 - acc: 0.9141 - val_loss: 1.4765 - val_acc: 0.6212\n",
      "Epoch 311/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3395 - acc: 0.9049Epoch 00311: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.3412 - acc: 0.9040 - val_loss: 1.5068 - val_acc: 0.6061\n",
      "Epoch 312/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3092 - acc: 0.9158Epoch 00312: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.3099 - acc: 0.9167 - val_loss: 1.4687 - val_acc: 0.6414\n",
      "Epoch 313/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3207 - acc: 0.9144Epoch 00313: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.3243 - acc: 0.9116 - val_loss: 1.4900 - val_acc: 0.6111\n",
      "Epoch 314/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3381 - acc: 0.9008Epoch 00314: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.3399 - acc: 0.9015 - val_loss: 1.4945 - val_acc: 0.6212\n",
      "Epoch 315/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3599 - acc: 0.9103- ETA: 0s - loss: 0.3747 - accEpoch 00315: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.3521 - acc: 0.9141 - val_loss: 1.5104 - val_acc: 0.6263\n",
      "Epoch 316/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3224 - acc: 0.9171Epoch 00316: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.3204 - acc: 0.9192 - val_loss: 1.4981 - val_acc: 0.6465\n",
      "Epoch 317/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3388 - acc: 0.9144Epoch 00317: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.3280 - acc: 0.9179 - val_loss: 1.5409 - val_acc: 0.6212\n",
      "Epoch 318/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3238 - acc: 0.9171Epoch 00318: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.3252 - acc: 0.9154 - val_loss: 1.5133 - val_acc: 0.6010\n",
      "Epoch 319/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3502 - acc: 0.9103Epoch 00319: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.3498 - acc: 0.9078 - val_loss: 1.4805 - val_acc: 0.6162\n",
      "Epoch 320/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3355 - acc: 0.9130Epoch 00320: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.3391 - acc: 0.9116 - val_loss: 1.5002 - val_acc: 0.6364\n",
      "Epoch 321/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3187 - acc: 0.9144Epoch 00321: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.3222 - acc: 0.9116 - val_loss: 1.5028 - val_acc: 0.6364\n",
      "Epoch 322/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3375 - acc: 0.9076Epoch 00322: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.3331 - acc: 0.9078 - val_loss: 1.4769 - val_acc: 0.6263\n",
      "Epoch 323/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3185 - acc: 0.9226Epoch 00323: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.3150 - acc: 0.9255 - val_loss: 1.5134 - val_acc: 0.6162\n",
      "Epoch 324/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3511 - acc: 0.8967Epoch 00324: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.3438 - acc: 0.8977 - val_loss: 1.4841 - val_acc: 0.6364\n",
      "Epoch 325/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3245 - acc: 0.9171Epoch 00325: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.3176 - acc: 0.9205 - val_loss: 1.5132 - val_acc: 0.6414\n",
      "Epoch 326/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2845 - acc: 0.9266Epoch 00326: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.2892 - acc: 0.9268 - val_loss: 1.4849 - val_acc: 0.6414\n",
      "Epoch 327/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3383 - acc: 0.9117Epoch 00327: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.3459 - acc: 0.9104 - val_loss: 1.4843 - val_acc: 0.6364\n",
      "Epoch 328/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3010 - acc: 0.9239Epoch 00328: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.2998 - acc: 0.9230 - val_loss: 1.4921 - val_acc: 0.6364\n",
      "Epoch 329/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2937 - acc: 0.9226Epoch 00329: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.2919 - acc: 0.9242 - val_loss: 1.4524 - val_acc: 0.6364\n",
      "Epoch 330/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2870 - acc: 0.9361Epoch 00330: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2937 - acc: 0.9331 - val_loss: 1.5161 - val_acc: 0.6162\n",
      "Epoch 331/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3126 - acc: 0.9348Epoch 00331: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.3024 - acc: 0.9369 - val_loss: 1.5353 - val_acc: 0.6111\n",
      "Epoch 332/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3062 - acc: 0.9198Epoch 00332: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.3020 - acc: 0.9205 - val_loss: 1.6127 - val_acc: 0.5960\n",
      "Epoch 333/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3020 - acc: 0.9171Epoch 00333: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.3051 - acc: 0.9116 - val_loss: 1.5352 - val_acc: 0.6111\n",
      "Epoch 334/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3057 - acc: 0.9171Epoch 00334: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.3096 - acc: 0.9154 - val_loss: 1.4957 - val_acc: 0.6263\n",
      "Epoch 335/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3047 - acc: 0.9130Epoch 00335: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.2968 - acc: 0.9141 - val_loss: 1.5650 - val_acc: 0.6263\n",
      "Epoch 336/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2972 - acc: 0.9266Epoch 00336: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.3004 - acc: 0.9280 - val_loss: 1.5191 - val_acc: 0.6061\n",
      "Epoch 337/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3160 - acc: 0.9144Epoch 00337: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.3195 - acc: 0.9141 - val_loss: 1.5454 - val_acc: 0.6111\n",
      "Epoch 338/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3420 - acc: 0.9185Epoch 00338: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3456 - acc: 0.9154 - val_loss: 1.5380 - val_acc: 0.6162\n",
      "Epoch 339/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3068 - acc: 0.9198Epoch 00339: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 0.3164 - acc: 0.9179 - val_loss: 1.5125 - val_acc: 0.6061\n",
      "Epoch 340/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3179 - acc: 0.9171Epoch 00340: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3091 - acc: 0.9205 - val_loss: 1.5491 - val_acc: 0.6111\n",
      "Epoch 341/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3275 - acc: 0.9198Epoch 00341: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.3257 - acc: 0.9205 - val_loss: 1.5292 - val_acc: 0.6061\n",
      "Epoch 342/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2517 - acc: 0.9416Epoch 00342: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.2589 - acc: 0.9407 - val_loss: 1.4804 - val_acc: 0.6061\n",
      "Epoch 343/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2847 - acc: 0.9226Epoch 00343: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2908 - acc: 0.9217 - val_loss: 1.5512 - val_acc: 0.6111\n",
      "Epoch 344/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3533 - acc: 0.9022Epoch 00344: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.3476 - acc: 0.9040 - val_loss: 1.5633 - val_acc: 0.6061\n",
      "Epoch 345/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3094 - acc: 0.9185Epoch 00345: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.3041 - acc: 0.9205 - val_loss: 1.5308 - val_acc: 0.6212\n",
      "Epoch 346/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3368 - acc: 0.9090Epoch 00346: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.3374 - acc: 0.9104 - val_loss: 1.5142 - val_acc: 0.6162\n",
      "Epoch 347/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2890 - acc: 0.9212Epoch 00347: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.2835 - acc: 0.9217 - val_loss: 1.5426 - val_acc: 0.6162\n",
      "Epoch 348/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2757 - acc: 0.9307Epoch 00348: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2848 - acc: 0.9280 - val_loss: 1.5490 - val_acc: 0.6364\n",
      "Epoch 349/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2772 - acc: 0.9280Epoch 00349: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.2818 - acc: 0.9280 - val_loss: 1.5210 - val_acc: 0.6111\n",
      "Epoch 350/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3167 - acc: 0.9212Epoch 00350: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.3074 - acc: 0.9255 - val_loss: 1.4961 - val_acc: 0.6566\n",
      "Epoch 351/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2822 - acc: 0.9321Epoch 00351: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2909 - acc: 0.9280 - val_loss: 1.5586 - val_acc: 0.6313\n",
      "Epoch 352/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3049 - acc: 0.9185Epoch 00352: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.3078 - acc: 0.9154 - val_loss: 1.5161 - val_acc: 0.6414\n",
      "Epoch 353/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3051 - acc: 0.9171Epoch 00353: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.3197 - acc: 0.9129 - val_loss: 1.5880 - val_acc: 0.6212\n",
      "Epoch 354/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2951 - acc: 0.9226Epoch 00354: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2957 - acc: 0.9242 - val_loss: 1.5331 - val_acc: 0.6212\n",
      "Epoch 355/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2967 - acc: 0.9198Epoch 00355: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2967 - acc: 0.9192 - val_loss: 1.5772 - val_acc: 0.6263\n",
      "Epoch 356/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2845 - acc: 0.9185Epoch 00356: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2877 - acc: 0.9192 - val_loss: 1.5076 - val_acc: 0.6263\n",
      "Epoch 357/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3111 - acc: 0.9076Epoch 00357: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.3102 - acc: 0.9066 - val_loss: 1.5015 - val_acc: 0.6061\n",
      "Epoch 358/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3130 - acc: 0.9130Epoch 00358: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.3078 - acc: 0.9154 - val_loss: 1.5380 - val_acc: 0.6212\n",
      "Epoch 359/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2484 - acc: 0.9280Epoch 00359: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2428 - acc: 0.9306 - val_loss: 1.5233 - val_acc: 0.6111\n",
      "Epoch 360/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2737 - acc: 0.9375Epoch 00360: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.2786 - acc: 0.9306 - val_loss: 1.5191 - val_acc: 0.6263\n",
      "Epoch 361/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3280 - acc: 0.9171Epoch 00361: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 0.3255 - acc: 0.9179 - val_loss: 1.6016 - val_acc: 0.6111\n",
      "Epoch 362/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2817 - acc: 0.9293Epoch 00362: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.2902 - acc: 0.9255 - val_loss: 1.5485 - val_acc: 0.6111\n",
      "Epoch 363/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2639 - acc: 0.9348Epoch 00363: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.2673 - acc: 0.9318 - val_loss: 1.5587 - val_acc: 0.5909\n",
      "Epoch 364/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2759 - acc: 0.9321Epoch 00364: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2810 - acc: 0.9293 - val_loss: 1.5997 - val_acc: 0.6111\n",
      "Epoch 365/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2781 - acc: 0.9226Epoch 00365: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.2854 - acc: 0.9179 - val_loss: 1.5733 - val_acc: 0.6010\n",
      "Epoch 366/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2946 - acc: 0.9253Epoch 00366: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2933 - acc: 0.9268 - val_loss: 1.5572 - val_acc: 0.5909\n",
      "Epoch 367/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2831 - acc: 0.9171Epoch 00367: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2854 - acc: 0.9192 - val_loss: 1.5524 - val_acc: 0.6212\n",
      "Epoch 368/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2748 - acc: 0.9334Epoch 00368: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.2702 - acc: 0.9331 - val_loss: 1.5300 - val_acc: 0.6465\n",
      "Epoch 369/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2586 - acc: 0.9361Epoch 00369: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.2517 - acc: 0.9407 - val_loss: 1.6016 - val_acc: 0.6111\n",
      "Epoch 370/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2578 - acc: 0.9402Epoch 00370: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.2655 - acc: 0.9381 - val_loss: 1.6124 - val_acc: 0.6010\n",
      "Epoch 371/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3164 - acc: 0.9185Epoch 00371: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.3087 - acc: 0.9217 - val_loss: 1.6597 - val_acc: 0.6010\n",
      "Epoch 372/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2948 - acc: 0.9293Epoch 00372: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.2958 - acc: 0.9280 - val_loss: 1.5786 - val_acc: 0.6111\n",
      "Epoch 373/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3317 - acc: 0.9008Epoch 00373: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.3312 - acc: 0.9015 - val_loss: 1.5834 - val_acc: 0.6313\n",
      "Epoch 374/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2970 - acc: 0.9185Epoch 00374: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.2927 - acc: 0.9205 - val_loss: 1.5897 - val_acc: 0.6212\n",
      "Epoch 375/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3032 - acc: 0.9185Epoch 00375: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.3013 - acc: 0.9167 - val_loss: 1.6114 - val_acc: 0.6010\n",
      "Epoch 376/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2914 - acc: 0.9185Epoch 00376: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.2899 - acc: 0.9192 - val_loss: 1.5505 - val_acc: 0.5859\n",
      "Epoch 377/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2869 - acc: 0.9171Epoch 00377: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.2865 - acc: 0.9179 - val_loss: 1.5341 - val_acc: 0.6263\n",
      "Epoch 378/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2905 - acc: 0.9226Epoch 00378: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.2890 - acc: 0.9255 - val_loss: 1.5493 - val_acc: 0.6061\n",
      "Epoch 379/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2851 - acc: 0.9239Epoch 00379: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 0.2793 - acc: 0.9255 - val_loss: 1.5672 - val_acc: 0.6263\n",
      "Epoch 380/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2539 - acc: 0.9348Epoch 00380: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 0.2582 - acc: 0.9343 - val_loss: 1.6218 - val_acc: 0.5859\n",
      "Epoch 381/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2959 - acc: 0.9239Epoch 00381: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.2979 - acc: 0.9217 - val_loss: 1.5383 - val_acc: 0.6313\n",
      "Epoch 382/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2580 - acc: 0.9375Epoch 00382: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.2662 - acc: 0.9343 - val_loss: 1.5386 - val_acc: 0.6061\n",
      "Epoch 383/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2855 - acc: 0.9198Epoch 00383: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 0.2910 - acc: 0.9179 - val_loss: 1.5624 - val_acc: 0.6313\n",
      "Epoch 384/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2805 - acc: 0.9212Epoch 00384: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.2790 - acc: 0.9230 - val_loss: 1.5368 - val_acc: 0.6212\n",
      "Epoch 385/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2807 - acc: 0.9253Epoch 00385: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.2861 - acc: 0.9242 - val_loss: 1.6355 - val_acc: 0.5606\n",
      "Epoch 386/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2573 - acc: 0.9361Epoch 00386: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.2613 - acc: 0.9356 - val_loss: 1.5657 - val_acc: 0.6061\n",
      "Epoch 387/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2881 - acc: 0.9226Epoch 00387: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.2849 - acc: 0.9242 - val_loss: 1.5503 - val_acc: 0.6212\n",
      "Epoch 388/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2503 - acc: 0.9266Epoch 00388: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.2516 - acc: 0.9268 - val_loss: 1.5430 - val_acc: 0.6364\n",
      "Epoch 389/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2546 - acc: 0.9280Epoch 00389: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 0.2449 - acc: 0.9318 - val_loss: 1.5717 - val_acc: 0.6212\n",
      "Epoch 390/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2834 - acc: 0.9212Epoch 00390: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 0.2856 - acc: 0.9167 - val_loss: 1.5510 - val_acc: 0.6111\n",
      "Epoch 391/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2574 - acc: 0.9389Epoch 00391: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 0.2651 - acc: 0.9369 - val_loss: 1.5567 - val_acc: 0.6263\n",
      "Epoch 392/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2769 - acc: 0.9307Epoch 00392: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 0.2708 - acc: 0.9318 - val_loss: 1.5570 - val_acc: 0.6162\n",
      "Epoch 393/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2480 - acc: 0.9375Epoch 00393: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2478 - acc: 0.9369 - val_loss: 1.5751 - val_acc: 0.6162\n",
      "Epoch 394/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3123 - acc: 0.9008Epoch 00394: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.3012 - acc: 0.9040 - val_loss: 1.5086 - val_acc: 0.6364\n",
      "Epoch 395/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2708 - acc: 0.9253Epoch 00395: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2769 - acc: 0.9230 - val_loss: 1.4948 - val_acc: 0.6414\n",
      "Epoch 396/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2702 - acc: 0.9334Epoch 00396: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.2729 - acc: 0.9306 - val_loss: 1.5383 - val_acc: 0.6162\n",
      "Epoch 397/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2548 - acc: 0.9416Epoch 00397: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.2518 - acc: 0.9432 - val_loss: 1.5439 - val_acc: 0.6465\n",
      "Epoch 398/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3252 - acc: 0.9022Epoch 00398: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.3196 - acc: 0.9066 - val_loss: 1.6223 - val_acc: 0.5909\n",
      "Epoch 399/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3045 - acc: 0.9171Epoch 00399: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.3106 - acc: 0.9129 - val_loss: 1.5716 - val_acc: 0.6162\n",
      "Epoch 400/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2883 - acc: 0.9239Epoch 00400: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2853 - acc: 0.9230 - val_loss: 1.6312 - val_acc: 0.5859\n",
      "Epoch 401/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2713 - acc: 0.9266Epoch 00401: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.2736 - acc: 0.9242 - val_loss: 1.6081 - val_acc: 0.6162\n",
      "Epoch 402/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2649 - acc: 0.9293Epoch 00402: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2539 - acc: 0.9331 - val_loss: 1.5515 - val_acc: 0.6263\n",
      "Epoch 403/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2904 - acc: 0.9212Epoch 00403: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.2861 - acc: 0.9217 - val_loss: 1.5233 - val_acc: 0.6465\n",
      "Epoch 404/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2887 - acc: 0.9117Epoch 00404: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.2853 - acc: 0.9129 - val_loss: 1.5698 - val_acc: 0.6313\n",
      "Epoch 405/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2732 - acc: 0.9280Epoch 00405: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.2682 - acc: 0.9280 - val_loss: 1.5749 - val_acc: 0.6263\n",
      "Epoch 406/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2709 - acc: 0.9226Epoch 00406: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.2740 - acc: 0.9230 - val_loss: 1.5332 - val_acc: 0.6212\n",
      "Epoch 407/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2698 - acc: 0.9226Epoch 00407: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.2827 - acc: 0.9217 - val_loss: 1.6169 - val_acc: 0.5859\n",
      "Epoch 408/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2476 - acc: 0.9253Epoch 00408: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 0.2523 - acc: 0.9242 - val_loss: 1.5733 - val_acc: 0.5808\n",
      "Epoch 409/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2617 - acc: 0.9212Epoch 00409: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 0.2680 - acc: 0.9179 - val_loss: 1.6053 - val_acc: 0.6111\n",
      "Epoch 410/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2462 - acc: 0.9416Epoch 00410: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2503 - acc: 0.9419 - val_loss: 1.5345 - val_acc: 0.6212\n",
      "Epoch 411/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2953 - acc: 0.9212Epoch 00411: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.2882 - acc: 0.9230 - val_loss: 1.5696 - val_acc: 0.6212\n",
      "Epoch 412/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2668 - acc: 0.9239Epoch 00412: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.2584 - acc: 0.9280 - val_loss: 1.5197 - val_acc: 0.6111\n",
      "Epoch 413/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2558 - acc: 0.9321Epoch 00413: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.2487 - acc: 0.9343 - val_loss: 1.5687 - val_acc: 0.6010\n",
      "Epoch 414/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3058 - acc: 0.9158Epoch 00414: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.3115 - acc: 0.9167 - val_loss: 1.5551 - val_acc: 0.6263\n",
      "Epoch 415/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2637 - acc: 0.9375Epoch 00415: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.2643 - acc: 0.9343 - val_loss: 1.5749 - val_acc: 0.6061\n",
      "Epoch 416/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2509 - acc: 0.9334Epoch 00416: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.2540 - acc: 0.9331 - val_loss: 1.5990 - val_acc: 0.6162\n",
      "Epoch 417/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2670 - acc: 0.9239Epoch 00417: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.2659 - acc: 0.9242 - val_loss: 1.5783 - val_acc: 0.6212\n",
      "Epoch 418/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2202 - acc: 0.9457Epoch 00418: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.2311 - acc: 0.9432 - val_loss: 1.5735 - val_acc: 0.6111\n",
      "Epoch 419/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2991 - acc: 0.9226Epoch 00419: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.2949 - acc: 0.9242 - val_loss: 1.5358 - val_acc: 0.6010\n",
      "Epoch 420/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2479 - acc: 0.9389Epoch 00420: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.2488 - acc: 0.9381 - val_loss: 1.5268 - val_acc: 0.6061\n",
      "Epoch 421/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2290 - acc: 0.9457Epoch 00421: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.2314 - acc: 0.9457 - val_loss: 1.5813 - val_acc: 0.6111\n",
      "Epoch 422/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2569 - acc: 0.9307Epoch 00422: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.2575 - acc: 0.9293 - val_loss: 1.5401 - val_acc: 0.6313\n",
      "Epoch 423/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2413 - acc: 0.9389Epoch 00423: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.2498 - acc: 0.9381 - val_loss: 1.6155 - val_acc: 0.6061\n",
      "Epoch 424/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2498 - acc: 0.9375Epoch 00424: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.2466 - acc: 0.9394 - val_loss: 1.5054 - val_acc: 0.6212\n",
      "Epoch 425/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2638 - acc: 0.9307Epoch 00425: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2624 - acc: 0.9293 - val_loss: 1.5346 - val_acc: 0.6263\n",
      "Epoch 426/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2820 - acc: 0.9158Epoch 00426: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2791 - acc: 0.9192 - val_loss: 1.5105 - val_acc: 0.6465\n",
      "Epoch 427/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2762 - acc: 0.9253Epoch 00427: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2683 - acc: 0.9268 - val_loss: 1.5370 - val_acc: 0.6111\n",
      "Epoch 428/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2520 - acc: 0.9239Epoch 00428: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.2495 - acc: 0.9280 - val_loss: 1.6048 - val_acc: 0.6162\n",
      "Epoch 429/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2676 - acc: 0.9239Epoch 00429: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.2586 - acc: 0.9280 - val_loss: 1.5462 - val_acc: 0.5960\n",
      "Epoch 430/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2600 - acc: 0.9307Epoch 00430: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.2615 - acc: 0.9306 - val_loss: 1.5180 - val_acc: 0.6364\n",
      "Epoch 431/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2405 - acc: 0.9457Epoch 00431: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.2425 - acc: 0.9444 - val_loss: 1.5860 - val_acc: 0.6212\n",
      "Epoch 432/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2723 - acc: 0.9185Epoch 00432: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.2946 - acc: 0.9091 - val_loss: 1.5555 - val_acc: 0.6263\n",
      "Epoch 433/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2694 - acc: 0.9375Epoch 00433: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2661 - acc: 0.9381 - val_loss: 1.5481 - val_acc: 0.6263\n",
      "Epoch 434/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2406 - acc: 0.9348Epoch 00434: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.2386 - acc: 0.9356 - val_loss: 1.5901 - val_acc: 0.6313\n",
      "Epoch 435/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2689 - acc: 0.9212Epoch 00435: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.2653 - acc: 0.9217 - val_loss: 1.5983 - val_acc: 0.5909\n",
      "Epoch 436/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2495 - acc: 0.9361Epoch 00436: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2575 - acc: 0.9331 - val_loss: 1.5973 - val_acc: 0.5859\n",
      "Epoch 437/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2492 - acc: 0.9280Epoch 00437: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.2488 - acc: 0.9268 - val_loss: 1.6172 - val_acc: 0.6111\n",
      "Epoch 438/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2784 - acc: 0.9171Epoch 00438: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.2795 - acc: 0.9154 - val_loss: 1.6152 - val_acc: 0.6162\n",
      "Epoch 439/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2551 - acc: 0.9361Epoch 00439: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.2506 - acc: 0.9394 - val_loss: 1.5660 - val_acc: 0.6162\n",
      "Epoch 440/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2659 - acc: 0.9361Epoch 00440: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.2633 - acc: 0.9343 - val_loss: 1.6359 - val_acc: 0.6061\n",
      "Epoch 441/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2869 - acc: 0.9185Epoch 00441: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 0.2836 - acc: 0.9230 - val_loss: 1.5752 - val_acc: 0.6212\n",
      "Epoch 442/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2333 - acc: 0.9402Epoch 00442: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.2320 - acc: 0.9407 - val_loss: 1.5730 - val_acc: 0.6111\n",
      "Epoch 443/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2599 - acc: 0.9334Epoch 00443: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 0.2539 - acc: 0.9331 - val_loss: 1.5815 - val_acc: 0.6061\n",
      "Epoch 444/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2474 - acc: 0.9457Epoch 00444: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2378 - acc: 0.9470 - val_loss: 1.5570 - val_acc: 0.6162\n",
      "Epoch 445/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2697 - acc: 0.9307Epoch 00445: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.2721 - acc: 0.9318 - val_loss: 1.5775 - val_acc: 0.6313\n",
      "Epoch 446/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2543 - acc: 0.9389Epoch 00446: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.2494 - acc: 0.9407 - val_loss: 1.5787 - val_acc: 0.6263\n",
      "Epoch 447/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2743 - acc: 0.9212Epoch 00447: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 0.2751 - acc: 0.9230 - val_loss: 1.4991 - val_acc: 0.6313\n",
      "Epoch 448/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2530 - acc: 0.9293Epoch 00448: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.2523 - acc: 0.9293 - val_loss: 1.5228 - val_acc: 0.6263\n",
      "Epoch 449/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2298 - acc: 0.9484Epoch 00449: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.2335 - acc: 0.9470 - val_loss: 1.5276 - val_acc: 0.6111\n",
      "Epoch 450/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2597 - acc: 0.9307Epoch 00450: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.2571 - acc: 0.9318 - val_loss: 1.5301 - val_acc: 0.6111\n",
      "Epoch 451/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2511 - acc: 0.9334Epoch 00451: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.2547 - acc: 0.9318 - val_loss: 1.5410 - val_acc: 0.6263\n",
      "Epoch 452/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2560 - acc: 0.9321Epoch 00452: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.2538 - acc: 0.9318 - val_loss: 1.5290 - val_acc: 0.5808\n",
      "Epoch 453/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2625 - acc: 0.9226Epoch 00453: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.2648 - acc: 0.9217 - val_loss: 1.5471 - val_acc: 0.6212\n",
      "Epoch 454/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2427 - acc: 0.9457Epoch 00454: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.2464 - acc: 0.9457 - val_loss: 1.5425 - val_acc: 0.6162\n",
      "Epoch 455/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2511 - acc: 0.9348Epoch 00455: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.2444 - acc: 0.9369 - val_loss: 1.5869 - val_acc: 0.6263\n",
      "Epoch 456/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2449 - acc: 0.9389Epoch 00456: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.2420 - acc: 0.9394 - val_loss: 1.5420 - val_acc: 0.6313\n",
      "Epoch 457/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2536 - acc: 0.9307Epoch 00457: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.2556 - acc: 0.9306 - val_loss: 1.5689 - val_acc: 0.6212\n",
      "Epoch 458/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2451 - acc: 0.9389Epoch 00458: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.2528 - acc: 0.9381 - val_loss: 1.5655 - val_acc: 0.6313\n",
      "Epoch 459/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2137 - acc: 0.9457Epoch 00459: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2114 - acc: 0.9457 - val_loss: 1.5921 - val_acc: 0.6212\n",
      "Epoch 460/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2683 - acc: 0.9307Epoch 00460: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.2596 - acc: 0.9343 - val_loss: 1.5444 - val_acc: 0.5909\n",
      "Epoch 461/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2583 - acc: 0.9348Epoch 00461: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2520 - acc: 0.9369 - val_loss: 1.5943 - val_acc: 0.6111\n",
      "Epoch 462/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2007 - acc: 0.9524Epoch 00462: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.2051 - acc: 0.9508 - val_loss: 1.6471 - val_acc: 0.5758\n",
      "Epoch 463/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2149 - acc: 0.9484Epoch 00463: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2070 - acc: 0.9520 - val_loss: 1.6037 - val_acc: 0.6263\n",
      "Epoch 464/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2349 - acc: 0.9321Epoch 00464: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2369 - acc: 0.9306 - val_loss: 1.5653 - val_acc: 0.6263\n",
      "Epoch 465/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2427 - acc: 0.9470Epoch 00465: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.2389 - acc: 0.9470 - val_loss: 1.6457 - val_acc: 0.5758\n",
      "Epoch 466/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2745 - acc: 0.9212Epoch 00466: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.2836 - acc: 0.9205 - val_loss: 1.5634 - val_acc: 0.6010\n",
      "Epoch 467/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2775 - acc: 0.9253Epoch 00467: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2762 - acc: 0.9255 - val_loss: 1.5903 - val_acc: 0.6313\n",
      "Epoch 468/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2505 - acc: 0.9334Epoch 00468: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.2562 - acc: 0.9343 - val_loss: 1.5359 - val_acc: 0.6364\n",
      "Epoch 469/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2842 - acc: 0.9158Epoch 00469: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2750 - acc: 0.9192 - val_loss: 1.5531 - val_acc: 0.6465\n",
      "Epoch 470/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2279 - acc: 0.9402Epoch 00470: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.2316 - acc: 0.9407 - val_loss: 1.5430 - val_acc: 0.6263\n",
      "Epoch 471/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2370 - acc: 0.9348Epoch 00471: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.2354 - acc: 0.9356 - val_loss: 1.6150 - val_acc: 0.5909\n",
      "Epoch 472/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2497 - acc: 0.9253Epoch 00472: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2428 - acc: 0.9268 - val_loss: 1.5930 - val_acc: 0.6212\n",
      "Epoch 473/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2802 - acc: 0.9280Epoch 00473: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.2729 - acc: 0.9306 - val_loss: 1.5764 - val_acc: 0.6313\n",
      "Epoch 474/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2000 - acc: 0.9443Epoch 00474: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1992 - acc: 0.9457 - val_loss: 1.5517 - val_acc: 0.6111\n",
      "Epoch 475/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2698 - acc: 0.9293Epoch 00475: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.2713 - acc: 0.9280 - val_loss: 1.6408 - val_acc: 0.6061\n",
      "Epoch 476/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2429 - acc: 0.9470Epoch 00476: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.2449 - acc: 0.9470 - val_loss: 1.5972 - val_acc: 0.6263\n",
      "Epoch 477/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2466 - acc: 0.9416Epoch 00477: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.2427 - acc: 0.9444 - val_loss: 1.5828 - val_acc: 0.5960\n",
      "Epoch 478/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2105 - acc: 0.9470Epoch 00478: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2102 - acc: 0.9444 - val_loss: 1.5812 - val_acc: 0.6313\n",
      "Epoch 479/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2208 - acc: 0.9457Epoch 00479: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.2281 - acc: 0.9407 - val_loss: 1.5983 - val_acc: 0.6162\n",
      "Epoch 480/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2398 - acc: 0.9361Epoch 00480: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.2356 - acc: 0.9381 - val_loss: 1.6523 - val_acc: 0.6111\n",
      "Epoch 481/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2417 - acc: 0.9280Epoch 00481: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2424 - acc: 0.9268 - val_loss: 1.5695 - val_acc: 0.6212\n",
      "Epoch 482/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2388 - acc: 0.9375Epoch 00482: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.2427 - acc: 0.9369 - val_loss: 1.6060 - val_acc: 0.6162\n",
      "Epoch 483/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2446 - acc: 0.9334Epoch 00483: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.2399 - acc: 0.9356 - val_loss: 1.5823 - val_acc: 0.6364\n",
      "Epoch 484/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2183 - acc: 0.9389Epoch 00484: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.2257 - acc: 0.9343 - val_loss: 1.5533 - val_acc: 0.6263\n",
      "Epoch 485/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2256 - acc: 0.9389Epoch 00485: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.2221 - acc: 0.9394 - val_loss: 1.5628 - val_acc: 0.6414\n",
      "Epoch 486/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2443 - acc: 0.9307Epoch 00486: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2487 - acc: 0.9280 - val_loss: 1.5926 - val_acc: 0.6364\n",
      "Epoch 487/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2276 - acc: 0.9389Epoch 00487: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.2305 - acc: 0.9394 - val_loss: 1.5409 - val_acc: 0.6414\n",
      "Epoch 488/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2488 - acc: 0.9402Epoch 00488: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.2493 - acc: 0.9394 - val_loss: 1.5633 - val_acc: 0.6111\n",
      "Epoch 489/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2156 - acc: 0.9429Epoch 00489: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.2205 - acc: 0.9419 - val_loss: 1.5842 - val_acc: 0.6111\n",
      "Epoch 490/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2578 - acc: 0.9280Epoch 00490: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.2577 - acc: 0.9280 - val_loss: 1.5506 - val_acc: 0.6263\n",
      "Epoch 491/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2223 - acc: 0.9524Epoch 00491: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.2200 - acc: 0.9533 - val_loss: 1.5202 - val_acc: 0.6263\n",
      "Epoch 492/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2089 - acc: 0.9389Epoch 00492: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.2151 - acc: 0.9356 - val_loss: 1.5434 - val_acc: 0.6263\n",
      "Epoch 493/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2125 - acc: 0.9429Epoch 00493: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.2152 - acc: 0.9444 - val_loss: 1.6187 - val_acc: 0.6212\n",
      "Epoch 494/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2083 - acc: 0.9484Epoch 00494: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.2066 - acc: 0.9482 - val_loss: 1.5509 - val_acc: 0.6566\n",
      "Epoch 495/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1973 - acc: 0.9524Epoch 00495: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.2018 - acc: 0.9508 - val_loss: 1.5976 - val_acc: 0.6313\n",
      "Epoch 496/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2223 - acc: 0.9429Epoch 00496: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.2165 - acc: 0.9444 - val_loss: 1.6205 - val_acc: 0.6313\n",
      "Epoch 497/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2119 - acc: 0.9457Epoch 00497: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.2176 - acc: 0.9419 - val_loss: 1.6752 - val_acc: 0.6010\n",
      "Epoch 498/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2243 - acc: 0.9443Epoch 00498: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.2267 - acc: 0.9419 - val_loss: 1.5663 - val_acc: 0.6212\n",
      "Epoch 499/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2207 - acc: 0.9443Epoch 00499: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.2226 - acc: 0.9432 - val_loss: 1.5668 - val_acc: 0.6111\n",
      "Epoch 500/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2671 - acc: 0.9226Epoch 00500: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.2620 - acc: 0.9268 - val_loss: 1.5436 - val_acc: 0.6364\n",
      "Epoch 501/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2398 - acc: 0.9429Epoch 00501: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.2494 - acc: 0.9394 - val_loss: 1.5653 - val_acc: 0.6313\n",
      "Epoch 502/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2206 - acc: 0.9416Epoch 00502: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.2155 - acc: 0.9432 - val_loss: 1.5509 - val_acc: 0.6212\n",
      "Epoch 503/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2497 - acc: 0.9375Epoch 00503: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.2492 - acc: 0.9343 - val_loss: 1.6470 - val_acc: 0.6162\n",
      "Epoch 504/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2313 - acc: 0.9389Epoch 00504: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.2370 - acc: 0.9369 - val_loss: 1.6265 - val_acc: 0.6162\n",
      "Epoch 505/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2297 - acc: 0.9416Epoch 00505: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.2292 - acc: 0.9394 - val_loss: 1.6279 - val_acc: 0.6111\n",
      "Epoch 506/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2687 - acc: 0.9253Epoch 00506: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2606 - acc: 0.9280 - val_loss: 1.5626 - val_acc: 0.6263\n",
      "Epoch 507/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2077 - acc: 0.9484Epoch 00507: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.2094 - acc: 0.9470 - val_loss: 1.5914 - val_acc: 0.6263\n",
      "Epoch 508/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2282 - acc: 0.9375Epoch 00508: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.2427 - acc: 0.9318 - val_loss: 1.5606 - val_acc: 0.6263\n",
      "Epoch 509/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2011 - acc: 0.9470Epoch 00509: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.2111 - acc: 0.9444 - val_loss: 1.5897 - val_acc: 0.6313\n",
      "Epoch 510/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2172 - acc: 0.9443Epoch 00510: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.2171 - acc: 0.9444 - val_loss: 1.5649 - val_acc: 0.6414\n",
      "Epoch 511/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2471 - acc: 0.9457Epoch 00511: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2512 - acc: 0.9444 - val_loss: 1.5370 - val_acc: 0.6162\n",
      "Epoch 512/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2490 - acc: 0.9389Epoch 00512: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.2449 - acc: 0.9381 - val_loss: 1.5301 - val_acc: 0.6313\n",
      "Epoch 513/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2089 - acc: 0.9457Epoch 00513: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.2139 - acc: 0.9419 - val_loss: 1.6463 - val_acc: 0.6111\n",
      "Epoch 514/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1910 - acc: 0.9565Epoch 00514: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1915 - acc: 0.9571 - val_loss: 1.5930 - val_acc: 0.6162\n",
      "Epoch 515/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2248 - acc: 0.9389Epoch 00515: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.2265 - acc: 0.9381 - val_loss: 1.6065 - val_acc: 0.6162\n",
      "Epoch 516/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2180 - acc: 0.9348Epoch 00516: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.2317 - acc: 0.9318 - val_loss: 1.6061 - val_acc: 0.6111\n",
      "Epoch 517/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2617 - acc: 0.9253Epoch 00517: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.2633 - acc: 0.9242 - val_loss: 1.6484 - val_acc: 0.6061\n",
      "Epoch 518/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2022 - acc: 0.9497Epoch 00518: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.2032 - acc: 0.9482 - val_loss: 1.6418 - val_acc: 0.6111\n",
      "Epoch 519/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2051 - acc: 0.9402Epoch 00519: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.2176 - acc: 0.9381 - val_loss: 1.6923 - val_acc: 0.6111\n",
      "Epoch 520/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2109 - acc: 0.9484Epoch 00520: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.2083 - acc: 0.9495 - val_loss: 1.5916 - val_acc: 0.6313\n",
      "Epoch 521/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2104 - acc: 0.9457Epoch 00521: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.2121 - acc: 0.9444 - val_loss: 1.5728 - val_acc: 0.6313\n",
      "Epoch 522/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2123 - acc: 0.9389Epoch 00522: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2191 - acc: 0.9381 - val_loss: 1.5898 - val_acc: 0.6313\n",
      "Epoch 523/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2262 - acc: 0.9375Epoch 00523: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.2330 - acc: 0.9369 - val_loss: 1.5906 - val_acc: 0.6364\n",
      "Epoch 524/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1933 - acc: 0.9552Epoch 00524: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1913 - acc: 0.9571 - val_loss: 1.5970 - val_acc: 0.6061\n",
      "Epoch 525/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2217 - acc: 0.9348Epoch 00525: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.2170 - acc: 0.9369 - val_loss: 1.5872 - val_acc: 0.6414\n",
      "Epoch 526/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2492 - acc: 0.9253Epoch 00526: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.2426 - acc: 0.9293 - val_loss: 1.5990 - val_acc: 0.6414\n",
      "Epoch 527/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2286 - acc: 0.9361Epoch 00527: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.2253 - acc: 0.9369 - val_loss: 1.6069 - val_acc: 0.6263\n",
      "Epoch 528/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2472 - acc: 0.9402Epoch 00528: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.2466 - acc: 0.9394 - val_loss: 1.6383 - val_acc: 0.6010\n",
      "Epoch 529/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2135 - acc: 0.9484Epoch 00529: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.2240 - acc: 0.9444 - val_loss: 1.5629 - val_acc: 0.6212\n",
      "Epoch 530/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2330 - acc: 0.9389Epoch 00530: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.2374 - acc: 0.9356 - val_loss: 1.5600 - val_acc: 0.6212\n",
      "Epoch 531/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2141 - acc: 0.9429Epoch 00531: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2178 - acc: 0.9432 - val_loss: 1.5625 - val_acc: 0.6111\n",
      "Epoch 532/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2425 - acc: 0.9348Epoch 00532: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.2381 - acc: 0.9343 - val_loss: 1.5768 - val_acc: 0.6313\n",
      "Epoch 533/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2171 - acc: 0.9280Epoch 00533: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.2216 - acc: 0.9268 - val_loss: 1.5478 - val_acc: 0.6313\n",
      "Epoch 534/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2126 - acc: 0.9429Epoch 00534: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.2208 - acc: 0.9381 - val_loss: 1.6025 - val_acc: 0.6010\n",
      "Epoch 535/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2347 - acc: 0.9348Epoch 00535: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.2323 - acc: 0.9369 - val_loss: 1.5662 - val_acc: 0.6111\n",
      "Epoch 536/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2203 - acc: 0.9402Epoch 00536: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.2191 - acc: 0.9419 - val_loss: 1.6048 - val_acc: 0.6010\n",
      "Epoch 537/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2542 - acc: 0.9334Epoch 00537: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.2491 - acc: 0.9356 - val_loss: 1.6008 - val_acc: 0.6061\n",
      "Epoch 538/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2158 - acc: 0.9429Epoch 00538: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.2120 - acc: 0.9457 - val_loss: 1.5942 - val_acc: 0.6061\n",
      "Epoch 539/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2050 - acc: 0.9497Epoch 00539: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2030 - acc: 0.9495 - val_loss: 1.6350 - val_acc: 0.5909\n",
      "Epoch 540/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2263 - acc: 0.9416Epoch 00540: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.2223 - acc: 0.9419 - val_loss: 1.6211 - val_acc: 0.6162\n",
      "Epoch 541/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2048 - acc: 0.9484Epoch 00541: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2031 - acc: 0.9482 - val_loss: 1.6682 - val_acc: 0.6061\n",
      "Epoch 542/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2039 - acc: 0.9552Epoch 00542: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.2013 - acc: 0.9545 - val_loss: 1.6398 - val_acc: 0.5960\n",
      "Epoch 543/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2376 - acc: 0.9307Epoch 00543: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.2368 - acc: 0.9318 - val_loss: 1.6191 - val_acc: 0.6263\n",
      "Epoch 544/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2419 - acc: 0.9348Epoch 00544: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.2438 - acc: 0.9331 - val_loss: 1.6121 - val_acc: 0.6111\n",
      "Epoch 545/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2308 - acc: 0.9402Epoch 00545: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.2254 - acc: 0.9432 - val_loss: 1.5605 - val_acc: 0.6111\n",
      "Epoch 546/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2421 - acc: 0.9334Epoch 00546: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.2392 - acc: 0.9343 - val_loss: 1.6208 - val_acc: 0.6010\n",
      "Epoch 547/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2036 - acc: 0.9429Epoch 00547: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.2009 - acc: 0.9444 - val_loss: 1.6497 - val_acc: 0.6111\n",
      "Epoch 548/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1903 - acc: 0.9552Epoch 00548: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1940 - acc: 0.9545 - val_loss: 1.6174 - val_acc: 0.6061\n",
      "Epoch 549/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2250 - acc: 0.9361Epoch 00549: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2298 - acc: 0.9356 - val_loss: 1.6131 - val_acc: 0.6061\n",
      "Epoch 550/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2218 - acc: 0.9334Epoch 00550: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2171 - acc: 0.9343 - val_loss: 1.6072 - val_acc: 0.6263\n",
      "Epoch 551/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2600 - acc: 0.9389Epoch 00551: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.2550 - acc: 0.9407 - val_loss: 1.6105 - val_acc: 0.6162\n",
      "Epoch 552/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2538 - acc: 0.9253Epoch 00552: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.2555 - acc: 0.9268 - val_loss: 1.6032 - val_acc: 0.6111\n",
      "Epoch 553/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2181 - acc: 0.9348Epoch 00553: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2131 - acc: 0.9369 - val_loss: 1.6671 - val_acc: 0.6061\n",
      "Epoch 554/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1921 - acc: 0.9606Epoch 00554: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1921 - acc: 0.9596 - val_loss: 1.6291 - val_acc: 0.6061\n",
      "Epoch 555/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1741 - acc: 0.9565Epoch 00555: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1776 - acc: 0.9545 - val_loss: 1.5975 - val_acc: 0.5909\n",
      "Epoch 556/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2026 - acc: 0.9429Epoch 00556: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.2066 - acc: 0.9419 - val_loss: 1.5624 - val_acc: 0.6313\n",
      "Epoch 557/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2278 - acc: 0.9389Epoch 00557: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.2233 - acc: 0.9394 - val_loss: 1.5771 - val_acc: 0.6313\n",
      "Epoch 558/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2211 - acc: 0.9497Epoch 00558: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.2175 - acc: 0.9508 - val_loss: 1.6055 - val_acc: 0.6061\n",
      "Epoch 559/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2242 - acc: 0.9334Epoch 00559: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.2291 - acc: 0.9306 - val_loss: 1.5707 - val_acc: 0.6061\n",
      "Epoch 560/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2202 - acc: 0.9429Epoch 00560: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2257 - acc: 0.9394 - val_loss: 1.5513 - val_acc: 0.6364\n",
      "Epoch 561/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2142 - acc: 0.9443Epoch 00561: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.2171 - acc: 0.9432 - val_loss: 1.5961 - val_acc: 0.6111\n",
      "Epoch 562/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1986 - acc: 0.9484Epoch 00562: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1995 - acc: 0.9470 - val_loss: 1.5529 - val_acc: 0.6364\n",
      "Epoch 563/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2118 - acc: 0.9470Epoch 00563: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2117 - acc: 0.9470 - val_loss: 1.5760 - val_acc: 0.6111\n",
      "Epoch 564/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1950 - acc: 0.9552Epoch 00564: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.2000 - acc: 0.9545 - val_loss: 1.5069 - val_acc: 0.6162\n",
      "Epoch 565/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1996 - acc: 0.9429Epoch 00565: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.2056 - acc: 0.9407 - val_loss: 1.5449 - val_acc: 0.6313\n",
      "Epoch 566/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2152 - acc: 0.9497Epoch 00566: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.2170 - acc: 0.9482 - val_loss: 1.5503 - val_acc: 0.6313\n",
      "Epoch 567/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2240 - acc: 0.9416Epoch 00567: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2257 - acc: 0.9419 - val_loss: 1.5413 - val_acc: 0.6313\n",
      "Epoch 568/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2376 - acc: 0.9307Epoch 00568: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.2315 - acc: 0.9331 - val_loss: 1.6296 - val_acc: 0.6162\n",
      "Epoch 569/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1976 - acc: 0.9497Epoch 00569: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.2047 - acc: 0.9470 - val_loss: 1.5845 - val_acc: 0.5909\n",
      "Epoch 570/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2378 - acc: 0.9334Epoch 00570: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2346 - acc: 0.9369 - val_loss: 1.5338 - val_acc: 0.6111\n",
      "Epoch 571/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2533 - acc: 0.9321Epoch 00571: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.2639 - acc: 0.9318 - val_loss: 1.5150 - val_acc: 0.6263\n",
      "Epoch 572/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2120 - acc: 0.9470Epoch 00572: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.2048 - acc: 0.9508 - val_loss: 1.6232 - val_acc: 0.6212\n",
      "Epoch 573/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1919 - acc: 0.9538Epoch 00573: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1897 - acc: 0.9558 - val_loss: 1.5774 - val_acc: 0.6414\n",
      "Epoch 574/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2077 - acc: 0.9416Epoch 00574: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.2043 - acc: 0.9444 - val_loss: 1.5788 - val_acc: 0.6212\n",
      "Epoch 575/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2217 - acc: 0.9416Epoch 00575: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2191 - acc: 0.9444 - val_loss: 1.6426 - val_acc: 0.6010\n",
      "Epoch 576/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2086 - acc: 0.9402Epoch 00576: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.2105 - acc: 0.9394 - val_loss: 1.5873 - val_acc: 0.6263\n",
      "Epoch 577/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1981 - acc: 0.9457Epoch 00577: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.2026 - acc: 0.9457 - val_loss: 1.6126 - val_acc: 0.6263\n",
      "Epoch 578/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2152 - acc: 0.9348Epoch 00578: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.2117 - acc: 0.9369 - val_loss: 1.5378 - val_acc: 0.6313\n",
      "Epoch 579/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1991 - acc: 0.9511Epoch 00579: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1999 - acc: 0.9508 - val_loss: 1.5882 - val_acc: 0.6111\n",
      "Epoch 580/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2458 - acc: 0.9307Epoch 00580: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2490 - acc: 0.9306 - val_loss: 1.6088 - val_acc: 0.6212\n",
      "Epoch 581/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2021 - acc: 0.9470Epoch 00581: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2026 - acc: 0.9482 - val_loss: 1.6064 - val_acc: 0.6162\n",
      "Epoch 582/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2086 - acc: 0.9402Epoch 00582: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2208 - acc: 0.9381 - val_loss: 1.6505 - val_acc: 0.6364\n",
      "Epoch 583/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1911 - acc: 0.9579Epoch 00583: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.2018 - acc: 0.9545 - val_loss: 1.6359 - val_acc: 0.6414\n",
      "Epoch 584/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2093 - acc: 0.9402Epoch 00584: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.2194 - acc: 0.9369 - val_loss: 1.6126 - val_acc: 0.6162\n",
      "Epoch 585/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1931 - acc: 0.9511Epoch 00585: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1988 - acc: 0.9495 - val_loss: 1.6573 - val_acc: 0.5909\n",
      "Epoch 586/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1888 - acc: 0.9565Epoch 00586: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1891 - acc: 0.9558 - val_loss: 1.6468 - val_acc: 0.6212\n",
      "Epoch 587/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2199 - acc: 0.9443Epoch 00587: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.2231 - acc: 0.9419 - val_loss: 1.5793 - val_acc: 0.6313\n",
      "Epoch 588/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1671 - acc: 0.9524Epoch 00588: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1747 - acc: 0.9508 - val_loss: 1.6116 - val_acc: 0.6364\n",
      "Epoch 589/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2150 - acc: 0.9402Epoch 00589: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2149 - acc: 0.9394 - val_loss: 1.5782 - val_acc: 0.6263\n",
      "Epoch 590/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2023 - acc: 0.9484Epoch 00590: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.2028 - acc: 0.9457 - val_loss: 1.6050 - val_acc: 0.6111\n",
      "Epoch 591/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2237 - acc: 0.9389Epoch 00591: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.2237 - acc: 0.9381 - val_loss: 1.6418 - val_acc: 0.6263\n",
      "Epoch 592/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1950 - acc: 0.9484Epoch 00592: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1921 - acc: 0.9508 - val_loss: 1.6138 - val_acc: 0.6212\n",
      "Epoch 593/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2013 - acc: 0.9565Epoch 00593: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1962 - acc: 0.9596 - val_loss: 1.6523 - val_acc: 0.6010\n",
      "Epoch 594/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2195 - acc: 0.9416Epoch 00594: val_loss did not improve\n",
      "792/792 [==============================] - 1s 934us/step - loss: 0.2141 - acc: 0.9432 - val_loss: 1.5763 - val_acc: 0.6263\n",
      "Epoch 595/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2116 - acc: 0.9484Epoch 00595: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.2144 - acc: 0.9470 - val_loss: 1.6187 - val_acc: 0.6263\n",
      "Epoch 596/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2050 - acc: 0.9416Epoch 00596: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.2006 - acc: 0.9444 - val_loss: 1.6205 - val_acc: 0.6263\n",
      "Epoch 597/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2210 - acc: 0.9389Epoch 00597: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.2248 - acc: 0.9343 - val_loss: 1.6062 - val_acc: 0.6414\n",
      "Epoch 598/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2039 - acc: 0.9497Epoch 00598: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.2021 - acc: 0.9508 - val_loss: 1.6166 - val_acc: 0.6263\n",
      "Epoch 599/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2059 - acc: 0.9497Epoch 00599: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.2033 - acc: 0.9495 - val_loss: 1.6151 - val_acc: 0.6414\n",
      "Epoch 600/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1990 - acc: 0.9457Epoch 00600: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1943 - acc: 0.9495 - val_loss: 1.6222 - val_acc: 0.6212\n",
      "Epoch 601/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1739 - acc: 0.9565Epoch 00601: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1793 - acc: 0.9558 - val_loss: 1.6367 - val_acc: 0.6263\n",
      "Epoch 602/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1943 - acc: 0.9511Epoch 00602: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 0.1948 - acc: 0.9508 - val_loss: 1.5736 - val_acc: 0.6162\n",
      "Epoch 603/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2155 - acc: 0.9497Epoch 00603: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 0.2187 - acc: 0.9482 - val_loss: 1.5130 - val_acc: 0.6364\n",
      "Epoch 604/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2247 - acc: 0.9348Epoch 00604: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.2283 - acc: 0.9331 - val_loss: 1.5798 - val_acc: 0.6566\n",
      "Epoch 605/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2011 - acc: 0.9443Epoch 00605: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.2031 - acc: 0.9432 - val_loss: 1.5890 - val_acc: 0.6465\n",
      "Epoch 606/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2185 - acc: 0.9389Epoch 00606: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2140 - acc: 0.9407 - val_loss: 1.6578 - val_acc: 0.6212\n",
      "Epoch 607/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1906 - acc: 0.9457Epoch 00607: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1899 - acc: 0.9457 - val_loss: 1.5818 - val_acc: 0.6313\n",
      "Epoch 608/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2352 - acc: 0.9348Epoch 00608: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.2247 - acc: 0.9394 - val_loss: 1.5823 - val_acc: 0.6465\n",
      "Epoch 609/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1912 - acc: 0.9484Epoch 00609: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1866 - acc: 0.9508 - val_loss: 1.5923 - val_acc: 0.6111\n",
      "Epoch 610/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1803 - acc: 0.9470Epoch 00610: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1862 - acc: 0.9457 - val_loss: 1.6295 - val_acc: 0.6212\n",
      "Epoch 611/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1992 - acc: 0.9470Epoch 00611: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1989 - acc: 0.9470 - val_loss: 1.6064 - val_acc: 0.6414\n",
      "Epoch 612/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2212 - acc: 0.9375Epoch 00612: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.2162 - acc: 0.9407 - val_loss: 1.6222 - val_acc: 0.6515\n",
      "Epoch 613/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2123 - acc: 0.9470Epoch 00613: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.2199 - acc: 0.9470 - val_loss: 1.5510 - val_acc: 0.6566\n",
      "Epoch 614/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2155 - acc: 0.9389Epoch 00614: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.2103 - acc: 0.9407 - val_loss: 1.5919 - val_acc: 0.6263\n",
      "Epoch 615/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1778 - acc: 0.9579Epoch 00615: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1753 - acc: 0.9571 - val_loss: 1.6318 - val_acc: 0.6111\n",
      "Epoch 616/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1885 - acc: 0.9511Epoch 00616: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1916 - acc: 0.9495 - val_loss: 1.5263 - val_acc: 0.6263\n",
      "Epoch 617/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1741 - acc: 0.9579Epoch 00617: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1837 - acc: 0.9533 - val_loss: 1.5217 - val_acc: 0.6465\n",
      "Epoch 618/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1932 - acc: 0.9579Epoch 00618: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1927 - acc: 0.9571 - val_loss: 1.5944 - val_acc: 0.6263\n",
      "Epoch 619/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1778 - acc: 0.9538Epoch 00619: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1809 - acc: 0.9495 - val_loss: 1.5333 - val_acc: 0.6414\n",
      "Epoch 620/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1995 - acc: 0.9470Epoch 00620: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.2076 - acc: 0.9419 - val_loss: 1.5057 - val_acc: 0.6313\n",
      "Epoch 621/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2049 - acc: 0.9416Epoch 00621: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.2033 - acc: 0.9432 - val_loss: 1.5483 - val_acc: 0.6414\n",
      "Epoch 622/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1517 - acc: 0.9715Epoch 00622: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.1539 - acc: 0.9697 - val_loss: 1.5266 - val_acc: 0.6364\n",
      "Epoch 623/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2294 - acc: 0.9416Epoch 00623: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 0.2256 - acc: 0.9419 - val_loss: 1.5219 - val_acc: 0.6515\n",
      "Epoch 624/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2129 - acc: 0.9375Epoch 00624: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.2147 - acc: 0.9381 - val_loss: 1.5263 - val_acc: 0.6313\n",
      "Epoch 625/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2182 - acc: 0.9511Epoch 00625: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2163 - acc: 0.9508 - val_loss: 1.5576 - val_acc: 0.6566\n",
      "Epoch 626/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1860 - acc: 0.9538Epoch 00626: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1930 - acc: 0.9495 - val_loss: 1.5998 - val_acc: 0.6414\n",
      "Epoch 627/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1972 - acc: 0.9443Epoch 00627: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1929 - acc: 0.9470 - val_loss: 1.6131 - val_acc: 0.6313\n",
      "Epoch 628/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1669 - acc: 0.9579Epoch 00628: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1687 - acc: 0.9583 - val_loss: 1.6080 - val_acc: 0.6111\n",
      "Epoch 629/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2007 - acc: 0.9497Epoch 00629: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1937 - acc: 0.9520 - val_loss: 1.5543 - val_acc: 0.6364\n",
      "Epoch 630/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1883 - acc: 0.9524Epoch 00630: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1896 - acc: 0.9533 - val_loss: 1.5602 - val_acc: 0.6263\n",
      "Epoch 631/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1783 - acc: 0.9565Epoch 00631: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1793 - acc: 0.9545 - val_loss: 1.6361 - val_acc: 0.6263\n",
      "Epoch 632/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2058 - acc: 0.9470Epoch 00632: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1980 - acc: 0.9495 - val_loss: 1.6330 - val_acc: 0.6414\n",
      "Epoch 633/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2128 - acc: 0.9429Epoch 00633: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.2193 - acc: 0.9419 - val_loss: 1.6281 - val_acc: 0.6212\n",
      "Epoch 634/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1930 - acc: 0.9552Epoch 00634: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1898 - acc: 0.9545 - val_loss: 1.5419 - val_acc: 0.6465\n",
      "Epoch 635/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2020 - acc: 0.9470Epoch 00635: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2040 - acc: 0.9444 - val_loss: 1.6105 - val_acc: 0.6263\n",
      "Epoch 636/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1966 - acc: 0.9429Epoch 00636: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.2045 - acc: 0.9407 - val_loss: 1.6264 - val_acc: 0.6162\n",
      "Epoch 637/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1620 - acc: 0.9620Epoch 00637: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1641 - acc: 0.9621 - val_loss: 1.6393 - val_acc: 0.6061\n",
      "Epoch 638/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1809 - acc: 0.9484Epoch 00638: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1773 - acc: 0.9520 - val_loss: 1.6372 - val_acc: 0.5909\n",
      "Epoch 639/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2114 - acc: 0.9457Epoch 00639: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.2127 - acc: 0.9432 - val_loss: 1.6252 - val_acc: 0.6313\n",
      "Epoch 640/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1884 - acc: 0.9552Epoch 00640: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1872 - acc: 0.9533 - val_loss: 1.6128 - val_acc: 0.6263\n",
      "Epoch 641/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2241 - acc: 0.9293Epoch 00641: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2200 - acc: 0.9318 - val_loss: 1.5590 - val_acc: 0.6212\n",
      "Epoch 642/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2065 - acc: 0.9429Epoch 00642: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.2043 - acc: 0.9432 - val_loss: 1.5221 - val_acc: 0.6414\n",
      "Epoch 643/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1859 - acc: 0.9552Epoch 00643: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1807 - acc: 0.9583 - val_loss: 1.5874 - val_acc: 0.6010\n",
      "Epoch 644/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2070 - acc: 0.9538Epoch 00644: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.2052 - acc: 0.9545 - val_loss: 1.5917 - val_acc: 0.5960\n",
      "Epoch 645/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1948 - acc: 0.9538Epoch 00645: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1997 - acc: 0.9533 - val_loss: 1.5599 - val_acc: 0.6364\n",
      "Epoch 646/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1891 - acc: 0.9565Epoch 00646: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1866 - acc: 0.9571 - val_loss: 1.6577 - val_acc: 0.6162\n",
      "Epoch 647/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1892 - acc: 0.9538Epoch 00647: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1941 - acc: 0.9520 - val_loss: 1.5852 - val_acc: 0.6465\n",
      "Epoch 648/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1782 - acc: 0.9579Epoch 00648: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1901 - acc: 0.9558 - val_loss: 1.6180 - val_acc: 0.6061\n",
      "Epoch 649/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1863 - acc: 0.9524Epoch 00649: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1810 - acc: 0.9558 - val_loss: 1.6172 - val_acc: 0.6212\n",
      "Epoch 650/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2039 - acc: 0.9511Epoch 00650: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.2071 - acc: 0.9482 - val_loss: 1.5652 - val_acc: 0.6263\n",
      "Epoch 651/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1916 - acc: 0.9538Epoch 00651: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1908 - acc: 0.9545 - val_loss: 1.5996 - val_acc: 0.6212\n",
      "Epoch 652/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1958 - acc: 0.9524Epoch 00652: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1998 - acc: 0.9470 - val_loss: 1.5910 - val_acc: 0.6364\n",
      "Epoch 653/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1999 - acc: 0.9511Epoch 00653: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2056 - acc: 0.9495 - val_loss: 1.5914 - val_acc: 0.6515\n",
      "Epoch 654/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2320 - acc: 0.9361Epoch 00654: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.2234 - acc: 0.9407 - val_loss: 1.5954 - val_acc: 0.6313\n",
      "Epoch 655/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1898 - acc: 0.9511Epoch 00655: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1945 - acc: 0.9508 - val_loss: 1.5693 - val_acc: 0.6768\n",
      "Epoch 656/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1967 - acc: 0.9511Epoch 00656: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.2050 - acc: 0.9482 - val_loss: 1.5862 - val_acc: 0.6414\n",
      "Epoch 657/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2004 - acc: 0.9443Epoch 00657: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.2017 - acc: 0.9432 - val_loss: 1.5977 - val_acc: 0.6313\n",
      "Epoch 658/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1873 - acc: 0.9579Epoch 00658: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1880 - acc: 0.9558 - val_loss: 1.6515 - val_acc: 0.6263\n",
      "Epoch 659/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1945 - acc: 0.9470Epoch 00659: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1870 - acc: 0.9495 - val_loss: 1.5638 - val_acc: 0.6313\n",
      "Epoch 660/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1900 - acc: 0.9538Epoch 00660: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1963 - acc: 0.9457 - val_loss: 1.5329 - val_acc: 0.6414\n",
      "Epoch 661/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1999 - acc: 0.9457Epoch 00661: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2023 - acc: 0.9432 - val_loss: 1.5090 - val_acc: 0.6465\n",
      "Epoch 662/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1982 - acc: 0.9457Epoch 00662: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1997 - acc: 0.9457 - val_loss: 1.5083 - val_acc: 0.6515\n",
      "Epoch 663/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1861 - acc: 0.9429Epoch 00663: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1810 - acc: 0.9432 - val_loss: 1.5469 - val_acc: 0.6313\n",
      "Epoch 664/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2353 - acc: 0.9389Epoch 00664: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2309 - acc: 0.9419 - val_loss: 1.5611 - val_acc: 0.6263\n",
      "Epoch 665/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2051 - acc: 0.9402Epoch 00665: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2003 - acc: 0.9419 - val_loss: 1.5398 - val_acc: 0.6313\n",
      "Epoch 666/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1972 - acc: 0.9416Epoch 00666: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1955 - acc: 0.9432 - val_loss: 1.5832 - val_acc: 0.6515\n",
      "Epoch 667/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2116 - acc: 0.9470Epoch 00667: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2036 - acc: 0.9508 - val_loss: 1.5970 - val_acc: 0.6414\n",
      "Epoch 668/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1543 - acc: 0.9620Epoch 00668: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1561 - acc: 0.9609 - val_loss: 1.5752 - val_acc: 0.6364\n",
      "Epoch 669/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2247 - acc: 0.9334Epoch 00669: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2169 - acc: 0.9356 - val_loss: 1.6512 - val_acc: 0.6414\n",
      "Epoch 670/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2022 - acc: 0.9470Epoch 00670: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.2013 - acc: 0.9470 - val_loss: 1.6000 - val_acc: 0.6364\n",
      "Epoch 671/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1982 - acc: 0.9470Epoch 00671: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1996 - acc: 0.9457 - val_loss: 1.5321 - val_acc: 0.6263\n",
      "Epoch 672/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1893 - acc: 0.9524Epoch 00672: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1887 - acc: 0.9520 - val_loss: 1.5444 - val_acc: 0.6465\n",
      "Epoch 673/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1888 - acc: 0.9497Epoch 00673: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1916 - acc: 0.9482 - val_loss: 1.5544 - val_acc: 0.6515\n",
      "Epoch 674/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1826 - acc: 0.9538Epoch 00674: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1797 - acc: 0.9558 - val_loss: 1.5424 - val_acc: 0.6465\n",
      "Epoch 675/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2012 - acc: 0.9402Epoch 00675: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.2024 - acc: 0.9407 - val_loss: 1.4970 - val_acc: 0.6515\n",
      "Epoch 676/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2108 - acc: 0.9497Epoch 00676: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.2082 - acc: 0.9508 - val_loss: 1.5267 - val_acc: 0.6566\n",
      "Epoch 677/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1706 - acc: 0.9606Epoch 00677: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1736 - acc: 0.9609 - val_loss: 1.5710 - val_acc: 0.6515\n",
      "Epoch 678/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2057 - acc: 0.9457Epoch 00678: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2050 - acc: 0.9457 - val_loss: 1.6168 - val_acc: 0.6364\n",
      "Epoch 679/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1951 - acc: 0.9470Epoch 00679: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1903 - acc: 0.9470 - val_loss: 1.5521 - val_acc: 0.6566\n",
      "Epoch 680/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1776 - acc: 0.9538Epoch 00680: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1776 - acc: 0.9533 - val_loss: 1.5306 - val_acc: 0.6717\n",
      "Epoch 681/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1863 - acc: 0.9511Epoch 00681: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1850 - acc: 0.9508 - val_loss: 1.5463 - val_acc: 0.6566\n",
      "Epoch 682/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2352 - acc: 0.9348Epoch 00682: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.2281 - acc: 0.9381 - val_loss: 1.5258 - val_acc: 0.6515\n",
      "Epoch 683/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1920 - acc: 0.9592Epoch 00683: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1902 - acc: 0.9596 - val_loss: 1.5280 - val_acc: 0.6667\n",
      "Epoch 684/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1653 - acc: 0.9633Epoch 00684: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1717 - acc: 0.9571 - val_loss: 1.5111 - val_acc: 0.6364\n",
      "Epoch 685/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2108 - acc: 0.9361Epoch 00685: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.2079 - acc: 0.9369 - val_loss: 1.5737 - val_acc: 0.6414\n",
      "Epoch 686/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1932 - acc: 0.9470Epoch 00686: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1948 - acc: 0.9444 - val_loss: 1.5620 - val_acc: 0.6212\n",
      "Epoch 687/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1826 - acc: 0.9592Epoch 00687: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1793 - acc: 0.9609 - val_loss: 1.5341 - val_acc: 0.6465\n",
      "Epoch 688/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2222 - acc: 0.9429Epoch 00688: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.2162 - acc: 0.9457 - val_loss: 1.5753 - val_acc: 0.6364\n",
      "Epoch 689/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1999 - acc: 0.9470Epoch 00689: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.2026 - acc: 0.9457 - val_loss: 1.5806 - val_acc: 0.6263\n",
      "Epoch 690/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2007 - acc: 0.9402Epoch 00690: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.2016 - acc: 0.9407 - val_loss: 1.5872 - val_acc: 0.6263\n",
      "Epoch 691/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1955 - acc: 0.9484Epoch 00691: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1960 - acc: 0.9495 - val_loss: 1.6155 - val_acc: 0.6212\n",
      "Epoch 692/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2023 - acc: 0.9524Epoch 00692: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.2009 - acc: 0.9545 - val_loss: 1.6089 - val_acc: 0.6414\n",
      "Epoch 693/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1665 - acc: 0.9592Epoch 00693: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1683 - acc: 0.9596 - val_loss: 1.6041 - val_acc: 0.6414\n",
      "Epoch 694/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2040 - acc: 0.9470Epoch 00694: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.2132 - acc: 0.9457 - val_loss: 1.5836 - val_acc: 0.6515\n",
      "Epoch 695/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1977 - acc: 0.9484Epoch 00695: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1986 - acc: 0.9470 - val_loss: 1.5245 - val_acc: 0.6566\n",
      "Epoch 696/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2230 - acc: 0.9348Epoch 00696: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.2303 - acc: 0.9306 - val_loss: 1.5408 - val_acc: 0.6515\n",
      "Epoch 697/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1928 - acc: 0.9484Epoch 00697: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1955 - acc: 0.9482 - val_loss: 1.5632 - val_acc: 0.6364\n",
      "Epoch 698/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1971 - acc: 0.9497Epoch 00698: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1981 - acc: 0.9495 - val_loss: 1.6480 - val_acc: 0.6263\n",
      "Epoch 699/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1777 - acc: 0.9538Epoch 00699: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1731 - acc: 0.9558 - val_loss: 1.5519 - val_acc: 0.6465\n",
      "Epoch 700/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2210 - acc: 0.9334Epoch 00700: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.2250 - acc: 0.9331 - val_loss: 1.5982 - val_acc: 0.6414\n",
      "Epoch 701/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1957 - acc: 0.9470Epoch 00701: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.2015 - acc: 0.9470 - val_loss: 1.5490 - val_acc: 0.6616\n",
      "Epoch 702/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2057 - acc: 0.9457Epoch 00702: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.2026 - acc: 0.9457 - val_loss: 1.6192 - val_acc: 0.6465\n",
      "Epoch 703/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1852 - acc: 0.9620Epoch 00703: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1880 - acc: 0.9609 - val_loss: 1.5811 - val_acc: 0.6465\n",
      "Epoch 704/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2135 - acc: 0.9429Epoch 00704: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2084 - acc: 0.9470 - val_loss: 1.5491 - val_acc: 0.6465\n",
      "Epoch 705/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1717 - acc: 0.9565Epoch 00705: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1718 - acc: 0.9545 - val_loss: 1.5959 - val_acc: 0.6313\n",
      "Epoch 706/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1668 - acc: 0.9552Epoch 00706: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1719 - acc: 0.9520 - val_loss: 1.5538 - val_acc: 0.6364\n",
      "Epoch 707/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1890 - acc: 0.9565Epoch 00707: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.2021 - acc: 0.9520 - val_loss: 1.5808 - val_acc: 0.6465\n",
      "Epoch 708/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2038 - acc: 0.9511Epoch 00708: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.2026 - acc: 0.9508 - val_loss: 1.5206 - val_acc: 0.6465\n",
      "Epoch 709/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1818 - acc: 0.9524Epoch 00709: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1786 - acc: 0.9533 - val_loss: 1.5161 - val_acc: 0.6465\n",
      "Epoch 710/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2115 - acc: 0.9389Epoch 00710: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2086 - acc: 0.9419 - val_loss: 1.5021 - val_acc: 0.6465\n",
      "Epoch 711/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2071 - acc: 0.9402Epoch 00711: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.2076 - acc: 0.9407 - val_loss: 1.5963 - val_acc: 0.6414\n",
      "Epoch 712/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1721 - acc: 0.9552Epoch 00712: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1816 - acc: 0.9533 - val_loss: 1.5390 - val_acc: 0.6313\n",
      "Epoch 713/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1926 - acc: 0.9552Epoch 00713: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1941 - acc: 0.9545 - val_loss: 1.5543 - val_acc: 0.6212\n",
      "Epoch 714/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1727 - acc: 0.9497Epoch 00714: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1761 - acc: 0.9495 - val_loss: 1.6115 - val_acc: 0.6414\n",
      "Epoch 715/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1830 - acc: 0.9497Epoch 00715: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1830 - acc: 0.9508 - val_loss: 1.5566 - val_acc: 0.6364\n",
      "Epoch 716/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1627 - acc: 0.9579Epoch 00716: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1636 - acc: 0.9583 - val_loss: 1.6251 - val_acc: 0.6313\n",
      "Epoch 717/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2127 - acc: 0.9416Epoch 00717: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.2107 - acc: 0.9444 - val_loss: 1.5666 - val_acc: 0.6616\n",
      "Epoch 718/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2036 - acc: 0.9429Epoch 00718: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.2116 - acc: 0.9419 - val_loss: 1.6517 - val_acc: 0.6515\n",
      "Epoch 719/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2204 - acc: 0.9416Epoch 00719: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.2275 - acc: 0.9419 - val_loss: 1.6299 - val_acc: 0.6313\n",
      "Epoch 720/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1763 - acc: 0.9389Epoch 00720: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1889 - acc: 0.9343 - val_loss: 1.5922 - val_acc: 0.6414\n",
      "Epoch 721/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1898 - acc: 0.9511Epoch 00721: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1874 - acc: 0.9520 - val_loss: 1.6330 - val_acc: 0.6515\n",
      "Epoch 722/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1444 - acc: 0.9674Epoch 00722: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1599 - acc: 0.9609 - val_loss: 1.5620 - val_acc: 0.6566\n",
      "Epoch 723/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2280 - acc: 0.9443Epoch 00723: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.2306 - acc: 0.9419 - val_loss: 1.5735 - val_acc: 0.6667\n",
      "Epoch 724/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1804 - acc: 0.9538Epoch 00724: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1791 - acc: 0.9545 - val_loss: 1.5825 - val_acc: 0.6667\n",
      "Epoch 725/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1863 - acc: 0.9457Epoch 00725: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1849 - acc: 0.9470 - val_loss: 1.6480 - val_acc: 0.6263\n",
      "Epoch 726/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1716 - acc: 0.9524Epoch 00726: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1681 - acc: 0.9533 - val_loss: 1.5629 - val_acc: 0.6313\n",
      "Epoch 727/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1539 - acc: 0.9620Epoch 00727: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1514 - acc: 0.9621 - val_loss: 1.5544 - val_acc: 0.6364\n",
      "Epoch 728/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1711 - acc: 0.9538Epoch 00728: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1819 - acc: 0.9495 - val_loss: 1.5937 - val_acc: 0.6162\n",
      "Epoch 729/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1839 - acc: 0.9497Epoch 00729: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1827 - acc: 0.9508 - val_loss: 1.5806 - val_acc: 0.6515\n",
      "Epoch 730/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1895 - acc: 0.9511Epoch 00730: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1822 - acc: 0.9545 - val_loss: 1.6138 - val_acc: 0.6212\n",
      "Epoch 731/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1832 - acc: 0.9497Epoch 00731: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1820 - acc: 0.9508 - val_loss: 1.5339 - val_acc: 0.6313\n",
      "Epoch 732/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1665 - acc: 0.9633Epoch 00732: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1630 - acc: 0.9646 - val_loss: 1.6024 - val_acc: 0.6364\n",
      "Epoch 733/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1920 - acc: 0.9470Epoch 00733: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1929 - acc: 0.9470 - val_loss: 1.5719 - val_acc: 0.6667\n",
      "Epoch 734/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1925 - acc: 0.9457Epoch 00734: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1900 - acc: 0.9470 - val_loss: 1.5991 - val_acc: 0.6364\n",
      "Epoch 735/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1457 - acc: 0.9742Epoch 00735: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1469 - acc: 0.9735 - val_loss: 1.5588 - val_acc: 0.6263\n",
      "Epoch 736/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1733 - acc: 0.9552Epoch 00736: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1775 - acc: 0.9533 - val_loss: 1.5702 - val_acc: 0.6263\n",
      "Epoch 737/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1936 - acc: 0.9470Epoch 00737: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.2016 - acc: 0.9444 - val_loss: 1.6130 - val_acc: 0.6263\n",
      "Epoch 738/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1961 - acc: 0.9457Epoch 00738: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1952 - acc: 0.9470 - val_loss: 1.5887 - val_acc: 0.6111\n",
      "Epoch 739/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1680 - acc: 0.9443Epoch 00739: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1743 - acc: 0.9419 - val_loss: 1.5556 - val_acc: 0.6414\n",
      "Epoch 740/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1885 - acc: 0.9511Epoch 00740: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1823 - acc: 0.9520 - val_loss: 1.6178 - val_acc: 0.6465\n",
      "Epoch 741/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1752 - acc: 0.9552Epoch 00741: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1756 - acc: 0.9545 - val_loss: 1.6285 - val_acc: 0.6364\n",
      "Epoch 742/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2184 - acc: 0.9361Epoch 00742: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.2163 - acc: 0.9381 - val_loss: 1.5800 - val_acc: 0.6414\n",
      "Epoch 743/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1724 - acc: 0.9565Epoch 00743: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1704 - acc: 0.9583 - val_loss: 1.5946 - val_acc: 0.6515\n",
      "Epoch 744/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1522 - acc: 0.9633Epoch 00744: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1577 - acc: 0.9621 - val_loss: 1.6310 - val_acc: 0.6111\n",
      "Epoch 745/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1832 - acc: 0.9579Epoch 00745: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1847 - acc: 0.9571 - val_loss: 1.5509 - val_acc: 0.6212\n",
      "Epoch 746/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1725 - acc: 0.9552- ETA: 0s - loss: 0.1741 - accEpoch 00746: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1700 - acc: 0.9571 - val_loss: 1.5495 - val_acc: 0.6263\n",
      "Epoch 747/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1999 - acc: 0.9416Epoch 00747: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1973 - acc: 0.9444 - val_loss: 1.5552 - val_acc: 0.6162\n",
      "Epoch 748/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1999 - acc: 0.9497Epoch 00748: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1995 - acc: 0.9495 - val_loss: 1.5794 - val_acc: 0.6465\n",
      "Epoch 749/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1974 - acc: 0.9470Epoch 00749: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.2018 - acc: 0.9444 - val_loss: 1.5209 - val_acc: 0.6162\n",
      "Epoch 750/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1798 - acc: 0.9565Epoch 00750: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1775 - acc: 0.9571 - val_loss: 1.5945 - val_acc: 0.6212\n",
      "Epoch 751/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2035 - acc: 0.9361Epoch 00751: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2002 - acc: 0.9369 - val_loss: 1.5580 - val_acc: 0.6212\n",
      "Epoch 752/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1778 - acc: 0.9524Epoch 00752: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1784 - acc: 0.9520 - val_loss: 1.5460 - val_acc: 0.6364\n",
      "Epoch 753/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1609 - acc: 0.9565Epoch 00753: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1642 - acc: 0.9558 - val_loss: 1.5338 - val_acc: 0.6465\n",
      "Epoch 754/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1633 - acc: 0.9606Epoch 00754: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1685 - acc: 0.9583 - val_loss: 1.6383 - val_acc: 0.6212\n",
      "Epoch 755/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1732 - acc: 0.9592Epoch 00755: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1711 - acc: 0.9583 - val_loss: 1.5761 - val_acc: 0.6364\n",
      "Epoch 756/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1915 - acc: 0.9524Epoch 00756: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1890 - acc: 0.9545 - val_loss: 1.6153 - val_acc: 0.6212\n",
      "Epoch 757/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2017 - acc: 0.9402Epoch 00757: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1991 - acc: 0.9407 - val_loss: 1.6124 - val_acc: 0.6414\n",
      "Epoch 758/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1793 - acc: 0.9511Epoch 00758: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1854 - acc: 0.9495 - val_loss: 1.6039 - val_acc: 0.6313\n",
      "Epoch 759/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1683 - acc: 0.9579Epoch 00759: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1733 - acc: 0.9571 - val_loss: 1.5935 - val_acc: 0.6465\n",
      "Epoch 760/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1925 - acc: 0.9511Epoch 00760: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1917 - acc: 0.9533 - val_loss: 1.6189 - val_acc: 0.6414\n",
      "Epoch 761/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1683 - acc: 0.9592Epoch 00761: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1672 - acc: 0.9621 - val_loss: 1.6211 - val_acc: 0.6313\n",
      "Epoch 762/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1597 - acc: 0.9592Epoch 00762: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1552 - acc: 0.9621 - val_loss: 1.6143 - val_acc: 0.6263\n",
      "Epoch 763/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1653 - acc: 0.9647Epoch 00763: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1670 - acc: 0.9646 - val_loss: 1.6041 - val_acc: 0.6414\n",
      "Epoch 764/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2016 - acc: 0.9524Epoch 00764: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.2031 - acc: 0.9508 - val_loss: 1.6030 - val_acc: 0.6263\n",
      "Epoch 765/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1991 - acc: 0.9538Epoch 00765: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.2078 - acc: 0.9495 - val_loss: 1.5518 - val_acc: 0.6364\n",
      "Epoch 766/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1821 - acc: 0.9552Epoch 00766: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1769 - acc: 0.9571 - val_loss: 1.5916 - val_acc: 0.6364\n",
      "Epoch 767/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1535 - acc: 0.9592Epoch 00767: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1559 - acc: 0.9596 - val_loss: 1.6250 - val_acc: 0.6364\n",
      "Epoch 768/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2045 - acc: 0.9457Epoch 00768: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.2080 - acc: 0.9457 - val_loss: 1.5679 - val_acc: 0.6515\n",
      "Epoch 769/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2070 - acc: 0.9361Epoch 00769: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2086 - acc: 0.9343 - val_loss: 1.5882 - val_acc: 0.6465\n",
      "Epoch 770/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1801 - acc: 0.9579Epoch 00770: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1780 - acc: 0.9583 - val_loss: 1.5969 - val_acc: 0.6616\n",
      "Epoch 771/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1793 - acc: 0.9524Epoch 00771: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1746 - acc: 0.9533 - val_loss: 1.5999 - val_acc: 0.6364\n",
      "Epoch 772/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1498 - acc: 0.9633Epoch 00772: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1457 - acc: 0.9646 - val_loss: 1.5989 - val_acc: 0.6717\n",
      "Epoch 773/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1921 - acc: 0.9457Epoch 00773: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1927 - acc: 0.9457 - val_loss: 1.5805 - val_acc: 0.6465\n",
      "Epoch 774/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1694 - acc: 0.9660Epoch 00774: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1787 - acc: 0.9634 - val_loss: 1.5991 - val_acc: 0.6465\n",
      "Epoch 775/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1771 - acc: 0.9470Epoch 00775: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1753 - acc: 0.9457 - val_loss: 1.5721 - val_acc: 0.6515\n",
      "Epoch 776/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1933 - acc: 0.9470Epoch 00776: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1916 - acc: 0.9470 - val_loss: 1.5921 - val_acc: 0.6465\n",
      "Epoch 777/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2039 - acc: 0.9389Epoch 00777: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1962 - acc: 0.9419 - val_loss: 1.6510 - val_acc: 0.6364\n",
      "Epoch 778/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1826 - acc: 0.9484Epoch 00778: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1781 - acc: 0.9508 - val_loss: 1.6529 - val_acc: 0.6212\n",
      "Epoch 779/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1839 - acc: 0.9552Epoch 00779: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1835 - acc: 0.9545 - val_loss: 1.5517 - val_acc: 0.6414\n",
      "Epoch 780/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2139 - acc: 0.9389Epoch 00780: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.2111 - acc: 0.9407 - val_loss: 1.5298 - val_acc: 0.6515\n",
      "Epoch 781/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1973 - acc: 0.9470Epoch 00781: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1972 - acc: 0.9470 - val_loss: 1.5432 - val_acc: 0.6566\n",
      "Epoch 782/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1746 - acc: 0.9511Epoch 00782: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1744 - acc: 0.9508 - val_loss: 1.5323 - val_acc: 0.6465\n",
      "Epoch 783/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1514 - acc: 0.9606Epoch 00783: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1542 - acc: 0.9609 - val_loss: 1.5628 - val_acc: 0.6515\n",
      "Epoch 784/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1931 - acc: 0.9524Epoch 00784: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1948 - acc: 0.9533 - val_loss: 1.6027 - val_acc: 0.6212\n",
      "Epoch 785/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1341 - acc: 0.9674Epoch 00785: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1368 - acc: 0.9672 - val_loss: 1.6219 - val_acc: 0.6313\n",
      "Epoch 786/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1842 - acc: 0.9552Epoch 00786: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1787 - acc: 0.9571 - val_loss: 1.6433 - val_acc: 0.6515\n",
      "Epoch 787/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1906 - acc: 0.9565Epoch 00787: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1858 - acc: 0.9571 - val_loss: 1.6185 - val_acc: 0.6414\n",
      "Epoch 788/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1890 - acc: 0.9538Epoch 00788: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1890 - acc: 0.9533 - val_loss: 1.6477 - val_acc: 0.5960\n",
      "Epoch 789/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1716 - acc: 0.9579Epoch 00789: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1807 - acc: 0.9533 - val_loss: 1.5994 - val_acc: 0.6162\n",
      "Epoch 790/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1734 - acc: 0.9524Epoch 00790: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1699 - acc: 0.9545 - val_loss: 1.5724 - val_acc: 0.6465\n",
      "Epoch 791/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1650 - acc: 0.9579Epoch 00791: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1620 - acc: 0.9596 - val_loss: 1.5932 - val_acc: 0.6313\n",
      "Epoch 792/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1627 - acc: 0.9633Epoch 00792: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1627 - acc: 0.9634 - val_loss: 1.6076 - val_acc: 0.6263\n",
      "Epoch 793/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1460 - acc: 0.9552Epoch 00793: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1432 - acc: 0.9558 - val_loss: 1.6355 - val_acc: 0.6263\n",
      "Epoch 794/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1533 - acc: 0.9674Epoch 00794: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1491 - acc: 0.9697 - val_loss: 1.5907 - val_acc: 0.6212\n",
      "Epoch 795/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2081 - acc: 0.9389Epoch 00795: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.2055 - acc: 0.9381 - val_loss: 1.6245 - val_acc: 0.6364\n",
      "Epoch 796/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1715 - acc: 0.9552Epoch 00796: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1825 - acc: 0.9533 - val_loss: 1.6550 - val_acc: 0.6364\n",
      "Epoch 797/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1863 - acc: 0.9470Epoch 00797: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1852 - acc: 0.9482 - val_loss: 1.5671 - val_acc: 0.6515\n",
      "Epoch 798/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1712 - acc: 0.9647Epoch 00798: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1720 - acc: 0.9646 - val_loss: 1.6502 - val_acc: 0.6212\n",
      "Epoch 799/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1639 - acc: 0.9620Epoch 00799: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1591 - acc: 0.9646 - val_loss: 1.5837 - val_acc: 0.6263\n",
      "Epoch 800/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1266 - acc: 0.9755Epoch 00800: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1299 - acc: 0.9747 - val_loss: 1.5843 - val_acc: 0.6364\n",
      "Epoch 801/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1599 - acc: 0.9565Epoch 00801: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1606 - acc: 0.9558 - val_loss: 1.5727 - val_acc: 0.6212\n",
      "Epoch 802/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1492 - acc: 0.9606Epoch 00802: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1621 - acc: 0.9571 - val_loss: 1.5381 - val_acc: 0.6212\n",
      "Epoch 803/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1511 - acc: 0.9606Epoch 00803: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1569 - acc: 0.9609 - val_loss: 1.6056 - val_acc: 0.5859\n",
      "Epoch 804/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1357 - acc: 0.9660Epoch 00804: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1441 - acc: 0.9621 - val_loss: 1.6639 - val_acc: 0.6061\n",
      "Epoch 805/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1767 - acc: 0.9552Epoch 00805: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1753 - acc: 0.9545 - val_loss: 1.5496 - val_acc: 0.6263\n",
      "Epoch 806/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2008 - acc: 0.9470Epoch 00806: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.2008 - acc: 0.9432 - val_loss: 1.5668 - val_acc: 0.6212\n",
      "Epoch 807/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1645 - acc: 0.9647Epoch 00807: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1716 - acc: 0.9634 - val_loss: 1.5411 - val_acc: 0.6414\n",
      "Epoch 808/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2039 - acc: 0.9443Epoch 00808: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1974 - acc: 0.9470 - val_loss: 1.5692 - val_acc: 0.6364\n",
      "Epoch 809/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1655 - acc: 0.9606Epoch 00809: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1701 - acc: 0.9583 - val_loss: 1.6012 - val_acc: 0.6364\n",
      "Epoch 810/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1679 - acc: 0.9538Epoch 00810: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1672 - acc: 0.9533 - val_loss: 1.5554 - val_acc: 0.6515\n",
      "Epoch 811/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1569 - acc: 0.9633Epoch 00811: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1580 - acc: 0.9609 - val_loss: 1.5405 - val_acc: 0.6515\n",
      "Epoch 812/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1608 - acc: 0.9606Epoch 00812: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1613 - acc: 0.9609 - val_loss: 1.5433 - val_acc: 0.6313\n",
      "Epoch 813/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1584 - acc: 0.9660Epoch 00813: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1585 - acc: 0.9646 - val_loss: 1.5840 - val_acc: 0.6515\n",
      "Epoch 814/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1666 - acc: 0.9538Epoch 00814: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1758 - acc: 0.9520 - val_loss: 1.6096 - val_acc: 0.6162\n",
      "Epoch 815/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1484 - acc: 0.9701Epoch 00815: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1575 - acc: 0.9684 - val_loss: 1.5650 - val_acc: 0.6364\n",
      "Epoch 816/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1641 - acc: 0.9565Epoch 00816: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1710 - acc: 0.9508 - val_loss: 1.4902 - val_acc: 0.6515\n",
      "Epoch 817/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1521 - acc: 0.9647Epoch 00817: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1591 - acc: 0.9634 - val_loss: 1.5331 - val_acc: 0.6414\n",
      "Epoch 818/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1746 - acc: 0.9538Epoch 00818: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1765 - acc: 0.9520 - val_loss: 1.5309 - val_acc: 0.6263\n",
      "Epoch 819/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1712 - acc: 0.9565Epoch 00819: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1680 - acc: 0.9583 - val_loss: 1.5484 - val_acc: 0.6364\n",
      "Epoch 820/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1809 - acc: 0.9565Epoch 00820: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1832 - acc: 0.9571 - val_loss: 1.5318 - val_acc: 0.6313\n",
      "Epoch 821/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1925 - acc: 0.9484Epoch 00821: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1962 - acc: 0.9470 - val_loss: 1.6115 - val_acc: 0.6212\n",
      "Epoch 822/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1557 - acc: 0.9647Epoch 00822: val_loss did not improve\n",
      "792/792 [==============================] - 1s 933us/step - loss: 0.1578 - acc: 0.9621 - val_loss: 1.5293 - val_acc: 0.6212\n",
      "Epoch 823/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1774 - acc: 0.9552Epoch 00823: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1807 - acc: 0.9520 - val_loss: 1.5501 - val_acc: 0.6313\n",
      "Epoch 824/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1633 - acc: 0.9647Epoch 00824: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1570 - acc: 0.9659 - val_loss: 1.5877 - val_acc: 0.6313\n",
      "Epoch 825/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1527 - acc: 0.9592Epoch 00825: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1553 - acc: 0.9583 - val_loss: 1.5337 - val_acc: 0.6313\n",
      "Epoch 826/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1646 - acc: 0.9565Epoch 00826: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1655 - acc: 0.9571 - val_loss: 1.5319 - val_acc: 0.6667\n",
      "Epoch 827/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1722 - acc: 0.9538Epoch 00827: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1720 - acc: 0.9545 - val_loss: 1.5385 - val_acc: 0.6515\n",
      "Epoch 828/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1744 - acc: 0.9484Epoch 00828: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1729 - acc: 0.9508 - val_loss: 1.5753 - val_acc: 0.6566\n",
      "Epoch 829/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1633 - acc: 0.9579Epoch 00829: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1671 - acc: 0.9558 - val_loss: 1.5517 - val_acc: 0.6364\n",
      "Epoch 830/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1804 - acc: 0.9524Epoch 00830: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1860 - acc: 0.9508 - val_loss: 1.5836 - val_acc: 0.6212\n",
      "Epoch 831/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1633 - acc: 0.9524Epoch 00831: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1652 - acc: 0.9508 - val_loss: 1.6290 - val_acc: 0.6212\n",
      "Epoch 832/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1793 - acc: 0.9592Epoch 00832: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1787 - acc: 0.9583 - val_loss: 1.6349 - val_acc: 0.6465\n",
      "Epoch 833/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1593 - acc: 0.9606Epoch 00833: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1666 - acc: 0.9609 - val_loss: 1.6266 - val_acc: 0.6465\n",
      "Epoch 834/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1902 - acc: 0.9497Epoch 00834: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.2009 - acc: 0.9444 - val_loss: 1.6742 - val_acc: 0.6263\n",
      "Epoch 835/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1712 - acc: 0.9565Epoch 00835: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1735 - acc: 0.9545 - val_loss: 1.5979 - val_acc: 0.6515\n",
      "Epoch 836/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1983 - acc: 0.9484Epoch 00836: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.2111 - acc: 0.9432 - val_loss: 1.5694 - val_acc: 0.6364\n",
      "Epoch 837/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1502 - acc: 0.9620Epoch 00837: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1502 - acc: 0.9621 - val_loss: 1.5275 - val_acc: 0.6515\n",
      "Epoch 838/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1338 - acc: 0.9688Epoch 00838: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1322 - acc: 0.9710 - val_loss: 1.5562 - val_acc: 0.6667\n",
      "Epoch 839/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2003 - acc: 0.9375Epoch 00839: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1977 - acc: 0.9407 - val_loss: 1.5944 - val_acc: 0.6414\n",
      "Epoch 840/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1621 - acc: 0.9606Epoch 00840: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1593 - acc: 0.9609 - val_loss: 1.5819 - val_acc: 0.6313\n",
      "Epoch 841/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1831 - acc: 0.9538Epoch 00841: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1758 - acc: 0.9571 - val_loss: 1.6375 - val_acc: 0.6364\n",
      "Epoch 842/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1669 - acc: 0.9552Epoch 00842: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1643 - acc: 0.9558 - val_loss: 1.6710 - val_acc: 0.5960\n",
      "Epoch 843/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1463 - acc: 0.9660Epoch 00843: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1432 - acc: 0.9659 - val_loss: 1.6260 - val_acc: 0.6515\n",
      "Epoch 844/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1580 - acc: 0.9606Epoch 00844: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1543 - acc: 0.9634 - val_loss: 1.6324 - val_acc: 0.6263\n",
      "Epoch 845/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1762 - acc: 0.9497Epoch 00845: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1701 - acc: 0.9508 - val_loss: 1.5832 - val_acc: 0.6364\n",
      "Epoch 846/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1721 - acc: 0.9592Epoch 00846: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1706 - acc: 0.9583 - val_loss: 1.5557 - val_acc: 0.6566\n",
      "Epoch 847/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1426 - acc: 0.9606Epoch 00847: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1434 - acc: 0.9609 - val_loss: 1.6079 - val_acc: 0.6465\n",
      "Epoch 848/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1899 - acc: 0.9457Epoch 00848: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1951 - acc: 0.9419 - val_loss: 1.5846 - val_acc: 0.6566\n",
      "Epoch 849/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1603 - acc: 0.9565Epoch 00849: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1632 - acc: 0.9545 - val_loss: 1.6044 - val_acc: 0.6364\n",
      "Epoch 850/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1633 - acc: 0.9592Epoch 00850: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1650 - acc: 0.9571 - val_loss: 1.6149 - val_acc: 0.6313\n",
      "Epoch 851/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1753 - acc: 0.9579Epoch 00851: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1704 - acc: 0.9596 - val_loss: 1.5669 - val_acc: 0.6313\n",
      "Epoch 852/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1791 - acc: 0.9497Epoch 00852: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1774 - acc: 0.9508 - val_loss: 1.5297 - val_acc: 0.6465\n",
      "Epoch 853/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1633 - acc: 0.9633Epoch 00853: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1682 - acc: 0.9621 - val_loss: 1.5688 - val_acc: 0.6566\n",
      "Epoch 854/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1625 - acc: 0.9592Epoch 00854: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1667 - acc: 0.9558 - val_loss: 1.6310 - val_acc: 0.6465\n",
      "Epoch 855/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1464 - acc: 0.9592Epoch 00855: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1498 - acc: 0.9583 - val_loss: 1.5611 - val_acc: 0.6616\n",
      "Epoch 856/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1669 - acc: 0.9511Epoch 00856: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1610 - acc: 0.9545 - val_loss: 1.5923 - val_acc: 0.6616\n",
      "Epoch 857/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1712 - acc: 0.9565Epoch 00857: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1786 - acc: 0.9545 - val_loss: 1.5797 - val_acc: 0.6414\n",
      "Epoch 858/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1457 - acc: 0.9633Epoch 00858: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.1538 - acc: 0.9596 - val_loss: 1.5650 - val_acc: 0.6717\n",
      "Epoch 859/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1658 - acc: 0.9592Epoch 00859: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1633 - acc: 0.9583 - val_loss: 1.5812 - val_acc: 0.6414\n",
      "Epoch 860/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1669 - acc: 0.9633Epoch 00860: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1612 - acc: 0.9659 - val_loss: 1.5827 - val_acc: 0.6515\n",
      "Epoch 861/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1506 - acc: 0.9633Epoch 00861: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1551 - acc: 0.9621 - val_loss: 1.6010 - val_acc: 0.6414\n",
      "Epoch 862/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1774 - acc: 0.9552Epoch 00862: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1833 - acc: 0.9545 - val_loss: 1.5412 - val_acc: 0.6515\n",
      "Epoch 863/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1236 - acc: 0.9715Epoch 00863: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1313 - acc: 0.9672 - val_loss: 1.6087 - val_acc: 0.6364\n",
      "Epoch 864/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1642 - acc: 0.9620Epoch 00864: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1604 - acc: 0.9621 - val_loss: 1.5553 - val_acc: 0.6465\n",
      "Epoch 865/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1831 - acc: 0.9552Epoch 00865: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1828 - acc: 0.9545 - val_loss: 1.6178 - val_acc: 0.6414\n",
      "Epoch 866/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1539 - acc: 0.9606Epoch 00866: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1559 - acc: 0.9596 - val_loss: 1.5507 - val_acc: 0.6212\n",
      "Epoch 867/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1443 - acc: 0.9565Epoch 00867: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1525 - acc: 0.9545 - val_loss: 1.5802 - val_acc: 0.6313\n",
      "Epoch 868/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2073 - acc: 0.9429Epoch 00868: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.2019 - acc: 0.9457 - val_loss: 1.6291 - val_acc: 0.6212\n",
      "Epoch 869/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1658 - acc: 0.9538Epoch 00869: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.1643 - acc: 0.9533 - val_loss: 1.5588 - val_acc: 0.6414\n",
      "Epoch 870/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1882 - acc: 0.9457Epoch 00870: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1824 - acc: 0.9482 - val_loss: 1.6103 - val_acc: 0.6515\n",
      "Epoch 871/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1829 - acc: 0.9538Epoch 00871: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1814 - acc: 0.9558 - val_loss: 1.6119 - val_acc: 0.6515\n",
      "Epoch 872/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1555 - acc: 0.9660Epoch 00872: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1508 - acc: 0.9684 - val_loss: 1.6226 - val_acc: 0.6313\n",
      "Epoch 873/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1680 - acc: 0.9592Epoch 00873: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1660 - acc: 0.9583 - val_loss: 1.6760 - val_acc: 0.6212\n",
      "Epoch 874/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1804 - acc: 0.9484Epoch 00874: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1771 - acc: 0.9495 - val_loss: 1.5914 - val_acc: 0.6364\n",
      "Epoch 875/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1712 - acc: 0.9497Epoch 00875: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1696 - acc: 0.9508 - val_loss: 1.5609 - val_acc: 0.6364\n",
      "Epoch 876/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1751 - acc: 0.9511Epoch 00876: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1803 - acc: 0.9495 - val_loss: 1.5216 - val_acc: 0.6616\n",
      "Epoch 877/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1657 - acc: 0.9565Epoch 00877: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1634 - acc: 0.9583 - val_loss: 1.6185 - val_acc: 0.6566\n",
      "Epoch 878/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1551 - acc: 0.9565Epoch 00878: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1564 - acc: 0.9558 - val_loss: 1.6331 - val_acc: 0.6313\n",
      "Epoch 879/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1923 - acc: 0.9552Epoch 00879: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.2015 - acc: 0.9508 - val_loss: 1.5836 - val_acc: 0.6263\n",
      "Epoch 880/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1957 - acc: 0.9484Epoch 00880: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.2000 - acc: 0.9482 - val_loss: 1.5653 - val_acc: 0.6364\n",
      "Epoch 881/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1853 - acc: 0.9497Epoch 00881: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 0.1910 - acc: 0.9470 - val_loss: 1.6211 - val_acc: 0.6010\n",
      "Epoch 882/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1575 - acc: 0.9606Epoch 00882: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1622 - acc: 0.9596 - val_loss: 1.6387 - val_acc: 0.6313\n",
      "Epoch 883/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1485 - acc: 0.9606Epoch 00883: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1447 - acc: 0.9621 - val_loss: 1.6198 - val_acc: 0.6263\n",
      "Epoch 884/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1957 - acc: 0.9484Epoch 00884: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1963 - acc: 0.9482 - val_loss: 1.5361 - val_acc: 0.6616\n",
      "Epoch 885/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1498 - acc: 0.9620Epoch 00885: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1529 - acc: 0.9596 - val_loss: 1.5890 - val_acc: 0.6414\n",
      "Epoch 886/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1728 - acc: 0.9497Epoch 00886: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.1696 - acc: 0.9508 - val_loss: 1.5609 - val_acc: 0.6465\n",
      "Epoch 887/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1544 - acc: 0.9552Epoch 00887: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1569 - acc: 0.9520 - val_loss: 1.5373 - val_acc: 0.6364\n",
      "Epoch 888/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1784 - acc: 0.9497Epoch 00888: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1773 - acc: 0.9482 - val_loss: 1.5759 - val_acc: 0.6263\n",
      "Epoch 889/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1414 - acc: 0.9592Epoch 00889: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1468 - acc: 0.9583 - val_loss: 1.5100 - val_acc: 0.6465\n",
      "Epoch 890/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1662 - acc: 0.9565Epoch 00890: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1704 - acc: 0.9545 - val_loss: 1.5944 - val_acc: 0.6566\n",
      "Epoch 891/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1540 - acc: 0.9565Epoch 00891: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1521 - acc: 0.9583 - val_loss: 1.5859 - val_acc: 0.6364\n",
      "Epoch 892/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1179 - acc: 0.9715Epoch 00892: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1257 - acc: 0.9684 - val_loss: 1.5932 - val_acc: 0.6364\n",
      "Epoch 893/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1767 - acc: 0.9511Epoch 00893: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1730 - acc: 0.9545 - val_loss: 1.6154 - val_acc: 0.6414\n",
      "Epoch 894/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1696 - acc: 0.9511Epoch 00894: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1653 - acc: 0.9520 - val_loss: 1.6465 - val_acc: 0.6364\n",
      "Epoch 895/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1599 - acc: 0.9579Epoch 00895: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 0.1628 - acc: 0.9571 - val_loss: 1.6089 - val_acc: 0.6616\n",
      "Epoch 896/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1275 - acc: 0.9769Epoch 00896: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1279 - acc: 0.9760 - val_loss: 1.6184 - val_acc: 0.6566\n",
      "Epoch 897/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1616 - acc: 0.9592Epoch 00897: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 0.1699 - acc: 0.9583 - val_loss: 1.6474 - val_acc: 0.6566\n",
      "Epoch 898/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1968 - acc: 0.9552Epoch 00898: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1944 - acc: 0.9558 - val_loss: 1.6196 - val_acc: 0.6667\n",
      "Epoch 899/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1780 - acc: 0.9470Epoch 00899: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1828 - acc: 0.9444 - val_loss: 1.6176 - val_acc: 0.6566\n",
      "Epoch 900/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1684 - acc: 0.9538Epoch 00900: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1689 - acc: 0.9533 - val_loss: 1.5651 - val_acc: 0.6616\n",
      "Epoch 901/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1788 - acc: 0.9457Epoch 00901: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1831 - acc: 0.9432 - val_loss: 1.5135 - val_acc: 0.6616\n",
      "Epoch 902/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1372 - acc: 0.9688Epoch 00902: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1413 - acc: 0.9672 - val_loss: 1.6048 - val_acc: 0.6465\n",
      "Epoch 903/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1744 - acc: 0.9579Epoch 00903: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1701 - acc: 0.9583 - val_loss: 1.6019 - val_acc: 0.6313\n",
      "Epoch 904/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1590 - acc: 0.9565Epoch 00904: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1535 - acc: 0.9583 - val_loss: 1.6268 - val_acc: 0.6465\n",
      "Epoch 905/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1344 - acc: 0.9674Epoch 00905: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1413 - acc: 0.9634 - val_loss: 1.6130 - val_acc: 0.6263\n",
      "Epoch 906/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1753 - acc: 0.9592Epoch 00906: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1721 - acc: 0.9609 - val_loss: 1.6254 - val_acc: 0.6313\n",
      "Epoch 907/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1447 - acc: 0.9647Epoch 00907: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1431 - acc: 0.9646 - val_loss: 1.6581 - val_acc: 0.6313\n",
      "Epoch 908/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1700 - acc: 0.9579Epoch 00908: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1717 - acc: 0.9571 - val_loss: 1.6542 - val_acc: 0.6414\n",
      "Epoch 909/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1606 - acc: 0.9524Epoch 00909: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1560 - acc: 0.9545 - val_loss: 1.6047 - val_acc: 0.6313\n",
      "Epoch 910/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1718 - acc: 0.9592Epoch 00910: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1796 - acc: 0.9571 - val_loss: 1.6364 - val_acc: 0.6111\n",
      "Epoch 911/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1665 - acc: 0.9524Epoch 00911: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1613 - acc: 0.9545 - val_loss: 1.6271 - val_acc: 0.6515\n",
      "Epoch 912/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1794 - acc: 0.9538Epoch 00912: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1776 - acc: 0.9545 - val_loss: 1.5852 - val_acc: 0.6566\n",
      "Epoch 913/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1695 - acc: 0.9565Epoch 00913: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1646 - acc: 0.9583 - val_loss: 1.6256 - val_acc: 0.6364\n",
      "Epoch 914/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1599 - acc: 0.9620Epoch 00914: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1611 - acc: 0.9596 - val_loss: 1.6143 - val_acc: 0.6364\n",
      "Epoch 915/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1714 - acc: 0.9470Epoch 00915: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1763 - acc: 0.9457 - val_loss: 1.5800 - val_acc: 0.6667\n",
      "Epoch 916/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1625 - acc: 0.9592Epoch 00916: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1778 - acc: 0.9533 - val_loss: 1.5800 - val_acc: 0.6465\n",
      "Epoch 917/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1368 - acc: 0.9660Epoch 00917: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1482 - acc: 0.9621 - val_loss: 1.5952 - val_acc: 0.6313\n",
      "Epoch 918/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1351 - acc: 0.9674Epoch 00918: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1298 - acc: 0.9697 - val_loss: 1.5842 - val_acc: 0.6414\n",
      "Epoch 919/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1690 - acc: 0.9470Epoch 00919: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1662 - acc: 0.9495 - val_loss: 1.6127 - val_acc: 0.6414\n",
      "Epoch 920/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1449 - acc: 0.9620Epoch 00920: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1538 - acc: 0.9583 - val_loss: 1.6640 - val_acc: 0.6061\n",
      "Epoch 921/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1875 - acc: 0.9389Epoch 00921: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1940 - acc: 0.9394 - val_loss: 1.6818 - val_acc: 0.6111\n",
      "Epoch 922/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1390 - acc: 0.9660Epoch 00922: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1477 - acc: 0.9646 - val_loss: 1.6563 - val_acc: 0.6263\n",
      "Epoch 923/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1820 - acc: 0.9511Epoch 00923: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1771 - acc: 0.9533 - val_loss: 1.6454 - val_acc: 0.6313\n",
      "Epoch 924/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1445 - acc: 0.9606- ETA: 0s - loss: 0.1712 - accEpoch 00924: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1435 - acc: 0.9609 - val_loss: 1.6001 - val_acc: 0.6414\n",
      "Epoch 925/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1812 - acc: 0.9484Epoch 00925: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1811 - acc: 0.9457 - val_loss: 1.6132 - val_acc: 0.6414\n",
      "Epoch 926/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1631 - acc: 0.9552Epoch 00926: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1660 - acc: 0.9545 - val_loss: 1.6486 - val_acc: 0.6162\n",
      "Epoch 927/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1677 - acc: 0.9565Epoch 00927: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.1655 - acc: 0.9583 - val_loss: 1.5855 - val_acc: 0.6414\n",
      "Epoch 928/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1300 - acc: 0.9755Epoch 00928: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1322 - acc: 0.9735 - val_loss: 1.5936 - val_acc: 0.6313\n",
      "Epoch 929/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1487 - acc: 0.9606Epoch 00929: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.1465 - acc: 0.9634 - val_loss: 1.5301 - val_acc: 0.6364\n",
      "Epoch 930/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1728 - acc: 0.9565Epoch 00930: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.1734 - acc: 0.9571 - val_loss: 1.5757 - val_acc: 0.6414\n",
      "Epoch 931/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1629 - acc: 0.9538Epoch 00931: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1635 - acc: 0.9545 - val_loss: 1.5843 - val_acc: 0.6414\n",
      "Epoch 932/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1850 - acc: 0.9579Epoch 00932: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1830 - acc: 0.9583 - val_loss: 1.5696 - val_acc: 0.6465\n",
      "Epoch 933/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1816 - acc: 0.9579Epoch 00933: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1814 - acc: 0.9583 - val_loss: 1.5565 - val_acc: 0.6414\n",
      "Epoch 934/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1769 - acc: 0.9524Epoch 00934: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1700 - acc: 0.9558 - val_loss: 1.6378 - val_acc: 0.6162\n",
      "Epoch 935/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1619 - acc: 0.9579Epoch 00935: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1783 - acc: 0.9520 - val_loss: 1.5846 - val_acc: 0.6515\n",
      "Epoch 936/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1808 - acc: 0.9402Epoch 00936: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1746 - acc: 0.9432 - val_loss: 1.5651 - val_acc: 0.6414\n",
      "Epoch 937/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1678 - acc: 0.9511Epoch 00937: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.1664 - acc: 0.9520 - val_loss: 1.6472 - val_acc: 0.6111\n",
      "Epoch 938/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1661 - acc: 0.9620Epoch 00938: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1658 - acc: 0.9634 - val_loss: 1.5828 - val_acc: 0.6414\n",
      "Epoch 939/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1788 - acc: 0.9497Epoch 00939: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 0.1794 - acc: 0.9495 - val_loss: 1.5682 - val_acc: 0.6465\n",
      "Epoch 940/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1805 - acc: 0.9457Epoch 00940: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1815 - acc: 0.9444 - val_loss: 1.5962 - val_acc: 0.6111\n",
      "Epoch 941/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1405 - acc: 0.9674Epoch 00941: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1381 - acc: 0.9697 - val_loss: 1.5812 - val_acc: 0.6313\n",
      "Epoch 942/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1908 - acc: 0.9524Epoch 00942: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1857 - acc: 0.9545 - val_loss: 1.5835 - val_acc: 0.6515\n",
      "Epoch 943/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1824 - acc: 0.9443Epoch 00943: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 0.1844 - acc: 0.9444 - val_loss: 1.5661 - val_acc: 0.6313\n",
      "Epoch 944/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1487 - acc: 0.9633Epoch 00944: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1582 - acc: 0.9609 - val_loss: 1.6221 - val_acc: 0.6364\n",
      "Epoch 945/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1428 - acc: 0.9606Epoch 00945: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 0.1455 - acc: 0.9596 - val_loss: 1.6149 - val_acc: 0.6313\n",
      "Epoch 946/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1558 - acc: 0.9633Epoch 00946: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1575 - acc: 0.9621 - val_loss: 1.6247 - val_acc: 0.6061\n",
      "Epoch 947/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1419 - acc: 0.9620Epoch 00947: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1445 - acc: 0.9621 - val_loss: 1.6365 - val_acc: 0.6212\n",
      "Epoch 948/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1752 - acc: 0.9592Epoch 00948: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1727 - acc: 0.9609 - val_loss: 1.5996 - val_acc: 0.6263\n",
      "Epoch 949/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1445 - acc: 0.9674Epoch 00949: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1375 - acc: 0.9697 - val_loss: 1.5993 - val_acc: 0.6414\n",
      "Epoch 950/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1457 - acc: 0.9647Epoch 00950: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1460 - acc: 0.9634 - val_loss: 1.5946 - val_acc: 0.6162\n",
      "Epoch 951/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1558 - acc: 0.9633Epoch 00951: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1577 - acc: 0.9609 - val_loss: 1.6260 - val_acc: 0.6212\n",
      "Epoch 952/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1647 - acc: 0.9524Epoch 00952: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1610 - acc: 0.9545 - val_loss: 1.5667 - val_acc: 0.6263\n",
      "Epoch 953/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1539 - acc: 0.9606Epoch 00953: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1548 - acc: 0.9609 - val_loss: 1.5452 - val_acc: 0.6111\n",
      "Epoch 954/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1730 - acc: 0.9565Epoch 00954: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1662 - acc: 0.9583 - val_loss: 1.5533 - val_acc: 0.6212\n",
      "Epoch 955/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1613 - acc: 0.9524Epoch 00955: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 0.1601 - acc: 0.9520 - val_loss: 1.5353 - val_acc: 0.6616\n",
      "Epoch 956/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1560 - acc: 0.9647Epoch 00956: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1549 - acc: 0.9646 - val_loss: 1.5551 - val_acc: 0.6263\n",
      "Epoch 957/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1743 - acc: 0.9565Epoch 00957: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1693 - acc: 0.9571 - val_loss: 1.5446 - val_acc: 0.6465\n",
      "Epoch 958/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1651 - acc: 0.9511Epoch 00958: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1591 - acc: 0.9545 - val_loss: 1.5793 - val_acc: 0.6515\n",
      "Epoch 959/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1679 - acc: 0.9511Epoch 00959: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.1616 - acc: 0.9533 - val_loss: 1.6041 - val_acc: 0.6263\n",
      "Epoch 960/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1478 - acc: 0.9620Epoch 00960: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1496 - acc: 0.9609 - val_loss: 1.5829 - val_acc: 0.6263\n",
      "Epoch 961/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1479 - acc: 0.9647Epoch 00961: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1579 - acc: 0.9596 - val_loss: 1.6393 - val_acc: 0.6010\n",
      "Epoch 962/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1548 - acc: 0.9579Epoch 00962: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 0.1486 - acc: 0.9596 - val_loss: 1.5919 - val_acc: 0.6465\n",
      "Epoch 963/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1606 - acc: 0.9565Epoch 00963: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 0.1776 - acc: 0.9508 - val_loss: 1.5433 - val_acc: 0.6616\n",
      "Epoch 964/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1458 - acc: 0.9592Epoch 00964: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 0.1484 - acc: 0.9583 - val_loss: 1.6105 - val_acc: 0.6212\n",
      "Epoch 965/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1550 - acc: 0.9701Epoch 00965: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 0.1578 - acc: 0.9659 - val_loss: 1.5553 - val_acc: 0.6414\n",
      "Epoch 966/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1573 - acc: 0.9592Epoch 00966: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1616 - acc: 0.9571 - val_loss: 1.6079 - val_acc: 0.6212\n",
      "Epoch 967/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1682 - acc: 0.9538Epoch 00967: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1710 - acc: 0.9520 - val_loss: 1.5927 - val_acc: 0.6212\n",
      "Epoch 968/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1827 - acc: 0.9457Epoch 00968: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1757 - acc: 0.9482 - val_loss: 1.5419 - val_acc: 0.6465\n",
      "Epoch 969/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1884 - acc: 0.9429Epoch 00969: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1826 - acc: 0.9457 - val_loss: 1.5619 - val_acc: 0.6263\n",
      "Epoch 970/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1569 - acc: 0.9552Epoch 00970: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 0.1512 - acc: 0.9571 - val_loss: 1.6079 - val_acc: 0.6465\n",
      "Epoch 971/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1344 - acc: 0.9674Epoch 00971: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 0.1399 - acc: 0.9659 - val_loss: 1.6020 - val_acc: 0.6414\n",
      "Epoch 972/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1517 - acc: 0.9647Epoch 00972: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1499 - acc: 0.9659 - val_loss: 1.6435 - val_acc: 0.6010\n",
      "Epoch 973/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1691 - acc: 0.9497Epoch 00973: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 0.1720 - acc: 0.9508 - val_loss: 1.5539 - val_acc: 0.6364\n",
      "Epoch 974/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1510 - acc: 0.9592Epoch 00974: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 0.1599 - acc: 0.9571 - val_loss: 1.5656 - val_acc: 0.6364\n",
      "Epoch 975/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1299 - acc: 0.9688Epoch 00975: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 0.1279 - acc: 0.9697 - val_loss: 1.5446 - val_acc: 0.6364\n",
      "Epoch 976/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1442 - acc: 0.9633Epoch 00976: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1454 - acc: 0.9621 - val_loss: 1.6282 - val_acc: 0.6263\n",
      "Epoch 977/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1294 - acc: 0.9769Epoch 00977: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1276 - acc: 0.9773 - val_loss: 1.6187 - val_acc: 0.6465\n",
      "Epoch 978/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1665 - acc: 0.9524Epoch 00978: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1673 - acc: 0.9545 - val_loss: 1.6706 - val_acc: 0.6162\n",
      "Epoch 979/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1558 - acc: 0.9579Epoch 00979: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1525 - acc: 0.9609 - val_loss: 1.6576 - val_acc: 0.6212\n",
      "Epoch 980/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1579 - acc: 0.9660Epoch 00980: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1691 - acc: 0.9621 - val_loss: 1.6656 - val_acc: 0.6263\n",
      "Epoch 981/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1675 - acc: 0.9552Epoch 00981: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1695 - acc: 0.9545 - val_loss: 1.6548 - val_acc: 0.6465\n",
      "Epoch 982/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1584 - acc: 0.9620Epoch 00982: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1577 - acc: 0.9621 - val_loss: 1.6761 - val_acc: 0.6263\n",
      "Epoch 983/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1571 - acc: 0.9606Epoch 00983: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1536 - acc: 0.9609 - val_loss: 1.5994 - val_acc: 0.6515\n",
      "Epoch 984/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1302 - acc: 0.9701Epoch 00984: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1271 - acc: 0.9710 - val_loss: 1.6147 - val_acc: 0.6212\n",
      "Epoch 985/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1271 - acc: 0.9701Epoch 00985: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1304 - acc: 0.9684 - val_loss: 1.6779 - val_acc: 0.6010\n",
      "Epoch 986/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1640 - acc: 0.9647Epoch 00986: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1654 - acc: 0.9621 - val_loss: 1.6006 - val_acc: 0.6566\n",
      "Epoch 987/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1466 - acc: 0.9633Epoch 00987: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1488 - acc: 0.9634 - val_loss: 1.6388 - val_acc: 0.6212\n",
      "Epoch 988/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1723 - acc: 0.9497Epoch 00988: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1664 - acc: 0.9520 - val_loss: 1.5657 - val_acc: 0.6616\n",
      "Epoch 989/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1345 - acc: 0.9728Epoch 00989: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1336 - acc: 0.9722 - val_loss: 1.6522 - val_acc: 0.6162\n",
      "Epoch 990/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1631 - acc: 0.9511Epoch 00990: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1656 - acc: 0.9508 - val_loss: 1.6135 - val_acc: 0.6515\n",
      "Epoch 991/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1480 - acc: 0.9620Epoch 00991: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1520 - acc: 0.9609 - val_loss: 1.6402 - val_acc: 0.6566\n",
      "Epoch 992/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1415 - acc: 0.9633Epoch 00992: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1416 - acc: 0.9634 - val_loss: 1.6041 - val_acc: 0.6414\n",
      "Epoch 993/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1355 - acc: 0.9674Epoch 00993: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1408 - acc: 0.9646 - val_loss: 1.6174 - val_acc: 0.6263\n",
      "Epoch 994/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1765 - acc: 0.9524Epoch 00994: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1714 - acc: 0.9545 - val_loss: 1.5634 - val_acc: 0.6414\n",
      "Epoch 995/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1843 - acc: 0.9470Epoch 00995: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1810 - acc: 0.9482 - val_loss: 1.6478 - val_acc: 0.6414\n",
      "Epoch 996/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1669 - acc: 0.9511Epoch 00996: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1681 - acc: 0.9508 - val_loss: 1.6380 - val_acc: 0.6061\n",
      "Epoch 997/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1670 - acc: 0.9579Epoch 00997: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1630 - acc: 0.9596 - val_loss: 1.6601 - val_acc: 0.6212\n",
      "Epoch 998/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1243 - acc: 0.9742Epoch 00998: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1271 - acc: 0.9747 - val_loss: 1.6217 - val_acc: 0.6414\n",
      "Epoch 999/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1682 - acc: 0.9565Epoch 00999: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1625 - acc: 0.9596 - val_loss: 1.5802 - val_acc: 0.6515\n",
      "Epoch 1000/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1567 - acc: 0.9511Epoch 01000: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1610 - acc: 0.9508 - val_loss: 1.5746 - val_acc: 0.6364\n",
      "Epoch 1001/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1375 - acc: 0.9674Epoch 01001: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1393 - acc: 0.9672 - val_loss: 1.6485 - val_acc: 0.6162\n",
      "Epoch 1002/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1474 - acc: 0.9647Epoch 01002: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1479 - acc: 0.9646 - val_loss: 1.6317 - val_acc: 0.6111\n",
      "Epoch 1003/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1295 - acc: 0.9742Epoch 01003: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1357 - acc: 0.9735 - val_loss: 1.5865 - val_acc: 0.6212\n",
      "Epoch 1004/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1611 - acc: 0.9565Epoch 01004: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1588 - acc: 0.9571 - val_loss: 1.5654 - val_acc: 0.6364\n",
      "Epoch 1005/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1444 - acc: 0.9660Epoch 01005: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1411 - acc: 0.9672 - val_loss: 1.6449 - val_acc: 0.6162\n",
      "Epoch 1006/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1791 - acc: 0.9511Epoch 01006: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1712 - acc: 0.9545 - val_loss: 1.5812 - val_acc: 0.6465\n",
      "Epoch 1007/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1628 - acc: 0.9511Epoch 01007: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1609 - acc: 0.9520 - val_loss: 1.6186 - val_acc: 0.6364\n",
      "Epoch 1008/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1671 - acc: 0.9538Epoch 01008: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1640 - acc: 0.9533 - val_loss: 1.6241 - val_acc: 0.6263\n",
      "Epoch 1009/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1749 - acc: 0.9429Epoch 01009: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1678 - acc: 0.9457 - val_loss: 1.5904 - val_acc: 0.6263\n",
      "Epoch 1010/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1586 - acc: 0.9647Epoch 01010: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1520 - acc: 0.9672 - val_loss: 1.6010 - val_acc: 0.6313\n",
      "Epoch 1011/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1521 - acc: 0.9674Epoch 01011: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1526 - acc: 0.9659 - val_loss: 1.6110 - val_acc: 0.6162\n",
      "Epoch 1012/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1315 - acc: 0.9715Epoch 01012: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1306 - acc: 0.9710 - val_loss: 1.6154 - val_acc: 0.6263\n",
      "Epoch 1013/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1490 - acc: 0.9647Epoch 01013: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1460 - acc: 0.9659 - val_loss: 1.6407 - val_acc: 0.6263\n",
      "Epoch 1014/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1423 - acc: 0.9592Epoch 01014: val_loss did not improve\n",
      "792/792 [==============================] - 1s 931us/step - loss: 0.1410 - acc: 0.9583 - val_loss: 1.6075 - val_acc: 0.6263\n",
      "Epoch 1015/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1218 - acc: 0.9674Epoch 01015: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.1231 - acc: 0.9659 - val_loss: 1.6054 - val_acc: 0.6212\n",
      "Epoch 1016/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1692 - acc: 0.9633Epoch 01016: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1714 - acc: 0.9596 - val_loss: 1.6543 - val_acc: 0.6212\n",
      "Epoch 1017/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1427 - acc: 0.9592Epoch 01017: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1494 - acc: 0.9583 - val_loss: 1.6832 - val_acc: 0.6162\n",
      "Epoch 1018/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1486 - acc: 0.9674Epoch 01018: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1468 - acc: 0.9684 - val_loss: 1.6376 - val_acc: 0.6111\n",
      "Epoch 1019/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1271 - acc: 0.9674Epoch 01019: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1217 - acc: 0.9697 - val_loss: 1.6470 - val_acc: 0.6414\n",
      "Epoch 1020/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1807 - acc: 0.9524Epoch 01020: val_loss did not improve\n",
      "792/792 [==============================] - 1s 933us/step - loss: 0.1771 - acc: 0.9545 - val_loss: 1.6550 - val_acc: 0.6364\n",
      "Epoch 1021/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1337 - acc: 0.9647Epoch 01021: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1349 - acc: 0.9646 - val_loss: 1.6419 - val_acc: 0.6111\n",
      "Epoch 1022/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1257 - acc: 0.9715Epoch 01022: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1291 - acc: 0.9697 - val_loss: 1.5858 - val_acc: 0.6364\n",
      "Epoch 1023/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1347 - acc: 0.9660Epoch 01023: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1337 - acc: 0.9684 - val_loss: 1.5674 - val_acc: 0.6263\n",
      "Epoch 1024/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1329 - acc: 0.9755Epoch 01024: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1288 - acc: 0.9773 - val_loss: 1.5558 - val_acc: 0.6465\n",
      "Epoch 1025/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1297 - acc: 0.9688Epoch 01025: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1295 - acc: 0.9684 - val_loss: 1.5904 - val_acc: 0.6465\n",
      "Epoch 1026/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1579 - acc: 0.9565Epoch 01026: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1574 - acc: 0.9571 - val_loss: 1.6219 - val_acc: 0.6263\n",
      "Epoch 1027/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1677 - acc: 0.9511Epoch 01027: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1649 - acc: 0.9520 - val_loss: 1.6139 - val_acc: 0.6313\n",
      "Epoch 1028/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1111 - acc: 0.9715Epoch 01028: val_loss did not improve\n",
      "792/792 [==============================] - 1s 934us/step - loss: 0.1112 - acc: 0.9722 - val_loss: 1.6469 - val_acc: 0.6465\n",
      "Epoch 1029/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1559 - acc: 0.9579Epoch 01029: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1651 - acc: 0.9545 - val_loss: 1.6329 - val_acc: 0.6465\n",
      "Epoch 1030/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1446 - acc: 0.9620Epoch 01030: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1445 - acc: 0.9621 - val_loss: 1.6101 - val_acc: 0.6414\n",
      "Epoch 1031/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1425 - acc: 0.9620Epoch 01031: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1529 - acc: 0.9571 - val_loss: 1.5757 - val_acc: 0.6313\n",
      "Epoch 1032/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1369 - acc: 0.9647Epoch 01032: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1391 - acc: 0.9634 - val_loss: 1.5710 - val_acc: 0.6313\n",
      "Epoch 1033/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1519 - acc: 0.9565Epoch 01033: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1505 - acc: 0.9558 - val_loss: 1.5790 - val_acc: 0.6313\n",
      "Epoch 1034/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1390 - acc: 0.9674Epoch 01034: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1390 - acc: 0.9659 - val_loss: 1.5962 - val_acc: 0.6364\n",
      "Epoch 1035/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1492 - acc: 0.9674Epoch 01035: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1492 - acc: 0.9672 - val_loss: 1.6096 - val_acc: 0.6111\n",
      "Epoch 1036/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1566 - acc: 0.9620Epoch 01036: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1565 - acc: 0.9621 - val_loss: 1.5822 - val_acc: 0.6313\n",
      "Epoch 1037/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1117 - acc: 0.9755Epoch 01037: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1135 - acc: 0.9773 - val_loss: 1.5515 - val_acc: 0.6263\n",
      "Epoch 1038/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1338 - acc: 0.9674Epoch 01038: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1325 - acc: 0.9672 - val_loss: 1.5509 - val_acc: 0.6263\n",
      "Epoch 1039/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1539 - acc: 0.9592Epoch 01039: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1504 - acc: 0.9596 - val_loss: 1.5688 - val_acc: 0.6364\n",
      "Epoch 1040/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1466 - acc: 0.9552Epoch 01040: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1529 - acc: 0.9545 - val_loss: 1.5790 - val_acc: 0.6263\n",
      "Epoch 1041/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1425 - acc: 0.9660Epoch 01041: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1489 - acc: 0.9621 - val_loss: 1.5637 - val_acc: 0.6414\n",
      "Epoch 1042/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1462 - acc: 0.9620Epoch 01042: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1482 - acc: 0.9609 - val_loss: 1.5585 - val_acc: 0.6263\n",
      "Epoch 1043/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1888 - acc: 0.9511Epoch 01043: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1921 - acc: 0.9495 - val_loss: 1.5681 - val_acc: 0.6364\n",
      "Epoch 1044/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1674 - acc: 0.9538Epoch 01044: val_loss did not improve\n",
      "792/792 [==============================] - 1s 934us/step - loss: 0.1682 - acc: 0.9533 - val_loss: 1.5517 - val_acc: 0.6364\n",
      "Epoch 1045/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1454 - acc: 0.9633Epoch 01045: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1455 - acc: 0.9634 - val_loss: 1.6170 - val_acc: 0.6364\n",
      "Epoch 1046/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1640 - acc: 0.9552Epoch 01046: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1626 - acc: 0.9558 - val_loss: 1.6058 - val_acc: 0.6515\n",
      "Epoch 1047/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1505 - acc: 0.9565Epoch 01047: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1476 - acc: 0.9583 - val_loss: 1.5711 - val_acc: 0.6263\n",
      "Epoch 1048/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1489 - acc: 0.9633Epoch 01048: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.1510 - acc: 0.9621 - val_loss: 1.6031 - val_acc: 0.6465\n",
      "Epoch 1049/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1399 - acc: 0.9660Epoch 01049: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1433 - acc: 0.9646 - val_loss: 1.5869 - val_acc: 0.6313\n",
      "Epoch 1050/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1717 - acc: 0.9552Epoch 01050: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1758 - acc: 0.9533 - val_loss: 1.5736 - val_acc: 0.6313\n",
      "Epoch 1051/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1542 - acc: 0.9565Epoch 01051: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1541 - acc: 0.9583 - val_loss: 1.6030 - val_acc: 0.6212\n",
      "Epoch 1052/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1378 - acc: 0.9633Epoch 01052: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1351 - acc: 0.9646 - val_loss: 1.6019 - val_acc: 0.6263\n",
      "Epoch 1053/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1584 - acc: 0.9524Epoch 01053: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1641 - acc: 0.9508 - val_loss: 1.6125 - val_acc: 0.6263\n",
      "Epoch 1054/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1280 - acc: 0.9755Epoch 01054: val_loss did not improve\n",
      "792/792 [==============================] - 1s 933us/step - loss: 0.1310 - acc: 0.9735 - val_loss: 1.6341 - val_acc: 0.6212\n",
      "Epoch 1055/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1369 - acc: 0.9674Epoch 01055: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1355 - acc: 0.9697 - val_loss: 1.6589 - val_acc: 0.6212\n",
      "Epoch 1056/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1411 - acc: 0.9620Epoch 01056: val_loss did not improve\n",
      "792/792 [==============================] - 1s 931us/step - loss: 0.1384 - acc: 0.9634 - val_loss: 1.6047 - val_acc: 0.6414\n",
      "Epoch 1057/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1422 - acc: 0.9701Epoch 01057: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1506 - acc: 0.9659 - val_loss: 1.6089 - val_acc: 0.6313\n",
      "Epoch 1058/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1244 - acc: 0.9728Epoch 01058: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1249 - acc: 0.9722 - val_loss: 1.6310 - val_acc: 0.6364\n",
      "Epoch 1059/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1669 - acc: 0.9524Epoch 01059: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1695 - acc: 0.9508 - val_loss: 1.6232 - val_acc: 0.6465\n",
      "Epoch 1060/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1249 - acc: 0.9701Epoch 01060: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1286 - acc: 0.9684 - val_loss: 1.5969 - val_acc: 0.6313\n",
      "Epoch 1061/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1498 - acc: 0.9647Epoch 01061: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1456 - acc: 0.9659 - val_loss: 1.6475 - val_acc: 0.6263\n",
      "Epoch 1062/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1662 - acc: 0.9524Epoch 01062: val_loss did not improve\n",
      "792/792 [==============================] - 1s 930us/step - loss: 0.1686 - acc: 0.9508 - val_loss: 1.5839 - val_acc: 0.6465\n",
      "Epoch 1063/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1582 - acc: 0.9565Epoch 01063: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1594 - acc: 0.9583 - val_loss: 1.6590 - val_acc: 0.6566\n",
      "Epoch 1064/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1583 - acc: 0.9579Epoch 01064: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1560 - acc: 0.9596 - val_loss: 1.7016 - val_acc: 0.6212\n",
      "Epoch 1065/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1266 - acc: 0.9674Epoch 01065: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1221 - acc: 0.9697 - val_loss: 1.6352 - val_acc: 0.6212\n",
      "Epoch 1066/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1003 - acc: 0.9783Epoch 01066: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1023 - acc: 0.9760 - val_loss: 1.5309 - val_acc: 0.6465\n",
      "Epoch 1067/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1247 - acc: 0.9688Epoch 01067: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1244 - acc: 0.9684 - val_loss: 1.6244 - val_acc: 0.6364\n",
      "Epoch 1068/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1252 - acc: 0.9715Epoch 01068: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1254 - acc: 0.9710 - val_loss: 1.6444 - val_acc: 0.6364\n",
      "Epoch 1069/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1590 - acc: 0.9552Epoch 01069: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1554 - acc: 0.9558 - val_loss: 1.6009 - val_acc: 0.6414\n",
      "Epoch 1070/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1322 - acc: 0.9647Epoch 01070: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.1273 - acc: 0.9672 - val_loss: 1.6149 - val_acc: 0.6465\n",
      "Epoch 1071/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1272 - acc: 0.9701Epoch 01071: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1410 - acc: 0.9634 - val_loss: 1.6776 - val_acc: 0.6212\n",
      "Epoch 1072/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1495 - acc: 0.9565Epoch 01072: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1460 - acc: 0.9583 - val_loss: 1.6874 - val_acc: 0.6465\n",
      "Epoch 1073/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1296 - acc: 0.9728Epoch 01073: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1358 - acc: 0.9697 - val_loss: 1.6613 - val_acc: 0.6414\n",
      "Epoch 1074/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1295 - acc: 0.9769Epoch 01074: val_loss did not improve\n",
      "792/792 [==============================] - 1s 933us/step - loss: 0.1301 - acc: 0.9760 - val_loss: 1.6744 - val_acc: 0.6111\n",
      "Epoch 1075/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1416 - acc: 0.9620Epoch 01075: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.1380 - acc: 0.9646 - val_loss: 1.6484 - val_acc: 0.6111\n",
      "Epoch 1076/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1328 - acc: 0.9674Epoch 01076: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1395 - acc: 0.9672 - val_loss: 1.6540 - val_acc: 0.6212\n",
      "Epoch 1077/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1452 - acc: 0.9579Epoch 01077: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1451 - acc: 0.9571 - val_loss: 1.6659 - val_acc: 0.6162\n",
      "Epoch 1078/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1453 - acc: 0.9620Epoch 01078: val_loss did not improve\n",
      "792/792 [==============================] - 1s 930us/step - loss: 0.1444 - acc: 0.9609 - val_loss: 1.6476 - val_acc: 0.6061\n",
      "Epoch 1079/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1429 - acc: 0.9606Epoch 01079: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1408 - acc: 0.9621 - val_loss: 1.6529 - val_acc: 0.6313\n",
      "Epoch 1080/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1314 - acc: 0.9755Epoch 01080: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1377 - acc: 0.9722 - val_loss: 1.6052 - val_acc: 0.6414\n",
      "Epoch 1081/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1554 - acc: 0.9592Epoch 01081: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1531 - acc: 0.9609 - val_loss: 1.6248 - val_acc: 0.6313\n",
      "Epoch 1082/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1445 - acc: 0.9660Epoch 01082: val_loss did not improve\n",
      "792/792 [==============================] - 1s 933us/step - loss: 0.1442 - acc: 0.9634 - val_loss: 1.6143 - val_acc: 0.6212\n",
      "Epoch 1083/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1461 - acc: 0.9592Epoch 01083: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1449 - acc: 0.9583 - val_loss: 1.7097 - val_acc: 0.6465\n",
      "Epoch 1084/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1382 - acc: 0.9674Epoch 01084: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1362 - acc: 0.9697 - val_loss: 1.5978 - val_acc: 0.6465\n",
      "Epoch 1085/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1676 - acc: 0.9592Epoch 01085: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1669 - acc: 0.9583 - val_loss: 1.5899 - val_acc: 0.6364\n",
      "Epoch 1086/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1369 - acc: 0.9674Epoch 01086: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1469 - acc: 0.9646 - val_loss: 1.6371 - val_acc: 0.6263\n",
      "Epoch 1087/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1235 - acc: 0.9647Epoch 01087: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1289 - acc: 0.9646 - val_loss: 1.6656 - val_acc: 0.6212\n",
      "Epoch 1088/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1474 - acc: 0.9552Epoch 01088: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1582 - acc: 0.9533 - val_loss: 1.5518 - val_acc: 0.6768\n",
      "Epoch 1089/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1465 - acc: 0.9633Epoch 01089: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1422 - acc: 0.9659 - val_loss: 1.6267 - val_acc: 0.6465\n",
      "Epoch 1090/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1254 - acc: 0.9701Epoch 01090: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1242 - acc: 0.9710 - val_loss: 1.5858 - val_acc: 0.6515\n",
      "Epoch 1091/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1713 - acc: 0.9565Epoch 01091: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1720 - acc: 0.9571 - val_loss: 1.6230 - val_acc: 0.6414\n",
      "Epoch 1092/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1229 - acc: 0.9688Epoch 01092: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1252 - acc: 0.9684 - val_loss: 1.6007 - val_acc: 0.6263\n",
      "Epoch 1093/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1211 - acc: 0.9742Epoch 01093: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1212 - acc: 0.9735 - val_loss: 1.6235 - val_acc: 0.6465\n",
      "Epoch 1094/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1402 - acc: 0.9620Epoch 01094: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1332 - acc: 0.9646 - val_loss: 1.6563 - val_acc: 0.6414\n",
      "Epoch 1095/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1430 - acc: 0.9674Epoch 01095: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1410 - acc: 0.9684 - val_loss: 1.6641 - val_acc: 0.6111\n",
      "Epoch 1096/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1550 - acc: 0.9647Epoch 01096: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1615 - acc: 0.9621 - val_loss: 1.6351 - val_acc: 0.6364\n",
      "Epoch 1097/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1373 - acc: 0.9660Epoch 01097: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1353 - acc: 0.9672 - val_loss: 1.5836 - val_acc: 0.6414\n",
      "Epoch 1098/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1239 - acc: 0.9755Epoch 01098: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1269 - acc: 0.9735 - val_loss: 1.5772 - val_acc: 0.6313\n",
      "Epoch 1099/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1702 - acc: 0.9552Epoch 01099: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1658 - acc: 0.9571 - val_loss: 1.6377 - val_acc: 0.6414\n",
      "Epoch 1100/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1741 - acc: 0.9565Epoch 01100: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1717 - acc: 0.9571 - val_loss: 1.6271 - val_acc: 0.6414\n",
      "Epoch 1101/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1458 - acc: 0.9565Epoch 01101: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1467 - acc: 0.9571 - val_loss: 1.6120 - val_acc: 0.6465\n",
      "Epoch 1102/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1566 - acc: 0.9538Epoch 01102: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1585 - acc: 0.9533 - val_loss: 1.5766 - val_acc: 0.6515\n",
      "Epoch 1103/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1831 - acc: 0.9511Epoch 01103: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1748 - acc: 0.9533 - val_loss: 1.6390 - val_acc: 0.6364\n",
      "Epoch 1104/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1552 - acc: 0.9674Epoch 01104: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1592 - acc: 0.9634 - val_loss: 1.5675 - val_acc: 0.6364\n",
      "Epoch 1105/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1462 - acc: 0.9674Epoch 01105: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1482 - acc: 0.9659 - val_loss: 1.6541 - val_acc: 0.6313\n",
      "Epoch 1106/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1344 - acc: 0.9633Epoch 01106: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1363 - acc: 0.9621 - val_loss: 1.6046 - val_acc: 0.6212\n",
      "Epoch 1107/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1580 - acc: 0.9511Epoch 01107: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1501 - acc: 0.9545 - val_loss: 1.5873 - val_acc: 0.6616\n",
      "Epoch 1108/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1426 - acc: 0.9688Epoch 01108: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1426 - acc: 0.9684 - val_loss: 1.6853 - val_acc: 0.6111\n",
      "Epoch 1109/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1465 - acc: 0.9647Epoch 01109: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1417 - acc: 0.9672 - val_loss: 1.6044 - val_acc: 0.6364\n",
      "Epoch 1110/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1281 - acc: 0.9660Epoch 01110: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1349 - acc: 0.9634 - val_loss: 1.6702 - val_acc: 0.6162\n",
      "Epoch 1111/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1364 - acc: 0.9565Epoch 01111: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1336 - acc: 0.9583 - val_loss: 1.6235 - val_acc: 0.6263\n",
      "Epoch 1112/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1555 - acc: 0.9565Epoch 01112: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1528 - acc: 0.9571 - val_loss: 1.6176 - val_acc: 0.6364\n",
      "Epoch 1113/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1537 - acc: 0.9579Epoch 01113: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1473 - acc: 0.9609 - val_loss: 1.6078 - val_acc: 0.6616\n",
      "Epoch 1114/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1345 - acc: 0.9592Epoch 01114: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1534 - acc: 0.9545 - val_loss: 1.7410 - val_acc: 0.6263\n",
      "Epoch 1115/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1525 - acc: 0.9620Epoch 01115: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1479 - acc: 0.9621 - val_loss: 1.5992 - val_acc: 0.6313\n",
      "Epoch 1116/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1385 - acc: 0.9606Epoch 01116: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1380 - acc: 0.9621 - val_loss: 1.6122 - val_acc: 0.6263\n",
      "Epoch 1117/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1882 - acc: 0.9538Epoch 01117: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1820 - acc: 0.9558 - val_loss: 1.6139 - val_acc: 0.6313\n",
      "Epoch 1118/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1228 - acc: 0.9701Epoch 01118: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.1234 - acc: 0.9697 - val_loss: 1.6306 - val_acc: 0.6313\n",
      "Epoch 1119/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1492 - acc: 0.9592Epoch 01119: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.1501 - acc: 0.9609 - val_loss: 1.6406 - val_acc: 0.6263\n",
      "Epoch 1120/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1365 - acc: 0.9674Epoch 01120: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1412 - acc: 0.9672 - val_loss: 1.6591 - val_acc: 0.6364\n",
      "Epoch 1121/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1379 - acc: 0.9647Epoch 01121: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1394 - acc: 0.9634 - val_loss: 1.6526 - val_acc: 0.6313\n",
      "Epoch 1122/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1327 - acc: 0.9647Epoch 01122: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1355 - acc: 0.9646 - val_loss: 1.5901 - val_acc: 0.6414\n",
      "Epoch 1123/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1247 - acc: 0.9701Epoch 01123: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1214 - acc: 0.9710 - val_loss: 1.6297 - val_acc: 0.6465\n",
      "Epoch 1124/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1354 - acc: 0.9647Epoch 01124: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1329 - acc: 0.9672 - val_loss: 1.6241 - val_acc: 0.6263\n",
      "Epoch 1125/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1564 - acc: 0.9620Epoch 01125: val_loss did not improve\n",
      "792/792 [==============================] - 1s 931us/step - loss: 0.1546 - acc: 0.9634 - val_loss: 1.6155 - val_acc: 0.6566\n",
      "Epoch 1126/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1220 - acc: 0.9755Epoch 01126: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1277 - acc: 0.9735 - val_loss: 1.5546 - val_acc: 0.6515\n",
      "Epoch 1127/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1420 - acc: 0.9606Epoch 01127: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1398 - acc: 0.9634 - val_loss: 1.5689 - val_acc: 0.6515\n",
      "Epoch 1128/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1477 - acc: 0.9565Epoch 01128: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1456 - acc: 0.9596 - val_loss: 1.6397 - val_acc: 0.6263\n",
      "Epoch 1129/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1563 - acc: 0.9620Epoch 01129: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1585 - acc: 0.9609 - val_loss: 1.5992 - val_acc: 0.6566\n",
      "Epoch 1130/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1432 - acc: 0.9579Epoch 01130: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1380 - acc: 0.9596 - val_loss: 1.6115 - val_acc: 0.6515\n",
      "Epoch 1131/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1524 - acc: 0.9647Epoch 01131: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1457 - acc: 0.9659 - val_loss: 1.6305 - val_acc: 0.6667\n",
      "Epoch 1132/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1661 - acc: 0.9511Epoch 01132: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1620 - acc: 0.9533 - val_loss: 1.6228 - val_acc: 0.6313\n",
      "Epoch 1133/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1437 - acc: 0.9620Epoch 01133: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1442 - acc: 0.9621 - val_loss: 1.5868 - val_acc: 0.6364\n",
      "Epoch 1134/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1410 - acc: 0.9620Epoch 01134: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1416 - acc: 0.9634 - val_loss: 1.6822 - val_acc: 0.6061\n",
      "Epoch 1135/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1321 - acc: 0.9701Epoch 01135: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1358 - acc: 0.9697 - val_loss: 1.5974 - val_acc: 0.6566\n",
      "Epoch 1136/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1497 - acc: 0.9633Epoch 01136: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1504 - acc: 0.9609 - val_loss: 1.6557 - val_acc: 0.6111\n",
      "Epoch 1137/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1645 - acc: 0.9552Epoch 01137: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1667 - acc: 0.9545 - val_loss: 1.6380 - val_acc: 0.6162\n",
      "Epoch 1138/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1514 - acc: 0.9579Epoch 01138: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1510 - acc: 0.9571 - val_loss: 1.5729 - val_acc: 0.6515\n",
      "Epoch 1139/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1355 - acc: 0.9660Epoch 01139: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1314 - acc: 0.9672 - val_loss: 1.6452 - val_acc: 0.6364\n",
      "Epoch 1140/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1395 - acc: 0.9660Epoch 01140: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1347 - acc: 0.9672 - val_loss: 1.5622 - val_acc: 0.6465\n",
      "Epoch 1141/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1123 - acc: 0.9701Epoch 01141: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1135 - acc: 0.9697 - val_loss: 1.5710 - val_acc: 0.6465\n",
      "Epoch 1142/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1181 - acc: 0.9715Epoch 01142: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1233 - acc: 0.9697 - val_loss: 1.6206 - val_acc: 0.6111\n",
      "Epoch 1143/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1588 - acc: 0.9620Epoch 01143: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1575 - acc: 0.9634 - val_loss: 1.6130 - val_acc: 0.6111\n",
      "Epoch 1144/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1328 - acc: 0.9647Epoch 01144: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1283 - acc: 0.9672 - val_loss: 1.6576 - val_acc: 0.6313\n",
      "Epoch 1145/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1270 - acc: 0.9755Epoch 01145: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1316 - acc: 0.9760 - val_loss: 1.5587 - val_acc: 0.6465\n",
      "Epoch 1146/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1315 - acc: 0.9674Epoch 01146: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1289 - acc: 0.9684 - val_loss: 1.5972 - val_acc: 0.6212\n",
      "Epoch 1147/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1551 - acc: 0.9565Epoch 01147: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1559 - acc: 0.9558 - val_loss: 1.6141 - val_acc: 0.6465\n",
      "Epoch 1148/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1442 - acc: 0.9647Epoch 01148: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1456 - acc: 0.9646 - val_loss: 1.6154 - val_acc: 0.6364\n",
      "Epoch 1149/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1591 - acc: 0.9565Epoch 01149: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1582 - acc: 0.9583 - val_loss: 1.5795 - val_acc: 0.6414\n",
      "Epoch 1150/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1416 - acc: 0.9647Epoch 01150: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1353 - acc: 0.9672 - val_loss: 1.6053 - val_acc: 0.6465\n",
      "Epoch 1151/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1350 - acc: 0.9497Epoch 01151: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1319 - acc: 0.9520 - val_loss: 1.5905 - val_acc: 0.6465\n",
      "Epoch 1152/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1435 - acc: 0.9565Epoch 01152: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1489 - acc: 0.9558 - val_loss: 1.5788 - val_acc: 0.6465\n",
      "Epoch 1153/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1447 - acc: 0.9633Epoch 01153: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1576 - acc: 0.9583 - val_loss: 1.5927 - val_acc: 0.6414\n",
      "Epoch 1154/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1422 - acc: 0.9674Epoch 01154: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1475 - acc: 0.9659 - val_loss: 1.6447 - val_acc: 0.6313\n",
      "Epoch 1155/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1544 - acc: 0.9606Epoch 01155: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1559 - acc: 0.9609 - val_loss: 1.6493 - val_acc: 0.6313\n",
      "Epoch 1156/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1378 - acc: 0.9660Epoch 01156: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1381 - acc: 0.9634 - val_loss: 1.6375 - val_acc: 0.6313\n",
      "Epoch 1157/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1252 - acc: 0.9647Epoch 01157: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1292 - acc: 0.9634 - val_loss: 1.6180 - val_acc: 0.6212\n",
      "Epoch 1158/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1344 - acc: 0.9660Epoch 01158: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1385 - acc: 0.9646 - val_loss: 1.6461 - val_acc: 0.6162\n",
      "Epoch 1159/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1208 - acc: 0.9728Epoch 01159: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1236 - acc: 0.9722 - val_loss: 1.5588 - val_acc: 0.6667\n",
      "Epoch 1160/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1615 - acc: 0.9565Epoch 01160: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1610 - acc: 0.9571 - val_loss: 1.5282 - val_acc: 0.6566\n",
      "Epoch 1161/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1609 - acc: 0.9443Epoch 01161: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1542 - acc: 0.9482 - val_loss: 1.5907 - val_acc: 0.6465\n",
      "Epoch 1162/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1452 - acc: 0.9620Epoch 01162: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1430 - acc: 0.9634 - val_loss: 1.6577 - val_acc: 0.6212\n",
      "Epoch 1163/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1381 - acc: 0.9715Epoch 01163: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1359 - acc: 0.9710 - val_loss: 1.6201 - val_acc: 0.6465\n",
      "Epoch 1164/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1354 - acc: 0.9647Epoch 01164: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1320 - acc: 0.9659 - val_loss: 1.6180 - val_acc: 0.6414\n",
      "Epoch 1165/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1527 - acc: 0.9538Epoch 01165: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1522 - acc: 0.9545 - val_loss: 1.5534 - val_acc: 0.6364\n",
      "Epoch 1166/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1214 - acc: 0.9674Epoch 01166: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1250 - acc: 0.9684 - val_loss: 1.5918 - val_acc: 0.6364\n",
      "Epoch 1167/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1381 - acc: 0.9688Epoch 01167: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1502 - acc: 0.9646 - val_loss: 1.5764 - val_acc: 0.6566\n",
      "Epoch 1168/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1365 - acc: 0.9660Epoch 01168: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1364 - acc: 0.9659 - val_loss: 1.6256 - val_acc: 0.6364\n",
      "Epoch 1169/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1380 - acc: 0.9633Epoch 01169: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1350 - acc: 0.9634 - val_loss: 1.5415 - val_acc: 0.6515\n",
      "Epoch 1170/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1227 - acc: 0.9688Epoch 01170: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1229 - acc: 0.9684 - val_loss: 1.5602 - val_acc: 0.6465\n",
      "Epoch 1171/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1428 - acc: 0.9660Epoch 01171: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1394 - acc: 0.9672 - val_loss: 1.6311 - val_acc: 0.6515\n",
      "Epoch 1172/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1470 - acc: 0.9538Epoch 01172: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1461 - acc: 0.9558 - val_loss: 1.5800 - val_acc: 0.6566\n",
      "Epoch 1173/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1577 - acc: 0.9592Epoch 01173: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1550 - acc: 0.9596 - val_loss: 1.5816 - val_acc: 0.6465\n",
      "Epoch 1174/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1620 - acc: 0.9524Epoch 01174: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1597 - acc: 0.9533 - val_loss: 1.6151 - val_acc: 0.6515\n",
      "Epoch 1175/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1455 - acc: 0.9579Epoch 01175: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1421 - acc: 0.9596 - val_loss: 1.5998 - val_acc: 0.6566\n",
      "Epoch 1176/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1372 - acc: 0.9606Epoch 01176: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1442 - acc: 0.9596 - val_loss: 1.6334 - val_acc: 0.6414\n",
      "Epoch 1177/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1572 - acc: 0.9552Epoch 01177: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.1692 - acc: 0.9520 - val_loss: 1.5552 - val_acc: 0.6667\n",
      "Epoch 1178/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1449 - acc: 0.9688Epoch 01178: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1514 - acc: 0.9672 - val_loss: 1.5951 - val_acc: 0.6515\n",
      "Epoch 1179/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1420 - acc: 0.9660Epoch 01179: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1399 - acc: 0.9672 - val_loss: 1.6073 - val_acc: 0.6313\n",
      "Epoch 1180/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1269 - acc: 0.9660Epoch 01180: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1340 - acc: 0.9634 - val_loss: 1.6222 - val_acc: 0.6414\n",
      "Epoch 1181/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1542 - acc: 0.9592Epoch 01181: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1488 - acc: 0.9609 - val_loss: 1.6059 - val_acc: 0.6566\n",
      "Epoch 1182/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1161 - acc: 0.9674Epoch 01182: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1172 - acc: 0.9672 - val_loss: 1.5782 - val_acc: 0.6515\n",
      "Epoch 1183/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1556 - acc: 0.9524Epoch 01183: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1584 - acc: 0.9520 - val_loss: 1.6105 - val_acc: 0.6414\n",
      "Epoch 1184/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1425 - acc: 0.9565Epoch 01184: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1477 - acc: 0.9558 - val_loss: 1.6425 - val_acc: 0.6263\n",
      "Epoch 1185/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1182 - acc: 0.9701Epoch 01185: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1174 - acc: 0.9697 - val_loss: 1.6630 - val_acc: 0.6263\n",
      "Epoch 1186/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1201 - acc: 0.9688Epoch 01186: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1190 - acc: 0.9697 - val_loss: 1.6333 - val_acc: 0.6111\n",
      "Epoch 1187/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1462 - acc: 0.9552Epoch 01187: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1444 - acc: 0.9558 - val_loss: 1.6089 - val_acc: 0.6313\n",
      "Epoch 1188/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1655 - acc: 0.9620Epoch 01188: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1653 - acc: 0.9621 - val_loss: 1.5950 - val_acc: 0.6263\n",
      "Epoch 1189/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1451 - acc: 0.9660Epoch 01189: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1450 - acc: 0.9659 - val_loss: 1.6652 - val_acc: 0.6162\n",
      "Epoch 1190/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1542 - acc: 0.9565Epoch 01190: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1522 - acc: 0.9583 - val_loss: 1.6253 - val_acc: 0.6414\n",
      "Epoch 1191/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1506 - acc: 0.9606Epoch 01191: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1472 - acc: 0.9609 - val_loss: 1.6042 - val_acc: 0.6465\n",
      "Epoch 1192/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1401 - acc: 0.9565Epoch 01192: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1424 - acc: 0.9571 - val_loss: 1.5712 - val_acc: 0.6667\n",
      "Epoch 1193/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1613 - acc: 0.9606Epoch 01193: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.1582 - acc: 0.9621 - val_loss: 1.6056 - val_acc: 0.6364\n",
      "Epoch 1194/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1596 - acc: 0.9552Epoch 01194: val_loss did not improve\n",
      "792/792 [==============================] - 1s 932us/step - loss: 0.1573 - acc: 0.9558 - val_loss: 1.5805 - val_acc: 0.6263\n",
      "Epoch 1195/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1432 - acc: 0.9647Epoch 01195: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1394 - acc: 0.9659 - val_loss: 1.6003 - val_acc: 0.6364\n",
      "Epoch 1196/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1569 - acc: 0.9579Epoch 01196: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1539 - acc: 0.9596 - val_loss: 1.6055 - val_acc: 0.6313\n",
      "Epoch 1197/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1354 - acc: 0.9674Epoch 01197: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1349 - acc: 0.9672 - val_loss: 1.6163 - val_acc: 0.6263\n",
      "Epoch 1198/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1555 - acc: 0.9565Epoch 01198: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1535 - acc: 0.9571 - val_loss: 1.5723 - val_acc: 0.6313\n",
      "Epoch 1199/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1327 - acc: 0.9633Epoch 01199: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1340 - acc: 0.9621 - val_loss: 1.5416 - val_acc: 0.6212\n",
      "Epoch 1200/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1300 - acc: 0.9660Epoch 01200: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1380 - acc: 0.9621 - val_loss: 1.6434 - val_acc: 0.6263\n",
      "Epoch 1201/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1293 - acc: 0.9688Epoch 01201: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1267 - acc: 0.9710 - val_loss: 1.5971 - val_acc: 0.6566\n",
      "Epoch 1202/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1256 - acc: 0.9728Epoch 01202: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1234 - acc: 0.9735 - val_loss: 1.6337 - val_acc: 0.6566\n",
      "Epoch 1203/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1472 - acc: 0.9688Epoch 01203: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1501 - acc: 0.9672 - val_loss: 1.6429 - val_acc: 0.6061\n",
      "Epoch 1204/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1496 - acc: 0.9592Epoch 01204: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1470 - acc: 0.9609 - val_loss: 1.6099 - val_acc: 0.6364\n",
      "Epoch 1205/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1299 - acc: 0.9633Epoch 01205: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1342 - acc: 0.9609 - val_loss: 1.6570 - val_acc: 0.6364\n",
      "Epoch 1206/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1654 - acc: 0.9470Epoch 01206: val_loss did not improve\n",
      "792/792 [==============================] - 1s 934us/step - loss: 0.1615 - acc: 0.9495 - val_loss: 1.5759 - val_acc: 0.6465\n",
      "Epoch 1207/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1123 - acc: 0.9755Epoch 01207: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1121 - acc: 0.9735 - val_loss: 1.6486 - val_acc: 0.6111\n",
      "Epoch 1208/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1347 - acc: 0.9715Epoch 01208: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1321 - acc: 0.9697 - val_loss: 1.6985 - val_acc: 0.6212\n",
      "Epoch 1209/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1483 - acc: 0.9592Epoch 01209: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1536 - acc: 0.9571 - val_loss: 1.6887 - val_acc: 0.6061\n",
      "Epoch 1210/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1279 - acc: 0.9633Epoch 01210: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1287 - acc: 0.9634 - val_loss: 1.6138 - val_acc: 0.6313\n",
      "Epoch 1211/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1356 - acc: 0.9660Epoch 01211: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1345 - acc: 0.9659 - val_loss: 1.6135 - val_acc: 0.6212\n",
      "Epoch 1212/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1138 - acc: 0.9688Epoch 01212: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1179 - acc: 0.9659 - val_loss: 1.5611 - val_acc: 0.6313\n",
      "Epoch 1213/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1516 - acc: 0.9579Epoch 01213: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1492 - acc: 0.9596 - val_loss: 1.5368 - val_acc: 0.6313\n",
      "Epoch 1214/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1311 - acc: 0.9620Epoch 01214: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1280 - acc: 0.9621 - val_loss: 1.6503 - val_acc: 0.6414\n",
      "Epoch 1215/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1662 - acc: 0.9579Epoch 01215: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1613 - acc: 0.9596 - val_loss: 1.6797 - val_acc: 0.6263\n",
      "Epoch 1216/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1323 - acc: 0.9674Epoch 01216: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1282 - acc: 0.9697 - val_loss: 1.6537 - val_acc: 0.6263\n",
      "Epoch 1217/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1243 - acc: 0.9728Epoch 01217: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1246 - acc: 0.9722 - val_loss: 1.6535 - val_acc: 0.6162\n",
      "Epoch 1218/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1357 - acc: 0.9674Epoch 01218: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1445 - acc: 0.9634 - val_loss: 1.6316 - val_acc: 0.6263\n",
      "Epoch 1219/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1404 - acc: 0.9620Epoch 01219: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1354 - acc: 0.9646 - val_loss: 1.6366 - val_acc: 0.6364\n",
      "Epoch 1220/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1195 - acc: 0.9701Epoch 01220: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1177 - acc: 0.9722 - val_loss: 1.6653 - val_acc: 0.6414\n",
      "Epoch 1221/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1413 - acc: 0.9647Epoch 01221: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1424 - acc: 0.9646 - val_loss: 1.6888 - val_acc: 0.6111\n",
      "Epoch 1222/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1636 - acc: 0.9524Epoch 01222: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1590 - acc: 0.9533 - val_loss: 1.6109 - val_acc: 0.6414\n",
      "Epoch 1223/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1557 - acc: 0.9565Epoch 01223: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1592 - acc: 0.9545 - val_loss: 1.5835 - val_acc: 0.6313\n",
      "Epoch 1224/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1297 - acc: 0.9715Epoch 01224: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1258 - acc: 0.9735 - val_loss: 1.6418 - val_acc: 0.6364\n",
      "Epoch 1225/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1294 - acc: 0.9674Epoch 01225: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1278 - acc: 0.9684 - val_loss: 1.6324 - val_acc: 0.6313\n",
      "Epoch 1226/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1260 - acc: 0.9715Epoch 01226: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1207 - acc: 0.9735 - val_loss: 1.6896 - val_acc: 0.6263\n",
      "Epoch 1227/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1228 - acc: 0.9701Epoch 01227: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1226 - acc: 0.9722 - val_loss: 1.6217 - val_acc: 0.6212\n",
      "Epoch 1228/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1332 - acc: 0.9701Epoch 01228: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1345 - acc: 0.9672 - val_loss: 1.6718 - val_acc: 0.6010\n",
      "Epoch 1229/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1260 - acc: 0.9674Epoch 01229: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1286 - acc: 0.9672 - val_loss: 1.6292 - val_acc: 0.6313\n",
      "Epoch 1230/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1202 - acc: 0.9647Epoch 01230: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1189 - acc: 0.9659 - val_loss: 1.6160 - val_acc: 0.6313\n",
      "Epoch 1231/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1515 - acc: 0.9579Epoch 01231: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1465 - acc: 0.9609 - val_loss: 1.6207 - val_acc: 0.6364\n",
      "Epoch 1232/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1010 - acc: 0.9701Epoch 01232: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1079 - acc: 0.9684 - val_loss: 1.6082 - val_acc: 0.6414\n",
      "Epoch 1233/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1538 - acc: 0.9606Epoch 01233: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1493 - acc: 0.9621 - val_loss: 1.6551 - val_acc: 0.6263\n",
      "Epoch 1234/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1010 - acc: 0.9837Epoch 01234: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1052 - acc: 0.9811 - val_loss: 1.5986 - val_acc: 0.6465\n",
      "Epoch 1235/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1118 - acc: 0.9728Epoch 01235: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1138 - acc: 0.9722 - val_loss: 1.5906 - val_acc: 0.6465\n",
      "Epoch 1236/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1369 - acc: 0.9647Epoch 01236: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1421 - acc: 0.9609 - val_loss: 1.5636 - val_acc: 0.6263\n",
      "Epoch 1237/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1186 - acc: 0.9688Epoch 01237: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1202 - acc: 0.9697 - val_loss: 1.5800 - val_acc: 0.6566\n",
      "Epoch 1238/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1198 - acc: 0.9688Epoch 01238: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1147 - acc: 0.9697 - val_loss: 1.6044 - val_acc: 0.6465\n",
      "Epoch 1239/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1389 - acc: 0.9579Epoch 01239: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1370 - acc: 0.9583 - val_loss: 1.6139 - val_acc: 0.6414\n",
      "Epoch 1240/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1522 - acc: 0.9592Epoch 01240: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1466 - acc: 0.9609 - val_loss: 1.5383 - val_acc: 0.6162\n",
      "Epoch 1241/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1474 - acc: 0.9674Epoch 01241: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 0.1460 - acc: 0.9684 - val_loss: 1.5860 - val_acc: 0.6465\n",
      "Epoch 1242/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1369 - acc: 0.9647Epoch 01242: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1380 - acc: 0.9646 - val_loss: 1.5809 - val_acc: 0.6515\n",
      "Epoch 1243/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0951 - acc: 0.9796Epoch 01243: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.0926 - acc: 0.9811 - val_loss: 1.5895 - val_acc: 0.6616\n",
      "Epoch 1244/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1198 - acc: 0.9769Epoch 01244: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1161 - acc: 0.9785 - val_loss: 1.6548 - val_acc: 0.6263\n",
      "Epoch 1245/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1463 - acc: 0.9592Epoch 01245: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1427 - acc: 0.9596 - val_loss: 1.6109 - val_acc: 0.6465\n",
      "Epoch 1246/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1382 - acc: 0.9606Epoch 01246: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1385 - acc: 0.9596 - val_loss: 1.6954 - val_acc: 0.6263\n",
      "Epoch 1247/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1218 - acc: 0.9742Epoch 01247: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1202 - acc: 0.9760 - val_loss: 1.6342 - val_acc: 0.6414\n",
      "Epoch 1248/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1421 - acc: 0.9592Epoch 01248: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1372 - acc: 0.9621 - val_loss: 1.6692 - val_acc: 0.6313\n",
      "Epoch 1249/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1210 - acc: 0.9742Epoch 01249: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1252 - acc: 0.9722 - val_loss: 1.5491 - val_acc: 0.6313\n",
      "Epoch 1250/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1191 - acc: 0.9701Epoch 01250: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1211 - acc: 0.9710 - val_loss: 1.5753 - val_acc: 0.6313\n",
      "Epoch 1251/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1368 - acc: 0.9688Epoch 01251: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1336 - acc: 0.9710 - val_loss: 1.6284 - val_acc: 0.6313\n",
      "Epoch 1252/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1388 - acc: 0.9660Epoch 01252: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1442 - acc: 0.9634 - val_loss: 1.6818 - val_acc: 0.6111\n",
      "Epoch 1253/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1294 - acc: 0.9742Epoch 01253: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1266 - acc: 0.9747 - val_loss: 1.6664 - val_acc: 0.6162\n",
      "Epoch 1254/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1319 - acc: 0.9742Epoch 01254: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1311 - acc: 0.9747 - val_loss: 1.6651 - val_acc: 0.6061\n",
      "Epoch 1255/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1387 - acc: 0.9592Epoch 01255: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1423 - acc: 0.9571 - val_loss: 1.6434 - val_acc: 0.6212\n",
      "Epoch 1256/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1530 - acc: 0.9633Epoch 01256: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1482 - acc: 0.9659 - val_loss: 1.6168 - val_acc: 0.6313\n",
      "Epoch 1257/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1411 - acc: 0.9660Epoch 01257: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1386 - acc: 0.9684 - val_loss: 1.6497 - val_acc: 0.6414\n",
      "Epoch 1258/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1620 - acc: 0.9511Epoch 01258: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1680 - acc: 0.9508 - val_loss: 1.6507 - val_acc: 0.6364\n",
      "Epoch 1259/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1561 - acc: 0.9552Epoch 01259: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1530 - acc: 0.9571 - val_loss: 1.6513 - val_acc: 0.6313\n",
      "Epoch 1260/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1463 - acc: 0.9620Epoch 01260: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1443 - acc: 0.9621 - val_loss: 1.6658 - val_acc: 0.6263\n",
      "Epoch 1261/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1473 - acc: 0.9592Epoch 01261: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.1420 - acc: 0.9609 - val_loss: 1.6802 - val_acc: 0.6364\n",
      "Epoch 1262/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1297 - acc: 0.9633Epoch 01262: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1300 - acc: 0.9634 - val_loss: 1.6823 - val_acc: 0.6364\n",
      "Epoch 1263/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1220 - acc: 0.9755Epoch 01263: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1234 - acc: 0.9747 - val_loss: 1.6849 - val_acc: 0.6212\n",
      "Epoch 1264/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1695 - acc: 0.9524Epoch 01264: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1660 - acc: 0.9520 - val_loss: 1.6005 - val_acc: 0.6313\n",
      "Epoch 1265/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1676 - acc: 0.9470Epoch 01265: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1668 - acc: 0.9470 - val_loss: 1.5664 - val_acc: 0.6414\n",
      "Epoch 1266/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1502 - acc: 0.9620Epoch 01266: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1470 - acc: 0.9634 - val_loss: 1.6380 - val_acc: 0.6414\n",
      "Epoch 1267/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1408 - acc: 0.9688Epoch 01267: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1404 - acc: 0.9684 - val_loss: 1.6515 - val_acc: 0.6263\n",
      "Epoch 1268/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1516 - acc: 0.9620Epoch 01268: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1460 - acc: 0.9646 - val_loss: 1.6605 - val_acc: 0.6263\n",
      "Epoch 1269/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1386 - acc: 0.9647Epoch 01269: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1416 - acc: 0.9646 - val_loss: 1.6449 - val_acc: 0.6364\n",
      "Epoch 1270/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1286 - acc: 0.9660Epoch 01270: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1422 - acc: 0.9621 - val_loss: 1.6033 - val_acc: 0.6313\n",
      "Epoch 1271/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1266 - acc: 0.9592Epoch 01271: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1304 - acc: 0.9583 - val_loss: 1.6047 - val_acc: 0.6263\n",
      "Epoch 1272/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1532 - acc: 0.9592Epoch 01272: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1567 - acc: 0.9571 - val_loss: 1.5845 - val_acc: 0.6111\n",
      "Epoch 1273/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1201 - acc: 0.9688Epoch 01273: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.1196 - acc: 0.9697 - val_loss: 1.5423 - val_acc: 0.6465\n",
      "Epoch 1274/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1339 - acc: 0.9647Epoch 01274: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1346 - acc: 0.9672 - val_loss: 1.6251 - val_acc: 0.6313\n",
      "Epoch 1275/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1460 - acc: 0.9538Epoch 01275: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1411 - acc: 0.9571 - val_loss: 1.6328 - val_acc: 0.6010\n",
      "Epoch 1276/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1286 - acc: 0.9660Epoch 01276: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1258 - acc: 0.9659 - val_loss: 1.6005 - val_acc: 0.6313\n",
      "Epoch 1277/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1308 - acc: 0.9633Epoch 01277: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1360 - acc: 0.9609 - val_loss: 1.6270 - val_acc: 0.6313\n",
      "Epoch 1278/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1374 - acc: 0.9647Epoch 01278: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1367 - acc: 0.9646 - val_loss: 1.5575 - val_acc: 0.6212\n",
      "Epoch 1279/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1008 - acc: 0.9810Epoch 01279: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1031 - acc: 0.9785 - val_loss: 1.6154 - val_acc: 0.6111\n",
      "Epoch 1280/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1371 - acc: 0.9552Epoch 01280: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1356 - acc: 0.9545 - val_loss: 1.6274 - val_acc: 0.6364\n",
      "Epoch 1281/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1594 - acc: 0.9592Epoch 01281: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1556 - acc: 0.9609 - val_loss: 1.6156 - val_acc: 0.6313\n",
      "Epoch 1282/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1444 - acc: 0.9633Epoch 01282: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1392 - acc: 0.9659 - val_loss: 1.6040 - val_acc: 0.6162\n",
      "Epoch 1283/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1287 - acc: 0.9647Epoch 01283: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1226 - acc: 0.9672 - val_loss: 1.6129 - val_acc: 0.6616\n",
      "Epoch 1284/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1506 - acc: 0.9538Epoch 01284: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1497 - acc: 0.9558 - val_loss: 1.6558 - val_acc: 0.6313\n",
      "Epoch 1285/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1297 - acc: 0.9660Epoch 01285: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1323 - acc: 0.9646 - val_loss: 1.6433 - val_acc: 0.6465\n",
      "Epoch 1286/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1317 - acc: 0.9633Epoch 01286: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1300 - acc: 0.9634 - val_loss: 1.6158 - val_acc: 0.6616\n",
      "Epoch 1287/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1314 - acc: 0.9715Epoch 01287: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1322 - acc: 0.9710 - val_loss: 1.5785 - val_acc: 0.6566\n",
      "Epoch 1288/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1458 - acc: 0.9606Epoch 01288: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1505 - acc: 0.9583 - val_loss: 1.5877 - val_acc: 0.6414\n",
      "Epoch 1289/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1343 - acc: 0.9579Epoch 01289: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1314 - acc: 0.9609 - val_loss: 1.5666 - val_acc: 0.6162\n",
      "Epoch 1290/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1225 - acc: 0.9688Epoch 01290: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1224 - acc: 0.9697 - val_loss: 1.6768 - val_acc: 0.6111\n",
      "Epoch 1291/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1309 - acc: 0.9688Epoch 01291: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.1359 - acc: 0.9684 - val_loss: 1.6168 - val_acc: 0.6162\n",
      "Epoch 1292/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1215 - acc: 0.9701Epoch 01292: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1246 - acc: 0.9697 - val_loss: 1.6241 - val_acc: 0.6263\n",
      "Epoch 1293/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1541 - acc: 0.9633Epoch 01293: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1514 - acc: 0.9621 - val_loss: 1.6030 - val_acc: 0.6313\n",
      "Epoch 1294/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1325 - acc: 0.9674Epoch 01294: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1276 - acc: 0.9697 - val_loss: 1.6151 - val_acc: 0.6263\n",
      "Epoch 1295/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1333 - acc: 0.9701Epoch 01295: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1418 - acc: 0.9672 - val_loss: 1.6319 - val_acc: 0.6162\n",
      "Epoch 1296/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1447 - acc: 0.9633Epoch 01296: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1438 - acc: 0.9646 - val_loss: 1.7051 - val_acc: 0.5909\n",
      "Epoch 1297/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1545 - acc: 0.9592Epoch 01297: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1520 - acc: 0.9596 - val_loss: 1.7044 - val_acc: 0.5960\n",
      "Epoch 1298/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1309 - acc: 0.9620Epoch 01298: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1331 - acc: 0.9634 - val_loss: 1.6867 - val_acc: 0.6212\n",
      "Epoch 1299/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1522 - acc: 0.9538Epoch 01299: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1594 - acc: 0.9520 - val_loss: 1.6705 - val_acc: 0.6061\n",
      "Epoch 1300/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1455 - acc: 0.9606Epoch 01300: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1510 - acc: 0.9583 - val_loss: 1.7033 - val_acc: 0.5960\n",
      "Epoch 1301/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1349 - acc: 0.9620Epoch 01301: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1305 - acc: 0.9646 - val_loss: 1.6275 - val_acc: 0.6465\n",
      "Epoch 1302/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1200 - acc: 0.9620Epoch 01302: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1199 - acc: 0.9634 - val_loss: 1.6076 - val_acc: 0.5960\n",
      "Epoch 1303/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1626 - acc: 0.9579Epoch 01303: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1578 - acc: 0.9596 - val_loss: 1.7677 - val_acc: 0.5859\n",
      "Epoch 1304/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1320 - acc: 0.9688Epoch 01304: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1318 - acc: 0.9684 - val_loss: 1.6938 - val_acc: 0.5960\n",
      "Epoch 1305/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1243 - acc: 0.9647Epoch 01305: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1258 - acc: 0.9646 - val_loss: 1.6145 - val_acc: 0.6212\n",
      "Epoch 1306/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1396 - acc: 0.9674Epoch 01306: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1394 - acc: 0.9672 - val_loss: 1.6518 - val_acc: 0.6364\n",
      "Epoch 1307/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1501 - acc: 0.9606Epoch 01307: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1439 - acc: 0.9634 - val_loss: 1.6766 - val_acc: 0.6414\n",
      "Epoch 1308/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1123 - acc: 0.9647Epoch 01308: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.1146 - acc: 0.9659 - val_loss: 1.8170 - val_acc: 0.5859\n",
      "Epoch 1309/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1330 - acc: 0.9688Epoch 01309: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1315 - acc: 0.9684 - val_loss: 1.6875 - val_acc: 0.6364\n",
      "Epoch 1310/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1582 - acc: 0.9524Epoch 01310: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1532 - acc: 0.9545 - val_loss: 1.6164 - val_acc: 0.6263\n",
      "Epoch 1311/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1011 - acc: 0.9796Epoch 01311: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1058 - acc: 0.9773 - val_loss: 1.6098 - val_acc: 0.6465\n",
      "Epoch 1312/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1288 - acc: 0.9647Epoch 01312: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1352 - acc: 0.9646 - val_loss: 1.5911 - val_acc: 0.6263\n",
      "Epoch 1313/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1105 - acc: 0.9783Epoch 01313: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1071 - acc: 0.9798 - val_loss: 1.5920 - val_acc: 0.6263\n",
      "Epoch 1314/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1642 - acc: 0.9524Epoch 01314: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1643 - acc: 0.9520 - val_loss: 1.5969 - val_acc: 0.6212\n",
      "Epoch 1315/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1201 - acc: 0.9701Epoch 01315: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1234 - acc: 0.9684 - val_loss: 1.5919 - val_acc: 0.6515\n",
      "Epoch 1316/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1293 - acc: 0.9701Epoch 01316: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1273 - acc: 0.9710 - val_loss: 1.6298 - val_acc: 0.6263\n",
      "Epoch 1317/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1241 - acc: 0.9715Epoch 01317: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1194 - acc: 0.9735 - val_loss: 1.5828 - val_acc: 0.6263\n",
      "Epoch 1318/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1571 - acc: 0.9660Epoch 01318: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1508 - acc: 0.9684 - val_loss: 1.5936 - val_acc: 0.6465\n",
      "Epoch 1319/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1384 - acc: 0.9592Epoch 01319: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1332 - acc: 0.9621 - val_loss: 1.6343 - val_acc: 0.6364\n",
      "Epoch 1320/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1323 - acc: 0.9715Epoch 01320: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1296 - acc: 0.9735 - val_loss: 1.6832 - val_acc: 0.6212\n",
      "Epoch 1321/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1327 - acc: 0.9688Epoch 01321: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1271 - acc: 0.9710 - val_loss: 1.6677 - val_acc: 0.6263\n",
      "Epoch 1322/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1149 - acc: 0.9742Epoch 01322: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1101 - acc: 0.9760 - val_loss: 1.6447 - val_acc: 0.6061\n",
      "Epoch 1323/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1357 - acc: 0.9674Epoch 01323: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1358 - acc: 0.9672 - val_loss: 1.6072 - val_acc: 0.6212\n",
      "Epoch 1324/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1172 - acc: 0.9742Epoch 01324: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1215 - acc: 0.9722 - val_loss: 1.6322 - val_acc: 0.6162\n",
      "Epoch 1325/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1659 - acc: 0.9511Epoch 01325: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1677 - acc: 0.9508 - val_loss: 1.6831 - val_acc: 0.6162\n",
      "Epoch 1326/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1257 - acc: 0.9633Epoch 01326: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1308 - acc: 0.9621 - val_loss: 1.6656 - val_acc: 0.6212\n",
      "Epoch 1327/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1367 - acc: 0.9701Epoch 01327: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1340 - acc: 0.9710 - val_loss: 1.6609 - val_acc: 0.6263\n",
      "Epoch 1328/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1056 - acc: 0.9688Epoch 01328: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.1109 - acc: 0.9672 - val_loss: 1.6588 - val_acc: 0.6263\n",
      "Epoch 1329/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1247 - acc: 0.9674Epoch 01329: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1255 - acc: 0.9672 - val_loss: 1.6002 - val_acc: 0.6465\n",
      "Epoch 1330/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1380 - acc: 0.9688Epoch 01330: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1340 - acc: 0.9697 - val_loss: 1.5906 - val_acc: 0.6263\n",
      "Epoch 1331/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1440 - acc: 0.9592Epoch 01331: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1410 - acc: 0.9609 - val_loss: 1.6590 - val_acc: 0.5960\n",
      "Epoch 1332/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1321 - acc: 0.9688Epoch 01332: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1330 - acc: 0.9697 - val_loss: 1.6102 - val_acc: 0.6313\n",
      "Epoch 1333/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1320 - acc: 0.9674Epoch 01333: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1301 - acc: 0.9672 - val_loss: 1.6615 - val_acc: 0.6111\n",
      "Epoch 1334/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1178 - acc: 0.9715Epoch 01334: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1160 - acc: 0.9722 - val_loss: 1.5764 - val_acc: 0.5909\n",
      "Epoch 1335/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1388 - acc: 0.9674Epoch 01335: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1331 - acc: 0.9697 - val_loss: 1.6271 - val_acc: 0.6010\n",
      "Epoch 1336/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1260 - acc: 0.9647Epoch 01336: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1274 - acc: 0.9646 - val_loss: 1.5561 - val_acc: 0.6566\n",
      "Epoch 1337/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1485 - acc: 0.9579Epoch 01337: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1449 - acc: 0.9596 - val_loss: 1.5625 - val_acc: 0.6364\n",
      "Epoch 1338/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1183 - acc: 0.9742Epoch 01338: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1220 - acc: 0.9722 - val_loss: 1.6682 - val_acc: 0.6263\n",
      "Epoch 1339/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1147 - acc: 0.9742Epoch 01339: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1187 - acc: 0.9735 - val_loss: 1.6162 - val_acc: 0.6414\n",
      "Epoch 1340/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1556 - acc: 0.9592Epoch 01340: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1538 - acc: 0.9596 - val_loss: 1.6395 - val_acc: 0.6263\n",
      "Epoch 1341/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1449 - acc: 0.9620Epoch 01341: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1434 - acc: 0.9634 - val_loss: 1.6737 - val_acc: 0.6061\n",
      "Epoch 1342/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1318 - acc: 0.9742Epoch 01342: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1370 - acc: 0.9710 - val_loss: 1.6085 - val_acc: 0.6263\n",
      "Epoch 1343/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1192 - acc: 0.9715Epoch 01343: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1181 - acc: 0.9710 - val_loss: 1.6424 - val_acc: 0.6111\n",
      "Epoch 1344/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1402 - acc: 0.9606Epoch 01344: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1377 - acc: 0.9609 - val_loss: 1.6305 - val_acc: 0.6263\n",
      "Epoch 1345/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1257 - acc: 0.9674Epoch 01345: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1341 - acc: 0.9646 - val_loss: 1.5804 - val_acc: 0.6212\n",
      "Epoch 1346/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1337 - acc: 0.9728Epoch 01346: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1284 - acc: 0.9747 - val_loss: 1.6570 - val_acc: 0.5960\n",
      "Epoch 1347/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1198 - acc: 0.9728Epoch 01347: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1159 - acc: 0.9735 - val_loss: 1.6797 - val_acc: 0.6162\n",
      "Epoch 1348/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1307 - acc: 0.9647Epoch 01348: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1249 - acc: 0.9672 - val_loss: 1.6409 - val_acc: 0.6111\n",
      "Epoch 1349/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1285 - acc: 0.9592Epoch 01349: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1305 - acc: 0.9583 - val_loss: 1.6314 - val_acc: 0.6111\n",
      "Epoch 1350/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1543 - acc: 0.9606Epoch 01350: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1502 - acc: 0.9634 - val_loss: 1.6088 - val_acc: 0.6263\n",
      "Epoch 1351/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1277 - acc: 0.9620Epoch 01351: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1351 - acc: 0.9571 - val_loss: 1.5708 - val_acc: 0.6313\n",
      "Epoch 1352/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1106 - acc: 0.9796Epoch 01352: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1063 - acc: 0.9811 - val_loss: 1.6465 - val_acc: 0.6263\n",
      "Epoch 1353/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1333 - acc: 0.9620Epoch 01353: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1311 - acc: 0.9634 - val_loss: 1.6476 - val_acc: 0.6061\n",
      "Epoch 1354/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1219 - acc: 0.9633Epoch 01354: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1248 - acc: 0.9621 - val_loss: 1.6342 - val_acc: 0.5808\n",
      "Epoch 1355/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1340 - acc: 0.9701Epoch 01355: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1323 - acc: 0.9710 - val_loss: 1.6089 - val_acc: 0.6212\n",
      "Epoch 1356/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1345 - acc: 0.9715Epoch 01356: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1326 - acc: 0.9722 - val_loss: 1.6128 - val_acc: 0.6010\n",
      "Epoch 1357/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1262 - acc: 0.9660Epoch 01357: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1293 - acc: 0.9659 - val_loss: 1.6283 - val_acc: 0.6162\n",
      "Epoch 1358/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1363 - acc: 0.9647Epoch 01358: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1323 - acc: 0.9672 - val_loss: 1.5558 - val_acc: 0.6313\n",
      "Epoch 1359/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1112 - acc: 0.9688Epoch 01359: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1101 - acc: 0.9697 - val_loss: 1.6046 - val_acc: 0.6364\n",
      "Epoch 1360/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1489 - acc: 0.9660Epoch 01360: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1478 - acc: 0.9659 - val_loss: 1.6224 - val_acc: 0.6111\n",
      "Epoch 1361/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1482 - acc: 0.9592Epoch 01361: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1518 - acc: 0.9558 - val_loss: 1.6522 - val_acc: 0.6162\n",
      "Epoch 1362/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1447 - acc: 0.9579Epoch 01362: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1460 - acc: 0.9583 - val_loss: 1.6005 - val_acc: 0.6414\n",
      "Epoch 1363/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1557 - acc: 0.9592Epoch 01363: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1573 - acc: 0.9596 - val_loss: 1.5670 - val_acc: 0.6313\n",
      "Epoch 1364/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1371 - acc: 0.9579Epoch 01364: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1386 - acc: 0.9583 - val_loss: 1.5929 - val_acc: 0.6111\n",
      "Epoch 1365/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1176 - acc: 0.9769Epoch 01365: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1179 - acc: 0.9760 - val_loss: 1.5736 - val_acc: 0.6313\n",
      "Epoch 1366/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1508 - acc: 0.9660Epoch 01366: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1475 - acc: 0.9659 - val_loss: 1.6831 - val_acc: 0.6212\n",
      "Epoch 1367/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1220 - acc: 0.9755Epoch 01367: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1169 - acc: 0.9773 - val_loss: 1.6523 - val_acc: 0.6111\n",
      "Epoch 1368/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1436 - acc: 0.9552Epoch 01368: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1448 - acc: 0.9533 - val_loss: 1.5857 - val_acc: 0.6313\n",
      "Epoch 1369/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1199 - acc: 0.9755Epoch 01369: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1219 - acc: 0.9747 - val_loss: 1.6552 - val_acc: 0.6111\n",
      "Epoch 1370/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1310 - acc: 0.9701Epoch 01370: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1267 - acc: 0.9710 - val_loss: 1.6211 - val_acc: 0.6212\n",
      "Epoch 1371/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1123 - acc: 0.9715Epoch 01371: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1132 - acc: 0.9710 - val_loss: 1.6157 - val_acc: 0.6263\n",
      "Epoch 1372/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1240 - acc: 0.9688Epoch 01372: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1263 - acc: 0.9697 - val_loss: 1.6329 - val_acc: 0.6263\n",
      "Epoch 1373/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1284 - acc: 0.9728Epoch 01373: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1256 - acc: 0.9735 - val_loss: 1.6355 - val_acc: 0.6212\n",
      "Epoch 1374/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1290 - acc: 0.9701Epoch 01374: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1295 - acc: 0.9710 - val_loss: 1.5842 - val_acc: 0.6162\n",
      "Epoch 1375/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1169 - acc: 0.9715Epoch 01375: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1219 - acc: 0.9684 - val_loss: 1.6668 - val_acc: 0.6061\n",
      "Epoch 1376/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1317 - acc: 0.9606Epoch 01376: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1299 - acc: 0.9621 - val_loss: 1.6632 - val_acc: 0.6010\n",
      "Epoch 1377/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1205 - acc: 0.9728Epoch 01377: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1196 - acc: 0.9735 - val_loss: 1.6580 - val_acc: 0.6162\n",
      "Epoch 1378/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1144 - acc: 0.9701Epoch 01378: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1135 - acc: 0.9722 - val_loss: 1.6141 - val_acc: 0.6364\n",
      "Epoch 1379/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1130 - acc: 0.9715Epoch 01379: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1147 - acc: 0.9710 - val_loss: 1.6210 - val_acc: 0.6263\n",
      "Epoch 1380/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1201 - acc: 0.9728Epoch 01380: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1219 - acc: 0.9722 - val_loss: 1.6317 - val_acc: 0.6111\n",
      "Epoch 1381/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1308 - acc: 0.9660Epoch 01381: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1339 - acc: 0.9646 - val_loss: 1.6164 - val_acc: 0.6212\n",
      "Epoch 1382/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1160 - acc: 0.9783Epoch 01382: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1152 - acc: 0.9773 - val_loss: 1.5914 - val_acc: 0.6263\n",
      "Epoch 1383/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1540 - acc: 0.9606Epoch 01383: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1511 - acc: 0.9609 - val_loss: 1.6427 - val_acc: 0.6212\n",
      "Epoch 1384/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1228 - acc: 0.9674Epoch 01384: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1255 - acc: 0.9659 - val_loss: 1.5652 - val_acc: 0.6364\n",
      "Epoch 1385/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1130 - acc: 0.9769Epoch 01385: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1221 - acc: 0.9735 - val_loss: 1.6399 - val_acc: 0.6212\n",
      "Epoch 1386/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1121 - acc: 0.9674Epoch 01386: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1100 - acc: 0.9684 - val_loss: 1.5833 - val_acc: 0.6465\n",
      "Epoch 1387/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1431 - acc: 0.9620Epoch 01387: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1434 - acc: 0.9621 - val_loss: 1.5957 - val_acc: 0.6465\n",
      "Epoch 1388/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1370 - acc: 0.9647Epoch 01388: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1343 - acc: 0.9659 - val_loss: 1.6039 - val_acc: 0.6364\n",
      "Epoch 1389/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1266 - acc: 0.9688Epoch 01389: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1251 - acc: 0.9697 - val_loss: 1.6048 - val_acc: 0.6313\n",
      "Epoch 1390/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1694 - acc: 0.9579Epoch 01390: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1698 - acc: 0.9558 - val_loss: 1.6614 - val_acc: 0.6414\n",
      "Epoch 1391/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0983 - acc: 0.9769Epoch 01391: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1024 - acc: 0.9747 - val_loss: 1.6314 - val_acc: 0.6263\n",
      "Epoch 1392/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1046 - acc: 0.9783Epoch 01392: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1091 - acc: 0.9785 - val_loss: 1.5994 - val_acc: 0.6162\n",
      "Epoch 1393/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1474 - acc: 0.9633Epoch 01393: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1496 - acc: 0.9609 - val_loss: 1.6189 - val_acc: 0.6364\n",
      "Epoch 1394/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1103 - acc: 0.9769Epoch 01394: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1185 - acc: 0.9722 - val_loss: 1.6034 - val_acc: 0.6212\n",
      "Epoch 1395/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1422 - acc: 0.9606Epoch 01395: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1406 - acc: 0.9609 - val_loss: 1.6710 - val_acc: 0.6364\n",
      "Epoch 1396/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1505 - acc: 0.9592Epoch 01396: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1468 - acc: 0.9621 - val_loss: 1.5880 - val_acc: 0.6465\n",
      "Epoch 1397/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1248 - acc: 0.9796Epoch 01397: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1326 - acc: 0.9773 - val_loss: 1.6809 - val_acc: 0.6364\n",
      "Epoch 1398/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1321 - acc: 0.9701Epoch 01398: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1297 - acc: 0.9722 - val_loss: 1.6163 - val_acc: 0.6414\n",
      "Epoch 1399/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1351 - acc: 0.9647Epoch 01399: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1348 - acc: 0.9646 - val_loss: 1.5905 - val_acc: 0.6364\n",
      "Epoch 1400/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1336 - acc: 0.9660Epoch 01400: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.1343 - acc: 0.9672 - val_loss: 1.5411 - val_acc: 0.6717\n",
      "Epoch 1401/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1164 - acc: 0.9620Epoch 01401: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1196 - acc: 0.9609 - val_loss: 1.6525 - val_acc: 0.6313\n",
      "Epoch 1402/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1149 - acc: 0.9715Epoch 01402: val_loss did not improve\n",
      "792/792 [==============================] - 1s 931us/step - loss: 0.1155 - acc: 0.9710 - val_loss: 1.6982 - val_acc: 0.6465\n",
      "Epoch 1403/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1440 - acc: 0.9592Epoch 01403: val_loss did not improve\n",
      "792/792 [==============================] - 1s 930us/step - loss: 0.1465 - acc: 0.9571 - val_loss: 1.5823 - val_acc: 0.6263\n",
      "Epoch 1404/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1412 - acc: 0.9579Epoch 01404: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1343 - acc: 0.9609 - val_loss: 1.5949 - val_acc: 0.6414\n",
      "Epoch 1405/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1461 - acc: 0.9620Epoch 01405: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1440 - acc: 0.9621 - val_loss: 1.6072 - val_acc: 0.6313\n",
      "Epoch 1406/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1063 - acc: 0.9755Epoch 01406: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1085 - acc: 0.9735 - val_loss: 1.6051 - val_acc: 0.6414\n",
      "Epoch 1407/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1260 - acc: 0.9755Epoch 01407: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1270 - acc: 0.9747 - val_loss: 1.5420 - val_acc: 0.6515\n",
      "Epoch 1408/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1524 - acc: 0.9633Epoch 01408: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1495 - acc: 0.9634 - val_loss: 1.6301 - val_acc: 0.6465\n",
      "Epoch 1409/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1367 - acc: 0.9701Epoch 01409: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1363 - acc: 0.9697 - val_loss: 1.6715 - val_acc: 0.6162\n",
      "Epoch 1410/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1227 - acc: 0.9620Epoch 01410: val_loss did not improve\n",
      "792/792 [==============================] - 1s 933us/step - loss: 0.1174 - acc: 0.9646 - val_loss: 1.6506 - val_acc: 0.6717\n",
      "Epoch 1411/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1373 - acc: 0.9701Epoch 01411: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1364 - acc: 0.9697 - val_loss: 1.6705 - val_acc: 0.6212\n",
      "Epoch 1412/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1437 - acc: 0.9620Epoch 01412: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1428 - acc: 0.9609 - val_loss: 1.5578 - val_acc: 0.6465\n",
      "Epoch 1413/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1436 - acc: 0.9633Epoch 01413: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1411 - acc: 0.9646 - val_loss: 1.6242 - val_acc: 0.6263\n",
      "Epoch 1414/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1329 - acc: 0.9674Epoch 01414: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1275 - acc: 0.9697 - val_loss: 1.5738 - val_acc: 0.6061\n",
      "Epoch 1415/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1073 - acc: 0.9783Epoch 01415: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.1089 - acc: 0.9785 - val_loss: 1.5582 - val_acc: 0.6414\n",
      "Epoch 1416/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0994 - acc: 0.9742Epoch 01416: val_loss did not improve\n",
      "792/792 [==============================] - 1s 932us/step - loss: 0.1109 - acc: 0.9710 - val_loss: 1.5642 - val_acc: 0.6263\n",
      "Epoch 1417/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1485 - acc: 0.9633Epoch 01417: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1474 - acc: 0.9634 - val_loss: 1.6179 - val_acc: 0.6313\n",
      "Epoch 1418/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1206 - acc: 0.9660Epoch 01418: val_loss did not improve\n",
      "792/792 [==============================] - 1s 930us/step - loss: 0.1147 - acc: 0.9684 - val_loss: 1.6576 - val_acc: 0.6313\n",
      "Epoch 1419/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1407 - acc: 0.9701Epoch 01419: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1428 - acc: 0.9684 - val_loss: 1.6439 - val_acc: 0.6515\n",
      "Epoch 1420/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1164 - acc: 0.9755Epoch 01420: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1244 - acc: 0.9722 - val_loss: 1.6014 - val_acc: 0.6465\n",
      "Epoch 1421/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0956 - acc: 0.9823Epoch 01421: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.0985 - acc: 0.9811 - val_loss: 1.5976 - val_acc: 0.6515\n",
      "Epoch 1422/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1427 - acc: 0.9606Epoch 01422: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1530 - acc: 0.9571 - val_loss: 1.6891 - val_acc: 0.6263\n",
      "Epoch 1423/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1247 - acc: 0.9688Epoch 01423: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1251 - acc: 0.9684 - val_loss: 1.6757 - val_acc: 0.6162\n",
      "Epoch 1424/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1220 - acc: 0.9688Epoch 01424: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1210 - acc: 0.9710 - val_loss: 1.6921 - val_acc: 0.6212\n",
      "Epoch 1425/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1303 - acc: 0.9633Epoch 01425: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1307 - acc: 0.9634 - val_loss: 1.6452 - val_acc: 0.6364\n",
      "Epoch 1426/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1398 - acc: 0.9620Epoch 01426: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1477 - acc: 0.9596 - val_loss: 1.6151 - val_acc: 0.6414\n",
      "Epoch 1427/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1389 - acc: 0.9579Epoch 01427: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1369 - acc: 0.9596 - val_loss: 1.6173 - val_acc: 0.6263\n",
      "Epoch 1428/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1265 - acc: 0.9660Epoch 01428: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1289 - acc: 0.9634 - val_loss: 1.6089 - val_acc: 0.6313\n",
      "Epoch 1429/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1393 - acc: 0.9674Epoch 01429: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1355 - acc: 0.9684 - val_loss: 1.5565 - val_acc: 0.6414\n",
      "Epoch 1430/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1106 - acc: 0.9701Epoch 01430: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1106 - acc: 0.9684 - val_loss: 1.6272 - val_acc: 0.6162\n",
      "Epoch 1431/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1047 - acc: 0.9742Epoch 01431: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1044 - acc: 0.9760 - val_loss: 1.5839 - val_acc: 0.6515\n",
      "Epoch 1432/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1493 - acc: 0.9579Epoch 01432: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1436 - acc: 0.9596 - val_loss: 1.5855 - val_acc: 0.6515\n",
      "Epoch 1433/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1224 - acc: 0.9674Epoch 01433: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1190 - acc: 0.9697 - val_loss: 1.6391 - val_acc: 0.6364\n",
      "Epoch 1434/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1182 - acc: 0.9674Epoch 01434: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1166 - acc: 0.9684 - val_loss: 1.6252 - val_acc: 0.6465\n",
      "Epoch 1435/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1086 - acc: 0.9796Epoch 01435: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1097 - acc: 0.9798 - val_loss: 1.6956 - val_acc: 0.6465\n",
      "Epoch 1436/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1117 - acc: 0.9728Epoch 01436: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1142 - acc: 0.9722 - val_loss: 1.6168 - val_acc: 0.6364\n",
      "Epoch 1437/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1200 - acc: 0.9715Epoch 01437: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1221 - acc: 0.9710 - val_loss: 1.6691 - val_acc: 0.6364\n",
      "Epoch 1438/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1205 - acc: 0.9674Epoch 01438: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1227 - acc: 0.9659 - val_loss: 1.6504 - val_acc: 0.6263\n",
      "Epoch 1439/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1224 - acc: 0.9715Epoch 01439: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1266 - acc: 0.9710 - val_loss: 1.6728 - val_acc: 0.6364\n",
      "Epoch 1440/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0919 - acc: 0.9783Epoch 01440: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.0957 - acc: 0.9773 - val_loss: 1.6884 - val_acc: 0.6263\n",
      "Epoch 1441/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1205 - acc: 0.9674Epoch 01441: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1165 - acc: 0.9697 - val_loss: 1.7074 - val_acc: 0.6414\n",
      "Epoch 1442/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1178 - acc: 0.9688Epoch 01442: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1218 - acc: 0.9684 - val_loss: 1.6297 - val_acc: 0.6515\n",
      "Epoch 1443/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1225 - acc: 0.9715Epoch 01443: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1238 - acc: 0.9710 - val_loss: 1.6595 - val_acc: 0.6313\n",
      "Epoch 1444/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1481 - acc: 0.9552Epoch 01444: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1496 - acc: 0.9533 - val_loss: 1.6053 - val_acc: 0.6616\n",
      "Epoch 1445/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1283 - acc: 0.9728Epoch 01445: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1329 - acc: 0.9710 - val_loss: 1.6364 - val_acc: 0.6717\n",
      "Epoch 1446/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1295 - acc: 0.9606Epoch 01446: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1266 - acc: 0.9621 - val_loss: 1.6367 - val_acc: 0.6515\n",
      "Epoch 1447/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1097 - acc: 0.9769Epoch 01447: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1059 - acc: 0.9785 - val_loss: 1.6263 - val_acc: 0.6667\n",
      "Epoch 1448/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1447 - acc: 0.9606Epoch 01448: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1427 - acc: 0.9609 - val_loss: 1.6501 - val_acc: 0.6515\n",
      "Epoch 1449/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1172 - acc: 0.9742Epoch 01449: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1204 - acc: 0.9735 - val_loss: 1.6338 - val_acc: 0.6364\n",
      "Epoch 1450/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1140 - acc: 0.9728Epoch 01450: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1199 - acc: 0.9697 - val_loss: 1.6181 - val_acc: 0.6212\n",
      "Epoch 1451/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1136 - acc: 0.9715Epoch 01451: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1145 - acc: 0.9697 - val_loss: 1.5790 - val_acc: 0.6364\n",
      "Epoch 1452/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1286 - acc: 0.9579Epoch 01452: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1298 - acc: 0.9571 - val_loss: 1.6669 - val_acc: 0.6263\n",
      "Epoch 1453/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1180 - acc: 0.9674Epoch 01453: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1181 - acc: 0.9672 - val_loss: 1.6058 - val_acc: 0.6313\n",
      "Epoch 1454/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1344 - acc: 0.9688Epoch 01454: val_loss did not improve\n",
      "792/792 [==============================] - 1s 929us/step - loss: 0.1415 - acc: 0.9672 - val_loss: 1.6570 - val_acc: 0.6414\n",
      "Epoch 1455/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1255 - acc: 0.9769Epoch 01455: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1295 - acc: 0.9760 - val_loss: 1.6098 - val_acc: 0.6566\n",
      "Epoch 1456/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1096 - acc: 0.9769Epoch 01456: val_loss did not improve\n",
      "792/792 [==============================] - 1s 925us/step - loss: 0.1088 - acc: 0.9785 - val_loss: 1.6329 - val_acc: 0.6717\n",
      "Epoch 1457/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1095 - acc: 0.9769Epoch 01457: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1123 - acc: 0.9747 - val_loss: 1.7342 - val_acc: 0.6263\n",
      "Epoch 1458/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1187 - acc: 0.9728Epoch 01458: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1150 - acc: 0.9735 - val_loss: 1.6424 - val_acc: 0.6616\n",
      "Epoch 1459/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1449 - acc: 0.9606Epoch 01459: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1548 - acc: 0.9583 - val_loss: 1.6605 - val_acc: 0.6313\n",
      "Epoch 1460/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1305 - acc: 0.9688Epoch 01460: val_loss did not improve\n",
      "792/792 [==============================] - 1s 930us/step - loss: 0.1245 - acc: 0.9710 - val_loss: 1.6410 - val_acc: 0.6515\n",
      "Epoch 1461/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1206 - acc: 0.9715Epoch 01461: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1246 - acc: 0.9710 - val_loss: 1.6215 - val_acc: 0.6364\n",
      "Epoch 1462/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1237 - acc: 0.9647Epoch 01462: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1351 - acc: 0.9621 - val_loss: 1.6552 - val_acc: 0.6364\n",
      "Epoch 1463/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1065 - acc: 0.9769Epoch 01463: val_loss did not improve\n",
      "792/792 [==============================] - 1s 931us/step - loss: 0.1088 - acc: 0.9760 - val_loss: 1.6065 - val_acc: 0.6566\n",
      "Epoch 1464/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1123 - acc: 0.9783Epoch 01464: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1128 - acc: 0.9773 - val_loss: 1.6598 - val_acc: 0.6212\n",
      "Epoch 1465/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1221 - acc: 0.9647Epoch 01465: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1225 - acc: 0.9634 - val_loss: 1.6483 - val_acc: 0.6364\n",
      "Epoch 1466/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1191 - acc: 0.9674Epoch 01466: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1189 - acc: 0.9672 - val_loss: 1.6602 - val_acc: 0.6162\n",
      "Epoch 1467/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1451 - acc: 0.9633Epoch 01467: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1434 - acc: 0.9634 - val_loss: 1.6524 - val_acc: 0.6465\n",
      "Epoch 1468/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1305 - acc: 0.9647Epoch 01468: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1292 - acc: 0.9646 - val_loss: 1.6639 - val_acc: 0.6414\n",
      "Epoch 1469/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1361 - acc: 0.9688Epoch 01469: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1369 - acc: 0.9684 - val_loss: 1.6629 - val_acc: 0.6313\n",
      "Epoch 1470/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1272 - acc: 0.9688Epoch 01470: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1279 - acc: 0.9684 - val_loss: 1.6557 - val_acc: 0.6313\n",
      "Epoch 1471/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1293 - acc: 0.9701Epoch 01471: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1348 - acc: 0.9659 - val_loss: 1.6309 - val_acc: 0.6515\n",
      "Epoch 1472/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1242 - acc: 0.9674Epoch 01472: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1218 - acc: 0.9684 - val_loss: 1.6031 - val_acc: 0.6263\n",
      "Epoch 1473/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1331 - acc: 0.9674Epoch 01473: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1405 - acc: 0.9659 - val_loss: 1.6455 - val_acc: 0.6010\n",
      "Epoch 1474/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1351 - acc: 0.9660Epoch 01474: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1377 - acc: 0.9646 - val_loss: 1.6129 - val_acc: 0.6313\n",
      "Epoch 1475/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1116 - acc: 0.9688Epoch 01475: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1088 - acc: 0.9697 - val_loss: 1.6048 - val_acc: 0.6364\n",
      "Epoch 1476/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1229 - acc: 0.9688Epoch 01476: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1202 - acc: 0.9684 - val_loss: 1.6103 - val_acc: 0.6515\n",
      "Epoch 1477/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1180 - acc: 0.9742Epoch 01477: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1154 - acc: 0.9735 - val_loss: 1.6456 - val_acc: 0.6313\n",
      "Epoch 1478/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1234 - acc: 0.9701Epoch 01478: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1235 - acc: 0.9697 - val_loss: 1.6917 - val_acc: 0.6364\n",
      "Epoch 1479/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1660 - acc: 0.9606Epoch 01479: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1623 - acc: 0.9609 - val_loss: 1.6634 - val_acc: 0.6313\n",
      "Epoch 1480/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1079 - acc: 0.9755Epoch 01480: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1127 - acc: 0.9747 - val_loss: 1.6111 - val_acc: 0.6414\n",
      "Epoch 1481/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1302 - acc: 0.9688Epoch 01481: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1294 - acc: 0.9684 - val_loss: 1.7062 - val_acc: 0.6061\n",
      "Epoch 1482/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1424 - acc: 0.9674Epoch 01482: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1504 - acc: 0.9634 - val_loss: 1.6673 - val_acc: 0.6313\n",
      "Epoch 1483/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0849 - acc: 0.9851Epoch 01483: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.0892 - acc: 0.9848 - val_loss: 1.7072 - val_acc: 0.6364\n",
      "Epoch 1484/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1284 - acc: 0.9688Epoch 01484: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1251 - acc: 0.9697 - val_loss: 1.6995 - val_acc: 0.6414\n",
      "Epoch 1485/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1357 - acc: 0.9701Epoch 01485: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1377 - acc: 0.9684 - val_loss: 1.6067 - val_acc: 0.6667\n",
      "Epoch 1486/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1236 - acc: 0.9674Epoch 01486: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1186 - acc: 0.9697 - val_loss: 1.6259 - val_acc: 0.6364\n",
      "Epoch 1487/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1124 - acc: 0.9701Epoch 01487: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1186 - acc: 0.9672 - val_loss: 1.6503 - val_acc: 0.6414\n",
      "Epoch 1488/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1223 - acc: 0.9701Epoch 01488: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1166 - acc: 0.9722 - val_loss: 1.6446 - val_acc: 0.6364\n",
      "Epoch 1489/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1342 - acc: 0.9674Epoch 01489: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1356 - acc: 0.9684 - val_loss: 1.6386 - val_acc: 0.6162\n",
      "Epoch 1490/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1167 - acc: 0.9742Epoch 01490: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1249 - acc: 0.9710 - val_loss: 1.6463 - val_acc: 0.6465\n",
      "Epoch 1491/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1314 - acc: 0.9647Epoch 01491: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1332 - acc: 0.9659 - val_loss: 1.5859 - val_acc: 0.6465\n",
      "Epoch 1492/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1352 - acc: 0.9660Epoch 01492: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1384 - acc: 0.9646 - val_loss: 1.5479 - val_acc: 0.6465\n",
      "Epoch 1493/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1175 - acc: 0.9728Epoch 01493: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1143 - acc: 0.9735 - val_loss: 1.6835 - val_acc: 0.6162\n",
      "Epoch 1494/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1260 - acc: 0.9715Epoch 01494: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1272 - acc: 0.9710 - val_loss: 1.5954 - val_acc: 0.6364\n",
      "Epoch 1495/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1385 - acc: 0.9660Epoch 01495: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1385 - acc: 0.9672 - val_loss: 1.5666 - val_acc: 0.6667\n",
      "Epoch 1496/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1384 - acc: 0.9606Epoch 01496: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1404 - acc: 0.9596 - val_loss: 1.5767 - val_acc: 0.6566\n",
      "Epoch 1497/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1192 - acc: 0.9755Epoch 01497: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1189 - acc: 0.9760 - val_loss: 1.6608 - val_acc: 0.6162\n",
      "Epoch 1498/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1269 - acc: 0.9701Epoch 01498: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1234 - acc: 0.9722 - val_loss: 1.7202 - val_acc: 0.6010\n",
      "Epoch 1499/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1106 - acc: 0.9796Epoch 01499: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1175 - acc: 0.9798 - val_loss: 1.5706 - val_acc: 0.6364\n",
      "Epoch 1500/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1200 - acc: 0.9620Epoch 01500: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1205 - acc: 0.9621 - val_loss: 1.6731 - val_acc: 0.6263\n",
      "Epoch 1501/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1131 - acc: 0.9715Epoch 01501: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1160 - acc: 0.9710 - val_loss: 1.6174 - val_acc: 0.6263\n",
      "Epoch 1502/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1382 - acc: 0.9633Epoch 01502: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1370 - acc: 0.9646 - val_loss: 1.6104 - val_acc: 0.6465\n",
      "Epoch 1503/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1384 - acc: 0.9660Epoch 01503: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1318 - acc: 0.9672 - val_loss: 1.6633 - val_acc: 0.6263\n",
      "Epoch 1504/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1414 - acc: 0.9633Epoch 01504: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1403 - acc: 0.9659 - val_loss: 1.6752 - val_acc: 0.5960\n",
      "Epoch 1505/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1265 - acc: 0.9592Epoch 01505: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1291 - acc: 0.9596 - val_loss: 1.6098 - val_acc: 0.6263\n",
      "Epoch 1506/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1530 - acc: 0.9620Epoch 01506: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1606 - acc: 0.9596 - val_loss: 1.6086 - val_acc: 0.6263\n",
      "Epoch 1507/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1254 - acc: 0.9674Epoch 01507: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1264 - acc: 0.9672 - val_loss: 1.5981 - val_acc: 0.6212\n",
      "Epoch 1508/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1276 - acc: 0.9674Epoch 01508: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1254 - acc: 0.9684 - val_loss: 1.6044 - val_acc: 0.6313\n",
      "Epoch 1509/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1332 - acc: 0.9728Epoch 01509: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1338 - acc: 0.9710 - val_loss: 1.5657 - val_acc: 0.6212\n",
      "Epoch 1510/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1459 - acc: 0.9660Epoch 01510: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1407 - acc: 0.9684 - val_loss: 1.5399 - val_acc: 0.6313\n",
      "Epoch 1511/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1294 - acc: 0.9715Epoch 01511: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1313 - acc: 0.9710 - val_loss: 1.6226 - val_acc: 0.6263\n",
      "Epoch 1512/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1327 - acc: 0.9701Epoch 01512: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1300 - acc: 0.9710 - val_loss: 1.5811 - val_acc: 0.6313\n",
      "Epoch 1513/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1632 - acc: 0.9620Epoch 01513: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1586 - acc: 0.9634 - val_loss: 1.6071 - val_acc: 0.6414\n",
      "Epoch 1514/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1154 - acc: 0.9688Epoch 01514: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1132 - acc: 0.9710 - val_loss: 1.6052 - val_acc: 0.6263\n",
      "Epoch 1515/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1255 - acc: 0.9674Epoch 01515: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1235 - acc: 0.9684 - val_loss: 1.5875 - val_acc: 0.6414\n",
      "Epoch 1516/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1316 - acc: 0.9701Epoch 01516: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1333 - acc: 0.9697 - val_loss: 1.6685 - val_acc: 0.6465\n",
      "Epoch 1517/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1361 - acc: 0.9647Epoch 01517: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1376 - acc: 0.9634 - val_loss: 1.6067 - val_acc: 0.6515\n",
      "Epoch 1518/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1391 - acc: 0.9674Epoch 01518: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1488 - acc: 0.9621 - val_loss: 1.6434 - val_acc: 0.6162\n",
      "Epoch 1519/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1161 - acc: 0.9674Epoch 01519: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1136 - acc: 0.9697 - val_loss: 1.6657 - val_acc: 0.6364\n",
      "Epoch 1520/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1278 - acc: 0.9660Epoch 01520: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1309 - acc: 0.9646 - val_loss: 1.6389 - val_acc: 0.6162\n",
      "Epoch 1521/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1395 - acc: 0.9620Epoch 01521: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1371 - acc: 0.9621 - val_loss: 1.6332 - val_acc: 0.6061\n",
      "Epoch 1522/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1004 - acc: 0.9796Epoch 01522: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 0.1011 - acc: 0.9785 - val_loss: 1.6138 - val_acc: 0.6263\n",
      "Epoch 1523/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1115 - acc: 0.9796Epoch 01523: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1162 - acc: 0.9785 - val_loss: 1.6545 - val_acc: 0.6414\n",
      "Epoch 1524/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0967 - acc: 0.9783Epoch 01524: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.0986 - acc: 0.9760 - val_loss: 1.7105 - val_acc: 0.6212\n",
      "Epoch 1525/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1039 - acc: 0.9701Epoch 01525: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1084 - acc: 0.9684 - val_loss: 1.6103 - val_acc: 0.6313\n",
      "Epoch 1526/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1264 - acc: 0.9674Epoch 01526: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1237 - acc: 0.9672 - val_loss: 1.6731 - val_acc: 0.6061\n",
      "Epoch 1527/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1732 - acc: 0.9457Epoch 01527: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1651 - acc: 0.9495 - val_loss: 1.6078 - val_acc: 0.6162\n",
      "Epoch 1528/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1226 - acc: 0.9728Epoch 01528: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1214 - acc: 0.9735 - val_loss: 1.6694 - val_acc: 0.6162\n",
      "Epoch 1529/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1308 - acc: 0.9633Epoch 01529: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1296 - acc: 0.9646 - val_loss: 1.5940 - val_acc: 0.6313\n",
      "Epoch 1530/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1045 - acc: 0.9755Epoch 01530: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1130 - acc: 0.9747 - val_loss: 1.5725 - val_acc: 0.6414\n",
      "Epoch 1531/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1290 - acc: 0.9688Epoch 01531: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1417 - acc: 0.9659 - val_loss: 1.6265 - val_acc: 0.6465\n",
      "Epoch 1532/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1344 - acc: 0.9674Epoch 01532: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1317 - acc: 0.9684 - val_loss: 1.6229 - val_acc: 0.6364\n",
      "Epoch 1533/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1223 - acc: 0.9715Epoch 01533: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1296 - acc: 0.9684 - val_loss: 1.5439 - val_acc: 0.6515\n",
      "Epoch 1534/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1534 - acc: 0.9660Epoch 01534: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1542 - acc: 0.9672 - val_loss: 1.6046 - val_acc: 0.6515\n",
      "Epoch 1535/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1588 - acc: 0.9524Epoch 01535: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1514 - acc: 0.9558 - val_loss: 1.6290 - val_acc: 0.6465\n",
      "Epoch 1536/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1203 - acc: 0.9715Epoch 01536: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1242 - acc: 0.9710 - val_loss: 1.6113 - val_acc: 0.6465\n",
      "Epoch 1537/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1389 - acc: 0.9620Epoch 01537: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1395 - acc: 0.9609 - val_loss: 1.6289 - val_acc: 0.6414\n",
      "Epoch 1538/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1246 - acc: 0.9688Epoch 01538: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1223 - acc: 0.9684 - val_loss: 1.6671 - val_acc: 0.6465\n",
      "Epoch 1539/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1210 - acc: 0.9660Epoch 01539: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1251 - acc: 0.9634 - val_loss: 1.6411 - val_acc: 0.6414\n",
      "Epoch 1540/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1196 - acc: 0.9688Epoch 01540: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1228 - acc: 0.9684 - val_loss: 1.6898 - val_acc: 0.6313\n",
      "Epoch 1541/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1304 - acc: 0.9674Epoch 01541: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1292 - acc: 0.9684 - val_loss: 1.6461 - val_acc: 0.6566\n",
      "Epoch 1542/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1370 - acc: 0.9660Epoch 01542: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1388 - acc: 0.9659 - val_loss: 1.5894 - val_acc: 0.6364\n",
      "Epoch 1543/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1210 - acc: 0.9728Epoch 01543: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1290 - acc: 0.9697 - val_loss: 1.6362 - val_acc: 0.6515\n",
      "Epoch 1544/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1534 - acc: 0.9606Epoch 01544: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1501 - acc: 0.9609 - val_loss: 1.6330 - val_acc: 0.6465\n",
      "Epoch 1545/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1357 - acc: 0.9633Epoch 01545: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1358 - acc: 0.9646 - val_loss: 1.6363 - val_acc: 0.6515\n",
      "Epoch 1546/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1471 - acc: 0.9565Epoch 01546: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1428 - acc: 0.9583 - val_loss: 1.6731 - val_acc: 0.6263\n",
      "Epoch 1547/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1237 - acc: 0.9674Epoch 01547: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1233 - acc: 0.9684 - val_loss: 1.6370 - val_acc: 0.6414\n",
      "Epoch 1548/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1265 - acc: 0.9728Epoch 01548: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1272 - acc: 0.9735 - val_loss: 1.6634 - val_acc: 0.6364\n",
      "Epoch 1549/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1304 - acc: 0.9620Epoch 01549: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1269 - acc: 0.9634 - val_loss: 1.6321 - val_acc: 0.6414\n",
      "Epoch 1550/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1254 - acc: 0.9647Epoch 01550: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1265 - acc: 0.9646 - val_loss: 1.6098 - val_acc: 0.6313\n",
      "Epoch 1551/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1217 - acc: 0.9742Epoch 01551: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1281 - acc: 0.9722 - val_loss: 1.5467 - val_acc: 0.6465\n",
      "Epoch 1552/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1276 - acc: 0.9728Epoch 01552: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1270 - acc: 0.9722 - val_loss: 1.6236 - val_acc: 0.6364\n",
      "Epoch 1553/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1432 - acc: 0.9606Epoch 01553: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1414 - acc: 0.9609 - val_loss: 1.6422 - val_acc: 0.6263\n",
      "Epoch 1554/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1280 - acc: 0.9674Epoch 01554: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1259 - acc: 0.9672 - val_loss: 1.5702 - val_acc: 0.6515\n",
      "Epoch 1555/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1224 - acc: 0.9674Epoch 01555: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1231 - acc: 0.9684 - val_loss: 1.5586 - val_acc: 0.6566\n",
      "Epoch 1556/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1294 - acc: 0.9633Epoch 01556: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1300 - acc: 0.9609 - val_loss: 1.5920 - val_acc: 0.6515\n",
      "Epoch 1557/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1080 - acc: 0.9742Epoch 01557: val_loss did not improve\n",
      "792/792 [==============================] - 1s 933us/step - loss: 0.1118 - acc: 0.9722 - val_loss: 1.6201 - val_acc: 0.6313\n",
      "Epoch 1558/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1148 - acc: 0.9796Epoch 01558: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1247 - acc: 0.9747 - val_loss: 1.6070 - val_acc: 0.6515\n",
      "Epoch 1559/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1106 - acc: 0.9769Epoch 01559: val_loss did not improve\n",
      "792/792 [==============================] - 1s 913us/step - loss: 0.1108 - acc: 0.9773 - val_loss: 1.6048 - val_acc: 0.6414\n",
      "Epoch 1560/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1504 - acc: 0.9579Epoch 01560: val_loss did not improve\n",
      "792/792 [==============================] - 1s 918us/step - loss: 0.1482 - acc: 0.9596 - val_loss: 1.5692 - val_acc: 0.6566\n",
      "Epoch 1561/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1081 - acc: 0.9769Epoch 01561: val_loss did not improve\n",
      "792/792 [==============================] - 1s 924us/step - loss: 0.1108 - acc: 0.9760 - val_loss: 1.5981 - val_acc: 0.6364\n",
      "Epoch 1562/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1042 - acc: 0.9769Epoch 01562: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1033 - acc: 0.9773 - val_loss: 1.6080 - val_acc: 0.6364\n",
      "Epoch 1563/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1029 - acc: 0.9810Epoch 01563: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1052 - acc: 0.9823 - val_loss: 1.6278 - val_acc: 0.6414\n",
      "Epoch 1564/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1109 - acc: 0.9742Epoch 01564: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1117 - acc: 0.9722 - val_loss: 1.6283 - val_acc: 0.6263\n",
      "Epoch 1565/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1144 - acc: 0.9674Epoch 01565: val_loss did not improve\n",
      "792/792 [==============================] - 1s 928us/step - loss: 0.1151 - acc: 0.9672 - val_loss: 1.5950 - val_acc: 0.6263\n",
      "Epoch 1566/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1216 - acc: 0.9701Epoch 01566: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.1193 - acc: 0.9710 - val_loss: 1.5914 - val_acc: 0.6414\n",
      "Epoch 1567/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1195 - acc: 0.9728Epoch 01567: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1170 - acc: 0.9722 - val_loss: 1.6186 - val_acc: 0.6364\n",
      "Epoch 1568/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1479 - acc: 0.9633Epoch 01568: val_loss did not improve\n",
      "792/792 [==============================] - 1s 934us/step - loss: 0.1522 - acc: 0.9609 - val_loss: 1.5893 - val_acc: 0.6465\n",
      "Epoch 1569/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1353 - acc: 0.9647Epoch 01569: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1324 - acc: 0.9659 - val_loss: 1.6135 - val_acc: 0.6515\n",
      "Epoch 1570/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1105 - acc: 0.9728Epoch 01570: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1073 - acc: 0.9735 - val_loss: 1.6254 - val_acc: 0.6566\n",
      "Epoch 1571/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1167 - acc: 0.9742Epoch 01571: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1112 - acc: 0.9760 - val_loss: 1.6374 - val_acc: 0.6364\n",
      "Epoch 1572/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1492 - acc: 0.9715Epoch 01572: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1488 - acc: 0.9710 - val_loss: 1.6485 - val_acc: 0.6364\n",
      "Epoch 1573/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1172 - acc: 0.9688Epoch 01573: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1176 - acc: 0.9684 - val_loss: 1.5495 - val_acc: 0.6667\n",
      "Epoch 1574/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1178 - acc: 0.9769Epoch 01574: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1250 - acc: 0.9722 - val_loss: 1.5980 - val_acc: 0.6616\n",
      "Epoch 1575/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1176 - acc: 0.9660Epoch 01575: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1139 - acc: 0.9672 - val_loss: 1.5998 - val_acc: 0.6616\n",
      "Epoch 1576/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1195 - acc: 0.9715Epoch 01576: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.1213 - acc: 0.9697 - val_loss: 1.5677 - val_acc: 0.6566\n",
      "Epoch 1577/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1362 - acc: 0.9606Epoch 01577: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 0.1359 - acc: 0.9609 - val_loss: 1.6236 - val_acc: 0.6212\n",
      "Epoch 1578/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1560 - acc: 0.9620Epoch 01578: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1514 - acc: 0.9634 - val_loss: 1.5807 - val_acc: 0.6364\n",
      "Epoch 1579/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1134 - acc: 0.9674Epoch 01579: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1161 - acc: 0.9672 - val_loss: 1.6239 - val_acc: 0.6414\n",
      "Epoch 1580/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1034 - acc: 0.9755Epoch 01580: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1041 - acc: 0.9747 - val_loss: 1.5932 - val_acc: 0.6566\n",
      "Epoch 1581/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1307 - acc: 0.9606Epoch 01581: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1261 - acc: 0.9621 - val_loss: 1.5973 - val_acc: 0.6667\n",
      "Epoch 1582/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1229 - acc: 0.9701Epoch 01582: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1235 - acc: 0.9710 - val_loss: 1.5716 - val_acc: 0.6465\n",
      "Epoch 1583/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1500 - acc: 0.9565Epoch 01583: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1476 - acc: 0.9558 - val_loss: 1.6410 - val_acc: 0.6566\n",
      "Epoch 1584/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1234 - acc: 0.9660Epoch 01584: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1237 - acc: 0.9672 - val_loss: 1.6388 - val_acc: 0.6313\n",
      "Epoch 1585/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1531 - acc: 0.9497Epoch 01585: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1522 - acc: 0.9495 - val_loss: 1.6377 - val_acc: 0.6414\n",
      "Epoch 1586/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1147 - acc: 0.9592Epoch 01586: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1098 - acc: 0.9621 - val_loss: 1.6355 - val_acc: 0.6465\n",
      "Epoch 1587/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1186 - acc: 0.9728Epoch 01587: val_loss did not improve\n",
      "792/792 [==============================] - 1s 921us/step - loss: 0.1194 - acc: 0.9722 - val_loss: 1.6255 - val_acc: 0.6364\n",
      "Epoch 1588/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1063 - acc: 0.9742Epoch 01588: val_loss did not improve\n",
      "792/792 [==============================] - 1s 929us/step - loss: 0.1148 - acc: 0.9697 - val_loss: 1.6450 - val_acc: 0.6263\n",
      "Epoch 1589/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1311 - acc: 0.9660Epoch 01589: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.1296 - acc: 0.9659 - val_loss: 1.5824 - val_acc: 0.6212\n",
      "Epoch 1590/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1218 - acc: 0.9728Epoch 01590: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1238 - acc: 0.9722 - val_loss: 1.6139 - val_acc: 0.6414\n",
      "Epoch 1591/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1217 - acc: 0.9755Epoch 01591: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1192 - acc: 0.9760 - val_loss: 1.5939 - val_acc: 0.6364\n",
      "Epoch 1592/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1384 - acc: 0.9592Epoch 01592: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1316 - acc: 0.9621 - val_loss: 1.6256 - val_acc: 0.6465\n",
      "Epoch 1593/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0922 - acc: 0.9783Epoch 01593: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.0911 - acc: 0.9785 - val_loss: 1.6254 - val_acc: 0.6414\n",
      "Epoch 1594/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1268 - acc: 0.9620Epoch 01594: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1240 - acc: 0.9621 - val_loss: 1.6588 - val_acc: 0.6162\n",
      "Epoch 1595/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1325 - acc: 0.9647Epoch 01595: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1331 - acc: 0.9646 - val_loss: 1.6462 - val_acc: 0.6010\n",
      "Epoch 1596/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1411 - acc: 0.9620Epoch 01596: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1390 - acc: 0.9621 - val_loss: 1.6705 - val_acc: 0.6263\n",
      "Epoch 1597/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1203 - acc: 0.9715Epoch 01597: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1174 - acc: 0.9735 - val_loss: 1.6474 - val_acc: 0.6364\n",
      "Epoch 1598/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1346 - acc: 0.9565Epoch 01598: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1340 - acc: 0.9571 - val_loss: 1.6222 - val_acc: 0.6515\n",
      "Epoch 1599/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1325 - acc: 0.9660Epoch 01599: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1284 - acc: 0.9684 - val_loss: 1.5885 - val_acc: 0.6465\n",
      "Epoch 1600/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1328 - acc: 0.9606Epoch 01600: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1288 - acc: 0.9621 - val_loss: 1.6304 - val_acc: 0.6263\n",
      "Epoch 1601/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0995 - acc: 0.9728Epoch 01601: val_loss did not improve\n",
      "792/792 [==============================] - 1s 927us/step - loss: 0.0977 - acc: 0.9735 - val_loss: 1.5848 - val_acc: 0.6515\n",
      "Epoch 1602/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1407 - acc: 0.9647Epoch 01602: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1400 - acc: 0.9646 - val_loss: 1.6392 - val_acc: 0.6414\n",
      "Epoch 1603/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0892 - acc: 0.9810Epoch 01603: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.0878 - acc: 0.9811 - val_loss: 1.6135 - val_acc: 0.6364\n",
      "Epoch 1604/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1148 - acc: 0.9674Epoch 01604: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1166 - acc: 0.9672 - val_loss: 1.6760 - val_acc: 0.6313\n",
      "Epoch 1605/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1119 - acc: 0.9688Epoch 01605: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1140 - acc: 0.9684 - val_loss: 1.6138 - val_acc: 0.6566\n",
      "Epoch 1606/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1186 - acc: 0.9701Epoch 01606: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1166 - acc: 0.9710 - val_loss: 1.6982 - val_acc: 0.6111\n",
      "Epoch 1607/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1287 - acc: 0.9688Epoch 01607: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1369 - acc: 0.9659 - val_loss: 1.6215 - val_acc: 0.6414\n",
      "Epoch 1608/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1055 - acc: 0.9755Epoch 01608: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.1085 - acc: 0.9735 - val_loss: 1.6307 - val_acc: 0.6515\n",
      "Epoch 1609/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1290 - acc: 0.9633Epoch 01609: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1329 - acc: 0.9621 - val_loss: 1.5945 - val_acc: 0.6414\n",
      "Epoch 1610/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1168 - acc: 0.9674Epoch 01610: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1145 - acc: 0.9684 - val_loss: 1.6670 - val_acc: 0.6414\n",
      "Epoch 1611/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1099 - acc: 0.9728Epoch 01611: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1079 - acc: 0.9747 - val_loss: 1.6667 - val_acc: 0.6414\n",
      "Epoch 1612/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1141 - acc: 0.9742Epoch 01612: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1172 - acc: 0.9735 - val_loss: 1.6983 - val_acc: 0.6263\n",
      "Epoch 1613/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1221 - acc: 0.9688Epoch 01613: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1212 - acc: 0.9697 - val_loss: 1.6658 - val_acc: 0.6465\n",
      "Epoch 1614/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1171 - acc: 0.9742Epoch 01614: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1188 - acc: 0.9735 - val_loss: 1.6177 - val_acc: 0.6313\n",
      "Epoch 1615/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1192 - acc: 0.9674Epoch 01615: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1219 - acc: 0.9684 - val_loss: 1.6265 - val_acc: 0.6212\n",
      "Epoch 1616/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1390 - acc: 0.9565Epoch 01616: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1381 - acc: 0.9571 - val_loss: 1.6160 - val_acc: 0.6313\n",
      "Epoch 1617/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1404 - acc: 0.9633Epoch 01617: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1428 - acc: 0.9609 - val_loss: 1.5953 - val_acc: 0.6364\n",
      "Epoch 1618/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1239 - acc: 0.9688Epoch 01618: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1233 - acc: 0.9684 - val_loss: 1.6055 - val_acc: 0.6364\n",
      "Epoch 1619/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1101 - acc: 0.9660Epoch 01619: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1091 - acc: 0.9659 - val_loss: 1.6877 - val_acc: 0.6061\n",
      "Epoch 1620/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1073 - acc: 0.9688Epoch 01620: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1071 - acc: 0.9710 - val_loss: 1.6763 - val_acc: 0.6263\n",
      "Epoch 1621/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1045 - acc: 0.9769Epoch 01621: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1040 - acc: 0.9760 - val_loss: 1.7093 - val_acc: 0.6263\n",
      "Epoch 1622/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1570 - acc: 0.9497Epoch 01622: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1501 - acc: 0.9520 - val_loss: 1.6340 - val_acc: 0.6364\n",
      "Epoch 1623/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0973 - acc: 0.9810Epoch 01623: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.0967 - acc: 0.9811 - val_loss: 1.6593 - val_acc: 0.6515\n",
      "Epoch 1624/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1175 - acc: 0.9755Epoch 01624: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1175 - acc: 0.9747 - val_loss: 1.6111 - val_acc: 0.6364\n",
      "Epoch 1625/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1389 - acc: 0.9579Epoch 01625: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1394 - acc: 0.9583 - val_loss: 1.6069 - val_acc: 0.6313\n",
      "Epoch 1626/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1211 - acc: 0.9715Epoch 01626: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1191 - acc: 0.9722 - val_loss: 1.5981 - val_acc: 0.6465\n",
      "Epoch 1627/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1206 - acc: 0.9715Epoch 01627: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1240 - acc: 0.9697 - val_loss: 1.7034 - val_acc: 0.6212\n",
      "Epoch 1628/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1034 - acc: 0.9783Epoch 01628: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1059 - acc: 0.9773 - val_loss: 1.6712 - val_acc: 0.6313\n",
      "Epoch 1629/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1457 - acc: 0.9647Epoch 01629: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.1407 - acc: 0.9672 - val_loss: 1.6835 - val_acc: 0.6414\n",
      "Epoch 1630/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1004 - acc: 0.9823Epoch 01630: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1010 - acc: 0.9811 - val_loss: 1.6424 - val_acc: 0.6515\n",
      "Epoch 1631/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1225 - acc: 0.9715Epoch 01631: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1255 - acc: 0.9697 - val_loss: 1.6479 - val_acc: 0.6263\n",
      "Epoch 1632/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1173 - acc: 0.9715Epoch 01632: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1254 - acc: 0.9672 - val_loss: 1.6216 - val_acc: 0.6364\n",
      "Epoch 1633/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1235 - acc: 0.9674Epoch 01633: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1278 - acc: 0.9659 - val_loss: 1.5966 - val_acc: 0.6515\n",
      "Epoch 1634/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1246 - acc: 0.9633Epoch 01634: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1310 - acc: 0.9634 - val_loss: 1.5397 - val_acc: 0.6566\n",
      "Epoch 1635/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0958 - acc: 0.9810Epoch 01635: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.0954 - acc: 0.9811 - val_loss: 1.5336 - val_acc: 0.6616\n",
      "Epoch 1636/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1304 - acc: 0.9606Epoch 01636: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1230 - acc: 0.9634 - val_loss: 1.5503 - val_acc: 0.6364\n",
      "Epoch 1637/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1170 - acc: 0.9674Epoch 01637: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1178 - acc: 0.9672 - val_loss: 1.5889 - val_acc: 0.6364\n",
      "Epoch 1638/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1519 - acc: 0.9606Epoch 01638: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1493 - acc: 0.9609 - val_loss: 1.5706 - val_acc: 0.6364\n",
      "Epoch 1639/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1187 - acc: 0.9701Epoch 01639: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1204 - acc: 0.9697 - val_loss: 1.6184 - val_acc: 0.6162\n",
      "Epoch 1640/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1228 - acc: 0.9660Epoch 01640: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1184 - acc: 0.9672 - val_loss: 1.6162 - val_acc: 0.6263\n",
      "Epoch 1641/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1026 - acc: 0.9769Epoch 01641: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1029 - acc: 0.9773 - val_loss: 1.5788 - val_acc: 0.6515\n",
      "Epoch 1642/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1161 - acc: 0.9606Epoch 01642: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1150 - acc: 0.9621 - val_loss: 1.5864 - val_acc: 0.6616\n",
      "Epoch 1643/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1166 - acc: 0.9674Epoch 01643: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1137 - acc: 0.9684 - val_loss: 1.5911 - val_acc: 0.6364\n",
      "Epoch 1644/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0898 - acc: 0.9810Epoch 01644: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.0957 - acc: 0.9798 - val_loss: 1.5532 - val_acc: 0.6313\n",
      "Epoch 1645/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1341 - acc: 0.9633Epoch 01645: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1383 - acc: 0.9609 - val_loss: 1.5909 - val_acc: 0.6313\n",
      "Epoch 1646/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1352 - acc: 0.9688Epoch 01646: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1358 - acc: 0.9684 - val_loss: 1.5965 - val_acc: 0.6414\n",
      "Epoch 1647/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1149 - acc: 0.9715Epoch 01647: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1206 - acc: 0.9684 - val_loss: 1.5268 - val_acc: 0.6768\n",
      "Epoch 1648/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1406 - acc: 0.9620Epoch 01648: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1372 - acc: 0.9646 - val_loss: 1.5546 - val_acc: 0.6515\n",
      "Epoch 1649/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1152 - acc: 0.9674Epoch 01649: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1119 - acc: 0.9684 - val_loss: 1.5974 - val_acc: 0.6616\n",
      "Epoch 1650/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1218 - acc: 0.9715Epoch 01650: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1205 - acc: 0.9722 - val_loss: 1.6136 - val_acc: 0.6566\n",
      "Epoch 1651/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1285 - acc: 0.9660Epoch 01651: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1244 - acc: 0.9684 - val_loss: 1.5865 - val_acc: 0.6616\n",
      "Epoch 1652/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1015 - acc: 0.9715Epoch 01652: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1138 - acc: 0.9659 - val_loss: 1.6308 - val_acc: 0.6515\n",
      "Epoch 1653/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1001 - acc: 0.9796Epoch 01653: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.0956 - acc: 0.9811 - val_loss: 1.5993 - val_acc: 0.6515\n",
      "Epoch 1654/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1088 - acc: 0.9769Epoch 01654: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1049 - acc: 0.9773 - val_loss: 1.5818 - val_acc: 0.6616\n",
      "Epoch 1655/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0992 - acc: 0.9742Epoch 01655: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1011 - acc: 0.9722 - val_loss: 1.6024 - val_acc: 0.6616\n",
      "Epoch 1656/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1209 - acc: 0.9660Epoch 01656: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1191 - acc: 0.9672 - val_loss: 1.6631 - val_acc: 0.6313\n",
      "Epoch 1657/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1213 - acc: 0.9647Epoch 01657: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1241 - acc: 0.9646 - val_loss: 1.5797 - val_acc: 0.6566\n",
      "Epoch 1658/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1257 - acc: 0.9728Epoch 01658: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1228 - acc: 0.9735 - val_loss: 1.5803 - val_acc: 0.6465\n",
      "Epoch 1659/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0996 - acc: 0.9755Epoch 01659: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.0988 - acc: 0.9760 - val_loss: 1.5892 - val_acc: 0.6566\n",
      "Epoch 1660/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1223 - acc: 0.9715Epoch 01660: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1210 - acc: 0.9735 - val_loss: 1.5965 - val_acc: 0.6566\n",
      "Epoch 1661/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1248 - acc: 0.9742Epoch 01661: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1234 - acc: 0.9747 - val_loss: 1.5919 - val_acc: 0.6515\n",
      "Epoch 1662/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1153 - acc: 0.9769Epoch 01662: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1206 - acc: 0.9735 - val_loss: 1.6037 - val_acc: 0.6566\n",
      "Epoch 1663/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1231 - acc: 0.9620Epoch 01663: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1285 - acc: 0.9596 - val_loss: 1.6538 - val_acc: 0.6212\n",
      "Epoch 1664/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1322 - acc: 0.9660Epoch 01664: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1364 - acc: 0.9621 - val_loss: 1.6303 - val_acc: 0.6616\n",
      "Epoch 1665/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1070 - acc: 0.9688Epoch 01665: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1116 - acc: 0.9684 - val_loss: 1.5984 - val_acc: 0.6465\n",
      "Epoch 1666/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1024 - acc: 0.9755Epoch 01666: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1052 - acc: 0.9747 - val_loss: 1.6240 - val_acc: 0.6313\n",
      "Epoch 1667/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1269 - acc: 0.9633Epoch 01667: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1249 - acc: 0.9634 - val_loss: 1.6399 - val_acc: 0.6414\n",
      "Epoch 1668/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1260 - acc: 0.9660Epoch 01668: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1223 - acc: 0.9672 - val_loss: 1.5867 - val_acc: 0.6465\n",
      "Epoch 1669/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1205 - acc: 0.9715Epoch 01669: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1195 - acc: 0.9710 - val_loss: 1.5894 - val_acc: 0.6566\n",
      "Epoch 1670/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1201 - acc: 0.9660Epoch 01670: val_loss did not improve\n",
      "792/792 [==============================] - 1s 938us/step - loss: 0.1180 - acc: 0.9672 - val_loss: 1.5616 - val_acc: 0.6667\n",
      "Epoch 1671/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1463 - acc: 0.9606Epoch 01671: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1398 - acc: 0.9621 - val_loss: 1.6144 - val_acc: 0.6414\n",
      "Epoch 1672/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1328 - acc: 0.9688Epoch 01672: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1266 - acc: 0.9710 - val_loss: 1.6103 - val_acc: 0.6414\n",
      "Epoch 1673/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0978 - acc: 0.9810Epoch 01673: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.0998 - acc: 0.9811 - val_loss: 1.6180 - val_acc: 0.6414\n",
      "Epoch 1674/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1087 - acc: 0.9715Epoch 01674: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1102 - acc: 0.9710 - val_loss: 1.5920 - val_acc: 0.6414\n",
      "Epoch 1675/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0980 - acc: 0.9810Epoch 01675: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1004 - acc: 0.9773 - val_loss: 1.6233 - val_acc: 0.6414\n",
      "Epoch 1676/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1379 - acc: 0.9538Epoch 01676: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1360 - acc: 0.9533 - val_loss: 1.5873 - val_acc: 0.6364\n",
      "Epoch 1677/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1172 - acc: 0.9715Epoch 01677: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1199 - acc: 0.9722 - val_loss: 1.5943 - val_acc: 0.6313\n",
      "Epoch 1678/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1228 - acc: 0.9715Epoch 01678: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1224 - acc: 0.9722 - val_loss: 1.5561 - val_acc: 0.6313\n",
      "Epoch 1679/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0922 - acc: 0.9769Epoch 01679: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.0917 - acc: 0.9785 - val_loss: 1.5899 - val_acc: 0.6465\n",
      "Epoch 1680/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1095 - acc: 0.9755Epoch 01680: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1104 - acc: 0.9760 - val_loss: 1.6055 - val_acc: 0.6667\n",
      "Epoch 1681/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1294 - acc: 0.9674Epoch 01681: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1315 - acc: 0.9659 - val_loss: 1.5799 - val_acc: 0.6515\n",
      "Epoch 1682/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1390 - acc: 0.9552Epoch 01682: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1384 - acc: 0.9558 - val_loss: 1.5993 - val_acc: 0.6364\n",
      "Epoch 1683/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1071 - acc: 0.9742Epoch 01683: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1073 - acc: 0.9735 - val_loss: 1.5626 - val_acc: 0.6364\n",
      "Epoch 1684/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1172 - acc: 0.9647Epoch 01684: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1178 - acc: 0.9646 - val_loss: 1.5816 - val_acc: 0.6364\n",
      "Epoch 1685/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1432 - acc: 0.9592Epoch 01685: val_loss did not improve\n",
      "792/792 [==============================] - 1s 933us/step - loss: 0.1424 - acc: 0.9609 - val_loss: 1.5851 - val_acc: 0.6263\n",
      "Epoch 1686/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1490 - acc: 0.9524Epoch 01686: val_loss did not improve\n",
      "792/792 [==============================] - 1s 934us/step - loss: 0.1443 - acc: 0.9545 - val_loss: 1.6270 - val_acc: 0.6263\n",
      "Epoch 1687/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1213 - acc: 0.9620Epoch 01687: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1162 - acc: 0.9646 - val_loss: 1.5940 - val_acc: 0.6364\n",
      "Epoch 1688/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1283 - acc: 0.9701Epoch 01688: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1238 - acc: 0.9710 - val_loss: 1.6414 - val_acc: 0.6212\n",
      "Epoch 1689/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1177 - acc: 0.9742Epoch 01689: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1145 - acc: 0.9747 - val_loss: 1.6731 - val_acc: 0.6364\n",
      "Epoch 1690/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1287 - acc: 0.9742Epoch 01690: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.1253 - acc: 0.9760 - val_loss: 1.6836 - val_acc: 0.6313\n",
      "Epoch 1691/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1291 - acc: 0.9660Epoch 01691: val_loss did not improve\n",
      "792/792 [==============================] - 1s 930us/step - loss: 0.1244 - acc: 0.9684 - val_loss: 1.6605 - val_acc: 0.6162\n",
      "Epoch 1692/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1266 - acc: 0.9742Epoch 01692: val_loss did not improve\n",
      "792/792 [==============================] - 1s 918us/step - loss: 0.1295 - acc: 0.9710 - val_loss: 1.5982 - val_acc: 0.6364\n",
      "Epoch 1693/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0928 - acc: 0.9837Epoch 01693: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.0980 - acc: 0.9798 - val_loss: 1.5756 - val_acc: 0.6566\n",
      "Epoch 1694/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1056 - acc: 0.9728Epoch 01694: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1106 - acc: 0.9710 - val_loss: 1.6237 - val_acc: 0.6616\n",
      "Epoch 1695/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1316 - acc: 0.9633Epoch 01695: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1256 - acc: 0.9659 - val_loss: 1.6155 - val_acc: 0.6465\n",
      "Epoch 1696/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0968 - acc: 0.9783Epoch 01696: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.0958 - acc: 0.9798 - val_loss: 1.5729 - val_acc: 0.6717\n",
      "Epoch 1697/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1080 - acc: 0.9769Epoch 01697: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1080 - acc: 0.9760 - val_loss: 1.5850 - val_acc: 0.6515\n",
      "Epoch 1698/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1089 - acc: 0.9769Epoch 01698: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1054 - acc: 0.9785 - val_loss: 1.5733 - val_acc: 0.6818\n",
      "Epoch 1699/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1181 - acc: 0.9674Epoch 01699: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1191 - acc: 0.9672 - val_loss: 1.5750 - val_acc: 0.6667\n",
      "Epoch 1700/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0997 - acc: 0.9728Epoch 01700: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.0950 - acc: 0.9747 - val_loss: 1.6218 - val_acc: 0.6515\n",
      "Epoch 1701/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1040 - acc: 0.9728Epoch 01701: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1016 - acc: 0.9747 - val_loss: 1.6602 - val_acc: 0.6364\n",
      "Epoch 1702/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1080 - acc: 0.9769- ETA: 0s - loss: 0.0807 - accEpoch 01702: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1080 - acc: 0.9760 - val_loss: 1.6106 - val_acc: 0.6313\n",
      "Epoch 1703/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1309 - acc: 0.9633Epoch 01703: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1270 - acc: 0.9646 - val_loss: 1.6299 - val_acc: 0.6414\n",
      "Epoch 1704/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1176 - acc: 0.9701Epoch 01704: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1201 - acc: 0.9684 - val_loss: 1.6325 - val_acc: 0.6111\n",
      "Epoch 1705/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1261 - acc: 0.9742Epoch 01705: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1220 - acc: 0.9747 - val_loss: 1.6184 - val_acc: 0.6414\n",
      "Epoch 1706/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1150 - acc: 0.9633Epoch 01706: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1211 - acc: 0.9621 - val_loss: 1.6260 - val_acc: 0.6364\n",
      "Epoch 1707/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1470 - acc: 0.9647Epoch 01707: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1510 - acc: 0.9634 - val_loss: 1.6062 - val_acc: 0.6616\n",
      "Epoch 1708/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1198 - acc: 0.9742Epoch 01708: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1145 - acc: 0.9760 - val_loss: 1.6345 - val_acc: 0.6414\n",
      "Epoch 1709/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1193 - acc: 0.9688Epoch 01709: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1201 - acc: 0.9684 - val_loss: 1.6228 - val_acc: 0.6364\n",
      "Epoch 1710/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1033 - acc: 0.9769Epoch 01710: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1003 - acc: 0.9785 - val_loss: 1.6142 - val_acc: 0.6313\n",
      "Epoch 1711/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1221 - acc: 0.9715Epoch 01711: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1183 - acc: 0.9722 - val_loss: 1.5461 - val_acc: 0.6667\n",
      "Epoch 1712/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1253 - acc: 0.9701Epoch 01712: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1192 - acc: 0.9722 - val_loss: 1.5363 - val_acc: 0.6566\n",
      "Epoch 1713/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0997 - acc: 0.9783Epoch 01713: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1002 - acc: 0.9785 - val_loss: 1.5646 - val_acc: 0.6566\n",
      "Epoch 1714/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1279 - acc: 0.9606Epoch 01714: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1293 - acc: 0.9583 - val_loss: 1.6501 - val_acc: 0.6313\n",
      "Epoch 1715/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1134 - acc: 0.9755Epoch 01715: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1196 - acc: 0.9735 - val_loss: 1.5933 - val_acc: 0.6263\n",
      "Epoch 1716/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0908 - acc: 0.9796Epoch 01716: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.0922 - acc: 0.9785 - val_loss: 1.6060 - val_acc: 0.6465\n",
      "Epoch 1717/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1025 - acc: 0.9783Epoch 01717: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1031 - acc: 0.9785 - val_loss: 1.6167 - val_acc: 0.6414\n",
      "Epoch 1718/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0995 - acc: 0.9715Epoch 01718: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1032 - acc: 0.9697 - val_loss: 1.6089 - val_acc: 0.6616\n",
      "Epoch 1719/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1094 - acc: 0.9674Epoch 01719: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1136 - acc: 0.9672 - val_loss: 1.5808 - val_acc: 0.6364\n",
      "Epoch 1720/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1143 - acc: 0.9715Epoch 01720: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1222 - acc: 0.9672 - val_loss: 1.6323 - val_acc: 0.6263\n",
      "Epoch 1721/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1072 - acc: 0.9755Epoch 01721: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1048 - acc: 0.9773 - val_loss: 1.6418 - val_acc: 0.6465\n",
      "Epoch 1722/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1225 - acc: 0.9674Epoch 01722: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1240 - acc: 0.9659 - val_loss: 1.6583 - val_acc: 0.6414\n",
      "Epoch 1723/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1073 - acc: 0.9755Epoch 01723: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1092 - acc: 0.9747 - val_loss: 1.7089 - val_acc: 0.6313\n",
      "Epoch 1724/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0860 - acc: 0.9742Epoch 01724: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.0898 - acc: 0.9722 - val_loss: 1.6945 - val_acc: 0.6263\n",
      "Epoch 1725/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1152 - acc: 0.9715Epoch 01725: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1164 - acc: 0.9697 - val_loss: 1.6834 - val_acc: 0.6111\n",
      "Epoch 1726/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1473 - acc: 0.9579Epoch 01726: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1546 - acc: 0.9545 - val_loss: 1.6571 - val_acc: 0.6465\n",
      "Epoch 1727/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1327 - acc: 0.9647Epoch 01727: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1285 - acc: 0.9646 - val_loss: 1.6797 - val_acc: 0.6212\n",
      "Epoch 1728/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1191 - acc: 0.9728Epoch 01728: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1145 - acc: 0.9747 - val_loss: 1.6713 - val_acc: 0.6061\n",
      "Epoch 1729/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1298 - acc: 0.9715Epoch 01729: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1308 - acc: 0.9697 - val_loss: 1.6683 - val_acc: 0.6111\n",
      "Epoch 1730/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1042 - acc: 0.9755Epoch 01730: val_loss did not improve\n",
      "792/792 [==============================] - 1s 937us/step - loss: 0.1043 - acc: 0.9760 - val_loss: 1.6098 - val_acc: 0.6313\n",
      "Epoch 1731/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1016 - acc: 0.9688Epoch 01731: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1008 - acc: 0.9697 - val_loss: 1.6173 - val_acc: 0.6465\n",
      "Epoch 1732/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0888 - acc: 0.9796Epoch 01732: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.0871 - acc: 0.9811 - val_loss: 1.6658 - val_acc: 0.6313\n",
      "Epoch 1733/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1309 - acc: 0.9674Epoch 01733: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1283 - acc: 0.9684 - val_loss: 1.6884 - val_acc: 0.6313\n",
      "Epoch 1734/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1131 - acc: 0.9728Epoch 01734: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1079 - acc: 0.9747 - val_loss: 1.6060 - val_acc: 0.6515\n",
      "Epoch 1735/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1198 - acc: 0.9660Epoch 01735: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1214 - acc: 0.9659 - val_loss: 1.6330 - val_acc: 0.6515\n",
      "Epoch 1736/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1441 - acc: 0.9579Epoch 01736: val_loss did not improve\n",
      "792/792 [==============================] - 1s 931us/step - loss: 0.1428 - acc: 0.9583 - val_loss: 1.6198 - val_acc: 0.6263\n",
      "Epoch 1737/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1258 - acc: 0.9701Epoch 01737: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1327 - acc: 0.9684 - val_loss: 1.6244 - val_acc: 0.6162\n",
      "Epoch 1738/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1303 - acc: 0.9701Epoch 01738: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1247 - acc: 0.9722 - val_loss: 1.6445 - val_acc: 0.5960\n",
      "Epoch 1739/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0966 - acc: 0.9755Epoch 01739: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.0989 - acc: 0.9747 - val_loss: 1.5873 - val_acc: 0.6010\n",
      "Epoch 1740/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1011 - acc: 0.9783Epoch 01740: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1065 - acc: 0.9735 - val_loss: 1.5916 - val_acc: 0.6465\n",
      "Epoch 1741/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1347 - acc: 0.9633Epoch 01741: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1346 - acc: 0.9634 - val_loss: 1.5876 - val_acc: 0.6212\n",
      "Epoch 1742/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0967 - acc: 0.9742Epoch 01742: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.0985 - acc: 0.9722 - val_loss: 1.6645 - val_acc: 0.6162\n",
      "Epoch 1743/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1282 - acc: 0.9715Epoch 01743: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1295 - acc: 0.9697 - val_loss: 1.6226 - val_acc: 0.6313\n",
      "Epoch 1744/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0911 - acc: 0.9796Epoch 01744: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.0919 - acc: 0.9785 - val_loss: 1.6188 - val_acc: 0.6162\n",
      "Epoch 1745/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1116 - acc: 0.9715Epoch 01745: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1125 - acc: 0.9710 - val_loss: 1.7041 - val_acc: 0.6162\n",
      "Epoch 1746/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1014 - acc: 0.9783Epoch 01746: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1075 - acc: 0.9760 - val_loss: 1.6642 - val_acc: 0.6111\n",
      "Epoch 1747/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1164 - acc: 0.9688Epoch 01747: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1197 - acc: 0.9672 - val_loss: 1.6780 - val_acc: 0.6313\n",
      "Epoch 1748/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1204 - acc: 0.9715Epoch 01748: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1182 - acc: 0.9710 - val_loss: 1.6019 - val_acc: 0.6263\n",
      "Epoch 1749/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1221 - acc: 0.9633Epoch 01749: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1231 - acc: 0.9646 - val_loss: 1.6210 - val_acc: 0.6162\n",
      "Epoch 1750/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0971 - acc: 0.9769Epoch 01750: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.0983 - acc: 0.9773 - val_loss: 1.6073 - val_acc: 0.6414\n",
      "Epoch 1751/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1322 - acc: 0.9674Epoch 01751: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1327 - acc: 0.9659 - val_loss: 1.6163 - val_acc: 0.6212\n",
      "Epoch 1752/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1115 - acc: 0.9715Epoch 01752: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1111 - acc: 0.9722 - val_loss: 1.6614 - val_acc: 0.6313\n",
      "Epoch 1753/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1221 - acc: 0.9715Epoch 01753: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1185 - acc: 0.9722 - val_loss: 1.6831 - val_acc: 0.6111\n",
      "Epoch 1754/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1066 - acc: 0.9728Epoch 01754: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1068 - acc: 0.9722 - val_loss: 1.6617 - val_acc: 0.6414\n",
      "Epoch 1755/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1305 - acc: 0.9647Epoch 01755: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1298 - acc: 0.9634 - val_loss: 1.6153 - val_acc: 0.6414\n",
      "Epoch 1756/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1210 - acc: 0.9660Epoch 01756: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1234 - acc: 0.9659 - val_loss: 1.6436 - val_acc: 0.6465\n",
      "Epoch 1757/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1007 - acc: 0.9769Epoch 01757: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1002 - acc: 0.9773 - val_loss: 1.6513 - val_acc: 0.6313\n",
      "Epoch 1758/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1188 - acc: 0.9701Epoch 01758: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1154 - acc: 0.9710 - val_loss: 1.6133 - val_acc: 0.6414\n",
      "Epoch 1759/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1211 - acc: 0.9688Epoch 01759: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1182 - acc: 0.9684 - val_loss: 1.5870 - val_acc: 0.6465\n",
      "Epoch 1760/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1008 - acc: 0.9742Epoch 01760: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1036 - acc: 0.9747 - val_loss: 1.6210 - val_acc: 0.6465\n",
      "Epoch 1761/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1106 - acc: 0.9728Epoch 01761: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1135 - acc: 0.9710 - val_loss: 1.6173 - val_acc: 0.6414\n",
      "Epoch 1762/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1135 - acc: 0.9769Epoch 01762: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1089 - acc: 0.9785 - val_loss: 1.5626 - val_acc: 0.6515\n",
      "Epoch 1763/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1215 - acc: 0.9715Epoch 01763: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1155 - acc: 0.9735 - val_loss: 1.5403 - val_acc: 0.6313\n",
      "Epoch 1764/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0998 - acc: 0.9823Epoch 01764: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1009 - acc: 0.9785 - val_loss: 1.5732 - val_acc: 0.6465\n",
      "Epoch 1765/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1007 - acc: 0.9742Epoch 01765: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1005 - acc: 0.9747 - val_loss: 1.5851 - val_acc: 0.6465\n",
      "Epoch 1766/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1193 - acc: 0.9715Epoch 01766: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1190 - acc: 0.9722 - val_loss: 1.6220 - val_acc: 0.6465\n",
      "Epoch 1767/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1029 - acc: 0.9769Epoch 01767: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1093 - acc: 0.9747 - val_loss: 1.5894 - val_acc: 0.6566\n",
      "Epoch 1768/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1139 - acc: 0.9715Epoch 01768: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1149 - acc: 0.9722 - val_loss: 1.6015 - val_acc: 0.6111\n",
      "Epoch 1769/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1166 - acc: 0.9728Epoch 01769: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1202 - acc: 0.9710 - val_loss: 1.5936 - val_acc: 0.6515\n",
      "Epoch 1770/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1194 - acc: 0.9674Epoch 01770: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1157 - acc: 0.9697 - val_loss: 1.5992 - val_acc: 0.6414\n",
      "Epoch 1771/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1144 - acc: 0.9688Epoch 01771: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1139 - acc: 0.9672 - val_loss: 1.6500 - val_acc: 0.6111\n",
      "Epoch 1772/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1205 - acc: 0.9688Epoch 01772: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1200 - acc: 0.9672 - val_loss: 1.6456 - val_acc: 0.6364\n",
      "Epoch 1773/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1160 - acc: 0.9674Epoch 01773: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1129 - acc: 0.9684 - val_loss: 1.6263 - val_acc: 0.6414\n",
      "Epoch 1774/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1003 - acc: 0.9755Epoch 01774: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.0975 - acc: 0.9760 - val_loss: 1.6386 - val_acc: 0.6414\n",
      "Epoch 1775/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1471 - acc: 0.9701Epoch 01775: val_loss did not improve\n",
      "792/792 [==============================] - 1s 939us/step - loss: 0.1411 - acc: 0.9710 - val_loss: 1.6170 - val_acc: 0.6212\n",
      "Epoch 1776/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1111 - acc: 0.9783Epoch 01776: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1227 - acc: 0.9735 - val_loss: 1.5854 - val_acc: 0.6566\n",
      "Epoch 1777/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1332 - acc: 0.9742Epoch 01777: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1277 - acc: 0.9747 - val_loss: 1.5692 - val_acc: 0.6566\n",
      "Epoch 1778/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0893 - acc: 0.9837Epoch 01778: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.0891 - acc: 0.9836 - val_loss: 1.5914 - val_acc: 0.6566\n",
      "Epoch 1779/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1157 - acc: 0.9647Epoch 01779: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1168 - acc: 0.9646 - val_loss: 1.6332 - val_acc: 0.6364\n",
      "Epoch 1780/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1046 - acc: 0.9688Epoch 01780: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1078 - acc: 0.9684 - val_loss: 1.6425 - val_acc: 0.6364\n",
      "Epoch 1781/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1248 - acc: 0.9647Epoch 01781: val_loss did not improve\n",
      "792/792 [==============================] - 1s 932us/step - loss: 0.1221 - acc: 0.9659 - val_loss: 1.6587 - val_acc: 0.6364\n",
      "Epoch 1782/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1151 - acc: 0.9728Epoch 01782: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1178 - acc: 0.9710 - val_loss: 1.6529 - val_acc: 0.6566\n",
      "Epoch 1783/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1224 - acc: 0.9579Epoch 01783: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1168 - acc: 0.9609 - val_loss: 1.6517 - val_acc: 0.6212\n",
      "Epoch 1784/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1226 - acc: 0.9701Epoch 01784: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1209 - acc: 0.9697 - val_loss: 1.6336 - val_acc: 0.6313\n",
      "Epoch 1785/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0958 - acc: 0.9769Epoch 01785: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.0972 - acc: 0.9773 - val_loss: 1.5936 - val_acc: 0.6414\n",
      "Epoch 1786/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1318 - acc: 0.9565Epoch 01786: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1314 - acc: 0.9571 - val_loss: 1.6427 - val_acc: 0.6414\n",
      "Epoch 1787/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1122 - acc: 0.9647Epoch 01787: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1150 - acc: 0.9646 - val_loss: 1.5966 - val_acc: 0.6364\n",
      "Epoch 1788/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1285 - acc: 0.9701Epoch 01788: val_loss did not improve\n",
      "792/792 [==============================] - 1s 936us/step - loss: 0.1236 - acc: 0.9710 - val_loss: 1.6360 - val_acc: 0.6162\n",
      "Epoch 1789/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1232 - acc: 0.9688Epoch 01789: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1218 - acc: 0.9697 - val_loss: 1.6217 - val_acc: 0.6313\n",
      "Epoch 1790/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1144 - acc: 0.9701Epoch 01790: val_loss did not improve\n",
      "792/792 [==============================] - 1s 941us/step - loss: 0.1153 - acc: 0.9710 - val_loss: 1.6028 - val_acc: 0.6414\n",
      "Epoch 1791/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1214 - acc: 0.9620Epoch 01791: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1184 - acc: 0.9646 - val_loss: 1.6830 - val_acc: 0.6010\n",
      "Epoch 1792/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1220 - acc: 0.9660Epoch 01792: val_loss did not improve\n",
      "792/792 [==============================] - 1s 928us/step - loss: 0.1161 - acc: 0.9684 - val_loss: 1.6693 - val_acc: 0.6212\n",
      "Epoch 1793/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1049 - acc: 0.9755Epoch 01793: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1072 - acc: 0.9760 - val_loss: 1.6568 - val_acc: 0.6364\n",
      "Epoch 1794/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1091 - acc: 0.9674Epoch 01794: val_loss did not improve\n",
      "792/792 [==============================] - 1s 933us/step - loss: 0.1041 - acc: 0.9697 - val_loss: 1.7047 - val_acc: 0.6212\n",
      "Epoch 1795/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1185 - acc: 0.9742Epoch 01795: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1151 - acc: 0.9747 - val_loss: 1.6542 - val_acc: 0.6465\n",
      "Epoch 1796/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1196 - acc: 0.9701Epoch 01796: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1243 - acc: 0.9684 - val_loss: 1.6356 - val_acc: 0.6364\n",
      "Epoch 1797/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1289 - acc: 0.9660Epoch 01797: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1254 - acc: 0.9684 - val_loss: 1.6034 - val_acc: 0.6313\n",
      "Epoch 1798/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1127 - acc: 0.9755Epoch 01798: val_loss did not improve\n",
      "792/792 [==============================] - 1s 933us/step - loss: 0.1110 - acc: 0.9760 - val_loss: 1.7076 - val_acc: 0.6263\n",
      "Epoch 1799/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1161 - acc: 0.9688Epoch 01799: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1121 - acc: 0.9697 - val_loss: 1.6374 - val_acc: 0.6465\n",
      "Epoch 1800/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1062 - acc: 0.9810Epoch 01800: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1060 - acc: 0.9811 - val_loss: 1.6688 - val_acc: 0.6465\n",
      "Epoch 1801/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1024 - acc: 0.9783Epoch 01801: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.0994 - acc: 0.9798 - val_loss: 1.6575 - val_acc: 0.6465\n",
      "Epoch 1802/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0930 - acc: 0.9742Epoch 01802: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1006 - acc: 0.9747 - val_loss: 1.6637 - val_acc: 0.6364\n",
      "Epoch 1803/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0943 - acc: 0.9837Epoch 01803: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1061 - acc: 0.9798 - val_loss: 1.6669 - val_acc: 0.6212\n",
      "Epoch 1804/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1107 - acc: 0.9769Epoch 01804: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1107 - acc: 0.9760 - val_loss: 1.6800 - val_acc: 0.6111\n",
      "Epoch 1805/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1036 - acc: 0.9755Epoch 01805: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1034 - acc: 0.9747 - val_loss: 1.7032 - val_acc: 0.6263\n",
      "Epoch 1806/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1099 - acc: 0.9755Epoch 01806: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1072 - acc: 0.9760 - val_loss: 1.6500 - val_acc: 0.6364\n",
      "Epoch 1807/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1108 - acc: 0.9755Epoch 01807: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1063 - acc: 0.9773 - val_loss: 1.7102 - val_acc: 0.6212\n",
      "Epoch 1808/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1034 - acc: 0.9823Epoch 01808: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1082 - acc: 0.9798 - val_loss: 1.7341 - val_acc: 0.6515\n",
      "Epoch 1809/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1031 - acc: 0.9633Epoch 01809: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1030 - acc: 0.9646 - val_loss: 1.7511 - val_acc: 0.6263\n",
      "Epoch 1810/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1133 - acc: 0.9715Epoch 01810: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1149 - acc: 0.9697 - val_loss: 1.6990 - val_acc: 0.6465\n",
      "Epoch 1811/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1231 - acc: 0.9701Epoch 01811: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1264 - acc: 0.9697 - val_loss: 1.7421 - val_acc: 0.6313\n",
      "Epoch 1812/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1161 - acc: 0.9769Epoch 01812: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1176 - acc: 0.9760 - val_loss: 1.7257 - val_acc: 0.6263\n",
      "Epoch 1813/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1002 - acc: 0.9755Epoch 01813: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1009 - acc: 0.9760 - val_loss: 1.7347 - val_acc: 0.6263\n",
      "Epoch 1814/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1229 - acc: 0.9715Epoch 01814: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1206 - acc: 0.9722 - val_loss: 1.7416 - val_acc: 0.6465\n",
      "Epoch 1815/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0902 - acc: 0.9796Epoch 01815: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.0954 - acc: 0.9798 - val_loss: 1.7336 - val_acc: 0.6364\n",
      "Epoch 1816/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1320 - acc: 0.9647Epoch 01816: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1391 - acc: 0.9646 - val_loss: 1.7156 - val_acc: 0.6212\n",
      "Epoch 1817/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1354 - acc: 0.9592Epoch 01817: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1348 - acc: 0.9596 - val_loss: 1.6967 - val_acc: 0.6414\n",
      "Epoch 1818/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1060 - acc: 0.9728Epoch 01818: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1044 - acc: 0.9722 - val_loss: 1.6457 - val_acc: 0.6263\n",
      "Epoch 1819/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0994 - acc: 0.9701Epoch 01819: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1012 - acc: 0.9684 - val_loss: 1.6666 - val_acc: 0.6111\n",
      "Epoch 1820/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1237 - acc: 0.9660Epoch 01820: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1262 - acc: 0.9659 - val_loss: 1.6838 - val_acc: 0.6162\n",
      "Epoch 1821/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1433 - acc: 0.9552Epoch 01821: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1438 - acc: 0.9545 - val_loss: 1.6776 - val_acc: 0.6515\n",
      "Epoch 1822/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1334 - acc: 0.9579Epoch 01822: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1293 - acc: 0.9596 - val_loss: 1.6643 - val_acc: 0.6414\n",
      "Epoch 1823/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1172 - acc: 0.9783Epoch 01823: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1153 - acc: 0.9773 - val_loss: 1.7522 - val_acc: 0.6061\n",
      "Epoch 1824/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0987 - acc: 0.9769Epoch 01824: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.0972 - acc: 0.9785 - val_loss: 1.7055 - val_acc: 0.6465\n",
      "Epoch 1825/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1152 - acc: 0.9742Epoch 01825: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1175 - acc: 0.9735 - val_loss: 1.6688 - val_acc: 0.6263\n",
      "Epoch 1826/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1236 - acc: 0.9688Epoch 01826: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1230 - acc: 0.9672 - val_loss: 1.6837 - val_acc: 0.6212\n",
      "Epoch 1827/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1124 - acc: 0.9728Epoch 01827: val_loss did not improve\n",
      "792/792 [==============================] - 1s 944us/step - loss: 0.1093 - acc: 0.9747 - val_loss: 1.6876 - val_acc: 0.6263\n",
      "Epoch 1828/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1088 - acc: 0.9688Epoch 01828: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1104 - acc: 0.9684 - val_loss: 1.6267 - val_acc: 0.6515\n",
      "Epoch 1829/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1232 - acc: 0.9633Epoch 01829: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1263 - acc: 0.9634 - val_loss: 1.6818 - val_acc: 0.6212\n",
      "Epoch 1830/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1165 - acc: 0.9728Epoch 01830: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1167 - acc: 0.9722 - val_loss: 1.6336 - val_acc: 0.6414\n",
      "Epoch 1831/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1296 - acc: 0.9647Epoch 01831: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1314 - acc: 0.9646 - val_loss: 1.6602 - val_acc: 0.6313\n",
      "Epoch 1832/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1294 - acc: 0.9688Epoch 01832: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1263 - acc: 0.9710 - val_loss: 1.6783 - val_acc: 0.6010\n",
      "Epoch 1833/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0919 - acc: 0.9796Epoch 01833: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.0950 - acc: 0.9785 - val_loss: 1.6264 - val_acc: 0.6364\n",
      "Epoch 1834/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1096 - acc: 0.9715Epoch 01834: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1092 - acc: 0.9710 - val_loss: 1.6552 - val_acc: 0.6212\n",
      "Epoch 1835/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1104 - acc: 0.9755Epoch 01835: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1106 - acc: 0.9760 - val_loss: 1.6732 - val_acc: 0.6263\n",
      "Epoch 1836/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1360 - acc: 0.9674Epoch 01836: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1303 - acc: 0.9697 - val_loss: 1.6430 - val_acc: 0.6111\n",
      "Epoch 1837/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1199 - acc: 0.9715Epoch 01837: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1270 - acc: 0.9684 - val_loss: 1.7053 - val_acc: 0.6111\n",
      "Epoch 1838/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1133 - acc: 0.9701Epoch 01838: val_loss did not improve\n",
      "792/792 [==============================] - 1s 942us/step - loss: 0.1119 - acc: 0.9710 - val_loss: 1.6553 - val_acc: 0.6212\n",
      "Epoch 1839/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1169 - acc: 0.9688Epoch 01839: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1214 - acc: 0.9684 - val_loss: 1.6641 - val_acc: 0.6263\n",
      "Epoch 1840/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0986 - acc: 0.9783Epoch 01840: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.1011 - acc: 0.9773 - val_loss: 1.6471 - val_acc: 0.6263\n",
      "Epoch 1841/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1101 - acc: 0.9755Epoch 01841: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1108 - acc: 0.9747 - val_loss: 1.7050 - val_acc: 0.6061\n",
      "Epoch 1842/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1174 - acc: 0.9674Epoch 01842: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1146 - acc: 0.9684 - val_loss: 1.6854 - val_acc: 0.6313\n",
      "Epoch 1843/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1003 - acc: 0.9728Epoch 01843: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1041 - acc: 0.9722 - val_loss: 1.7093 - val_acc: 0.6414\n",
      "Epoch 1844/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1109 - acc: 0.9701Epoch 01844: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1121 - acc: 0.9710 - val_loss: 1.6637 - val_acc: 0.6212\n",
      "Epoch 1845/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1261 - acc: 0.9647Epoch 01845: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1267 - acc: 0.9646 - val_loss: 1.6682 - val_acc: 0.6162\n",
      "Epoch 1846/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1234 - acc: 0.9647Epoch 01846: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1211 - acc: 0.9646 - val_loss: 1.6824 - val_acc: 0.6313\n",
      "Epoch 1847/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1131 - acc: 0.9715Epoch 01847: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1091 - acc: 0.9722 - val_loss: 1.6304 - val_acc: 0.6465\n",
      "Epoch 1848/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1179 - acc: 0.9728Epoch 01848: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1127 - acc: 0.9747 - val_loss: 1.6754 - val_acc: 0.6313\n",
      "Epoch 1849/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1007 - acc: 0.9728Epoch 01849: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1039 - acc: 0.9697 - val_loss: 1.6727 - val_acc: 0.6414\n",
      "Epoch 1850/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1494 - acc: 0.9647Epoch 01850: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1532 - acc: 0.9634 - val_loss: 1.6793 - val_acc: 0.6313\n",
      "Epoch 1851/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1069 - acc: 0.9728Epoch 01851: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1025 - acc: 0.9747 - val_loss: 1.6448 - val_acc: 0.6465\n",
      "Epoch 1852/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1187 - acc: 0.9715Epoch 01852: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1159 - acc: 0.9722 - val_loss: 1.6024 - val_acc: 0.6364\n",
      "Epoch 1853/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0855 - acc: 0.9851Epoch 01853: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.0850 - acc: 0.9848 - val_loss: 1.6682 - val_acc: 0.6313\n",
      "Epoch 1854/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1084 - acc: 0.9769Epoch 01854: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1057 - acc: 0.9785 - val_loss: 1.6906 - val_acc: 0.6010\n",
      "Epoch 1855/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1220 - acc: 0.9674Epoch 01855: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1216 - acc: 0.9684 - val_loss: 1.6276 - val_acc: 0.6212\n",
      "Epoch 1856/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1062 - acc: 0.9742Epoch 01856: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1062 - acc: 0.9735 - val_loss: 1.6157 - val_acc: 0.6414\n",
      "Epoch 1857/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1159 - acc: 0.9728Epoch 01857: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1156 - acc: 0.9722 - val_loss: 1.6049 - val_acc: 0.6162\n",
      "Epoch 1858/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1138 - acc: 0.9755Epoch 01858: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1204 - acc: 0.9735 - val_loss: 1.6388 - val_acc: 0.6162\n",
      "Epoch 1859/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1471 - acc: 0.9633Epoch 01859: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1424 - acc: 0.9646 - val_loss: 1.6416 - val_acc: 0.6162\n",
      "Epoch 1860/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0974 - acc: 0.9810Epoch 01860: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.0971 - acc: 0.9811 - val_loss: 1.6202 - val_acc: 0.6364\n",
      "Epoch 1861/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1137 - acc: 0.9715Epoch 01861: val_loss did not improve\n",
      "792/792 [==============================] - 1s 935us/step - loss: 0.1245 - acc: 0.9672 - val_loss: 1.6782 - val_acc: 0.6162\n",
      "Epoch 1862/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1356 - acc: 0.9606Epoch 01862: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1324 - acc: 0.9634 - val_loss: 1.6513 - val_acc: 0.6364\n",
      "Epoch 1863/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1192 - acc: 0.9728Epoch 01863: val_loss did not improve\n",
      "792/792 [==============================] - 1s 946us/step - loss: 0.1141 - acc: 0.9735 - val_loss: 1.6407 - val_acc: 0.6263\n",
      "Epoch 1864/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1208 - acc: 0.9674Epoch 01864: val_loss did not improve\n",
      "792/792 [==============================] - 1s 945us/step - loss: 0.1187 - acc: 0.9684 - val_loss: 1.6273 - val_acc: 0.6263\n",
      "Epoch 1865/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1207 - acc: 0.9755Epoch 01865: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.1216 - acc: 0.9722 - val_loss: 1.6383 - val_acc: 0.6263\n",
      "Epoch 1866/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1199 - acc: 0.9715Epoch 01866: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1199 - acc: 0.9710 - val_loss: 1.6694 - val_acc: 0.6313\n",
      "Epoch 1867/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1353 - acc: 0.9688Epoch 01867: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1344 - acc: 0.9684 - val_loss: 1.6511 - val_acc: 0.6162\n",
      "Epoch 1868/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1162 - acc: 0.9742Epoch 01868: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1132 - acc: 0.9747 - val_loss: 1.6264 - val_acc: 0.6263\n",
      "Epoch 1869/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1215 - acc: 0.9674Epoch 01869: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1203 - acc: 0.9684 - val_loss: 1.6415 - val_acc: 0.6465\n",
      "Epoch 1870/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1034 - acc: 0.9715Epoch 01870: val_loss did not improve\n",
      "792/792 [==============================] - 1s 940us/step - loss: 0.1029 - acc: 0.9710 - val_loss: 1.6481 - val_acc: 0.6364\n",
      "Epoch 1871/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1261 - acc: 0.9633Epoch 01871: val_loss did not improve\n",
      "792/792 [==============================] - 1s 949us/step - loss: 0.1252 - acc: 0.9646 - val_loss: 1.6194 - val_acc: 0.6465\n",
      "Epoch 1872/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1073 - acc: 0.9701Epoch 01872: val_loss did not improve\n",
      "792/792 [==============================] - 1s 943us/step - loss: 0.1115 - acc: 0.9684 - val_loss: 1.6031 - val_acc: 0.6515\n",
      "Epoch 1873/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1120 - acc: 0.9701Epoch 01873: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1101 - acc: 0.9710 - val_loss: 1.6405 - val_acc: 0.6566\n",
      "Epoch 1874/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1110 - acc: 0.9742Epoch 01874: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 0.1122 - acc: 0.9710 - val_loss: 1.6495 - val_acc: 0.6263\n",
      "Epoch 1875/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0979 - acc: 0.9755Epoch 01875: val_loss did not improve\n",
      "792/792 [==============================] - 1s 947us/step - loss: 0.0996 - acc: 0.9747 - val_loss: 1.6501 - val_acc: 0.6313\n",
      "Epoch 1876/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1219 - acc: 0.9633Epoch 01876: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1214 - acc: 0.9646 - val_loss: 1.6105 - val_acc: 0.6414\n",
      "Epoch 1877/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0930 - acc: 0.9755Epoch 01877: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.0936 - acc: 0.9735 - val_loss: 1.6087 - val_acc: 0.6212\n",
      "Epoch 1878/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1137 - acc: 0.9715Epoch 01878: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1082 - acc: 0.9735 - val_loss: 1.6540 - val_acc: 0.6313\n",
      "Epoch 1879/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0995 - acc: 0.9783Epoch 01879: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1048 - acc: 0.9747 - val_loss: 1.7068 - val_acc: 0.6212\n",
      "Epoch 1880/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1224 - acc: 0.9620Epoch 01880: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1259 - acc: 0.9634 - val_loss: 1.6733 - val_acc: 0.6162\n",
      "Epoch 1881/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1092 - acc: 0.9688Epoch 01881: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1101 - acc: 0.9697 - val_loss: 1.6914 - val_acc: 0.6162\n",
      "Epoch 1882/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1170 - acc: 0.9715Epoch 01882: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1204 - acc: 0.9697 - val_loss: 1.6171 - val_acc: 0.6414\n",
      "Epoch 1883/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1104 - acc: 0.9715Epoch 01883: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1098 - acc: 0.9735 - val_loss: 1.6816 - val_acc: 0.6061\n",
      "Epoch 1884/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0928 - acc: 0.9769Epoch 01884: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.0971 - acc: 0.9747 - val_loss: 1.7698 - val_acc: 0.5808\n",
      "Epoch 1885/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1117 - acc: 0.9715Epoch 01885: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1107 - acc: 0.9710 - val_loss: 1.6339 - val_acc: 0.6111\n",
      "Epoch 1886/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1200 - acc: 0.9742Epoch 01886: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1163 - acc: 0.9747 - val_loss: 1.7074 - val_acc: 0.5960\n",
      "Epoch 1887/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1068 - acc: 0.9728Epoch 01887: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1069 - acc: 0.9735 - val_loss: 1.6858 - val_acc: 0.6364\n",
      "Epoch 1888/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1311 - acc: 0.9620Epoch 01888: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1293 - acc: 0.9621 - val_loss: 1.6619 - val_acc: 0.6414\n",
      "Epoch 1889/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1061 - acc: 0.9728Epoch 01889: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1074 - acc: 0.9722 - val_loss: 1.6454 - val_acc: 0.6263\n",
      "Epoch 1890/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1318 - acc: 0.9633Epoch 01890: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1316 - acc: 0.9634 - val_loss: 1.7187 - val_acc: 0.6263\n",
      "Epoch 1891/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0893 - acc: 0.9796Epoch 01891: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.0920 - acc: 0.9785 - val_loss: 1.7004 - val_acc: 0.6212\n",
      "Epoch 1892/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1169 - acc: 0.9742Epoch 01892: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1138 - acc: 0.9760 - val_loss: 1.6858 - val_acc: 0.6212\n",
      "Epoch 1893/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1229 - acc: 0.9715Epoch 01893: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1208 - acc: 0.9710 - val_loss: 1.6705 - val_acc: 0.6212\n",
      "Epoch 1894/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1179 - acc: 0.9728Epoch 01894: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1148 - acc: 0.9747 - val_loss: 1.6856 - val_acc: 0.6364\n",
      "Epoch 1895/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1260 - acc: 0.9674Epoch 01895: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1211 - acc: 0.9697 - val_loss: 1.6560 - val_acc: 0.6414\n",
      "Epoch 1896/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0821 - acc: 0.9837Epoch 01896: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.0805 - acc: 0.9848 - val_loss: 1.6442 - val_acc: 0.6212\n",
      "Epoch 1897/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1060 - acc: 0.9755Epoch 01897: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1055 - acc: 0.9773 - val_loss: 1.7080 - val_acc: 0.6212\n",
      "Epoch 1898/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0886 - acc: 0.9851Epoch 01898: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.0948 - acc: 0.9836 - val_loss: 1.6997 - val_acc: 0.6313\n",
      "Epoch 1899/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1226 - acc: 0.9674Epoch 01899: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1163 - acc: 0.9697 - val_loss: 1.6916 - val_acc: 0.6414\n",
      "Epoch 1900/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1114 - acc: 0.9674Epoch 01900: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1175 - acc: 0.9659 - val_loss: 1.6817 - val_acc: 0.6364\n",
      "Epoch 1901/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1055 - acc: 0.9728Epoch 01901: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1023 - acc: 0.9747 - val_loss: 1.6601 - val_acc: 0.6364\n",
      "Epoch 1902/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1138 - acc: 0.9688Epoch 01902: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1113 - acc: 0.9710 - val_loss: 1.6353 - val_acc: 0.6566\n",
      "Epoch 1903/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0991 - acc: 0.9769Epoch 01903: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.0968 - acc: 0.9773 - val_loss: 1.6638 - val_acc: 0.6313\n",
      "Epoch 1904/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1178 - acc: 0.9728Epoch 01904: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1154 - acc: 0.9735 - val_loss: 1.7213 - val_acc: 0.5960\n",
      "Epoch 1905/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0996 - acc: 0.9755Epoch 01905: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.0986 - acc: 0.9760 - val_loss: 1.6144 - val_acc: 0.6414\n",
      "Epoch 1906/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1236 - acc: 0.9728Epoch 01906: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1198 - acc: 0.9735 - val_loss: 1.5895 - val_acc: 0.6566\n",
      "Epoch 1907/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0961 - acc: 0.9742Epoch 01907: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 0.0994 - acc: 0.9722 - val_loss: 1.6216 - val_acc: 0.6313\n",
      "Epoch 1908/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0833 - acc: 0.9837Epoch 01908: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.0864 - acc: 0.9836 - val_loss: 1.5935 - val_acc: 0.6414\n",
      "Epoch 1909/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1172 - acc: 0.9688Epoch 01909: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1145 - acc: 0.9697 - val_loss: 1.6398 - val_acc: 0.6313\n",
      "Epoch 1910/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1359 - acc: 0.9620Epoch 01910: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1327 - acc: 0.9646 - val_loss: 1.6364 - val_acc: 0.6313\n",
      "Epoch 1911/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1015 - acc: 0.9728Epoch 01911: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.0975 - acc: 0.9747 - val_loss: 1.6046 - val_acc: 0.6364\n",
      "Epoch 1912/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1137 - acc: 0.9647Epoch 01912: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1161 - acc: 0.9659 - val_loss: 1.6481 - val_acc: 0.6566\n",
      "Epoch 1913/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1105 - acc: 0.9728Epoch 01913: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1134 - acc: 0.9735 - val_loss: 1.6479 - val_acc: 0.6364\n",
      "Epoch 1914/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0823 - acc: 0.9851Epoch 01914: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.0842 - acc: 0.9848 - val_loss: 1.6291 - val_acc: 0.6465\n",
      "Epoch 1915/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1192 - acc: 0.9742Epoch 01915: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1244 - acc: 0.9710 - val_loss: 1.6315 - val_acc: 0.6566\n",
      "Epoch 1916/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0985 - acc: 0.9769Epoch 01916: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.0979 - acc: 0.9760 - val_loss: 1.6516 - val_acc: 0.6313\n",
      "Epoch 1917/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1259 - acc: 0.9660Epoch 01917: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1252 - acc: 0.9672 - val_loss: 1.6533 - val_acc: 0.6616\n",
      "Epoch 1918/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0980 - acc: 0.9715Epoch 01918: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1011 - acc: 0.9697 - val_loss: 1.6919 - val_acc: 0.6313\n",
      "Epoch 1919/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1172 - acc: 0.9715Epoch 01919: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1149 - acc: 0.9735 - val_loss: 1.6370 - val_acc: 0.6414\n",
      "Epoch 1920/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1052 - acc: 0.9674Epoch 01920: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1102 - acc: 0.9672 - val_loss: 1.7196 - val_acc: 0.6111\n",
      "Epoch 1921/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1205 - acc: 0.9674Epoch 01921: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1152 - acc: 0.9697 - val_loss: 1.6889 - val_acc: 0.6364\n",
      "Epoch 1922/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1030 - acc: 0.9769Epoch 01922: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.1007 - acc: 0.9773 - val_loss: 1.6624 - val_acc: 0.6364\n",
      "Epoch 1923/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0814 - acc: 0.9823Epoch 01923: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.0869 - acc: 0.9798 - val_loss: 1.6644 - val_acc: 0.6263\n",
      "Epoch 1924/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1083 - acc: 0.9783Epoch 01924: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1098 - acc: 0.9760 - val_loss: 1.6231 - val_acc: 0.6414\n",
      "Epoch 1925/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1003 - acc: 0.9742Epoch 01925: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.1004 - acc: 0.9747 - val_loss: 1.6263 - val_acc: 0.6465\n",
      "Epoch 1926/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0955 - acc: 0.9810Epoch 01926: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.0950 - acc: 0.9798 - val_loss: 1.6866 - val_acc: 0.6212\n",
      "Epoch 1927/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1186 - acc: 0.9755Epoch 01927: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1131 - acc: 0.9773 - val_loss: 1.6126 - val_acc: 0.6212\n",
      "Epoch 1928/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1175 - acc: 0.9688Epoch 01928: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1154 - acc: 0.9684 - val_loss: 1.6000 - val_acc: 0.6515\n",
      "Epoch 1929/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1031 - acc: 0.9755Epoch 01929: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1033 - acc: 0.9747 - val_loss: 1.6757 - val_acc: 0.6313\n",
      "Epoch 1930/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0892 - acc: 0.9810Epoch 01930: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.0923 - acc: 0.9811 - val_loss: 1.6427 - val_acc: 0.6313\n",
      "Epoch 1931/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1117 - acc: 0.9728Epoch 01931: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 0.1136 - acc: 0.9722 - val_loss: 1.6337 - val_acc: 0.6515\n",
      "Epoch 1932/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0880 - acc: 0.9823Epoch 01932: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.0871 - acc: 0.9823 - val_loss: 1.6849 - val_acc: 0.6162\n",
      "Epoch 1933/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1330 - acc: 0.9620Epoch 01933: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 0.1297 - acc: 0.9609 - val_loss: 1.6636 - val_acc: 0.6263\n",
      "Epoch 1934/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0973 - acc: 0.9742Epoch 01934: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.0934 - acc: 0.9760 - val_loss: 1.6690 - val_acc: 0.6364\n",
      "Epoch 1935/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1249 - acc: 0.9633Epoch 01935: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1225 - acc: 0.9621 - val_loss: 1.7316 - val_acc: 0.6010\n",
      "Epoch 1936/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1076 - acc: 0.9728Epoch 01936: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1072 - acc: 0.9735 - val_loss: 1.6956 - val_acc: 0.6212\n",
      "Epoch 1937/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1183 - acc: 0.9633Epoch 01937: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1182 - acc: 0.9634 - val_loss: 1.7699 - val_acc: 0.6162\n",
      "Epoch 1938/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0975 - acc: 0.9755Epoch 01938: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.0962 - acc: 0.9773 - val_loss: 1.6597 - val_acc: 0.6162\n",
      "Epoch 1939/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1209 - acc: 0.9633Epoch 01939: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 0.1156 - acc: 0.9659 - val_loss: 1.7114 - val_acc: 0.6061\n",
      "Epoch 1940/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1164 - acc: 0.9647Epoch 01940: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1146 - acc: 0.9659 - val_loss: 1.6514 - val_acc: 0.6263\n",
      "Epoch 1941/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0861 - acc: 0.9810Epoch 01941: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.0933 - acc: 0.9773 - val_loss: 1.6557 - val_acc: 0.6111\n",
      "Epoch 1942/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1034 - acc: 0.9701Epoch 01942: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.1009 - acc: 0.9722 - val_loss: 1.6655 - val_acc: 0.6364\n",
      "Epoch 1943/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0976 - acc: 0.9688Epoch 01943: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 0.0945 - acc: 0.9710 - val_loss: 1.6949 - val_acc: 0.6414\n",
      "Epoch 1944/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1217 - acc: 0.9688Epoch 01944: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1184 - acc: 0.9710 - val_loss: 1.6626 - val_acc: 0.6465\n",
      "Epoch 1945/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0711 - acc: 0.9864Epoch 01945: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.0723 - acc: 0.9861 - val_loss: 1.7432 - val_acc: 0.6111\n",
      "Epoch 1946/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1029 - acc: 0.9823Epoch 01946: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.0994 - acc: 0.9836 - val_loss: 1.6317 - val_acc: 0.6162\n",
      "Epoch 1947/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1271 - acc: 0.9674Epoch 01947: val_loss did not improve\n",
      "792/792 [==============================] - 1s 958us/step - loss: 0.1235 - acc: 0.9697 - val_loss: 1.6739 - val_acc: 0.6061\n",
      "Epoch 1948/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1228 - acc: 0.9688Epoch 01948: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1247 - acc: 0.9672 - val_loss: 1.6111 - val_acc: 0.6465\n",
      "Epoch 1949/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1071 - acc: 0.9688Epoch 01949: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1090 - acc: 0.9697 - val_loss: 1.6537 - val_acc: 0.6313\n",
      "Epoch 1950/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0937 - acc: 0.9796Epoch 01950: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.0905 - acc: 0.9811 - val_loss: 1.6453 - val_acc: 0.6263\n",
      "Epoch 1951/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1315 - acc: 0.9647Epoch 01951: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 0.1292 - acc: 0.9672 - val_loss: 1.6346 - val_acc: 0.6364\n",
      "Epoch 1952/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0839 - acc: 0.9810Epoch 01952: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 0.0905 - acc: 0.9773 - val_loss: 1.6367 - val_acc: 0.6515\n",
      "Epoch 1953/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0888 - acc: 0.9783Epoch 01953: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 0.0927 - acc: 0.9785 - val_loss: 1.7220 - val_acc: 0.6061\n",
      "Epoch 1954/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1042 - acc: 0.9742Epoch 01954: val_loss did not improve\n",
      "792/792 [==============================] - 1s 952us/step - loss: 0.1052 - acc: 0.9735 - val_loss: 1.6275 - val_acc: 0.6313\n",
      "Epoch 1955/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0964 - acc: 0.9810Epoch 01955: val_loss did not improve\n",
      "792/792 [==============================] - 1s 950us/step - loss: 0.1001 - acc: 0.9811 - val_loss: 1.6602 - val_acc: 0.6313\n",
      "Epoch 1956/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1088 - acc: 0.9688Epoch 01956: val_loss did not improve\n",
      "792/792 [==============================] - 1s 953us/step - loss: 0.1122 - acc: 0.9672 - val_loss: 1.6501 - val_acc: 0.6465\n",
      "Epoch 1957/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1138 - acc: 0.9647Epoch 01957: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1107 - acc: 0.9672 - val_loss: 1.6823 - val_acc: 0.6313\n",
      "Epoch 1958/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1466 - acc: 0.9647Epoch 01958: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1420 - acc: 0.9672 - val_loss: 1.6900 - val_acc: 0.6010\n",
      "Epoch 1959/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1024 - acc: 0.9810Epoch 01959: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1025 - acc: 0.9811 - val_loss: 1.7118 - val_acc: 0.6010\n",
      "Epoch 1960/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1266 - acc: 0.9633Epoch 01960: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1282 - acc: 0.9621 - val_loss: 1.6988 - val_acc: 0.6061\n",
      "Epoch 1961/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1019 - acc: 0.9728Epoch 01961: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1100 - acc: 0.9697 - val_loss: 1.6087 - val_acc: 0.6414\n",
      "Epoch 1962/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1197 - acc: 0.9755Epoch 01962: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 0.1214 - acc: 0.9735 - val_loss: 1.7053 - val_acc: 0.6263\n",
      "Epoch 1963/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0958 - acc: 0.9688Epoch 01963: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.0926 - acc: 0.9710 - val_loss: 1.6574 - val_acc: 0.6414\n",
      "Epoch 1964/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1186 - acc: 0.9660Epoch 01964: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 0.1157 - acc: 0.9672 - val_loss: 1.7086 - val_acc: 0.6061\n",
      "Epoch 1965/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0934 - acc: 0.9755Epoch 01965: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 0.0945 - acc: 0.9760 - val_loss: 1.6853 - val_acc: 0.6263\n",
      "Epoch 1966/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1090 - acc: 0.9755Epoch 01966: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 0.1183 - acc: 0.9697 - val_loss: 1.7185 - val_acc: 0.6162\n",
      "Epoch 1967/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0976 - acc: 0.9810Epoch 01967: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.0992 - acc: 0.9811 - val_loss: 1.6440 - val_acc: 0.6465\n",
      "Epoch 1968/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1211 - acc: 0.9647Epoch 01968: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1172 - acc: 0.9672 - val_loss: 1.6039 - val_acc: 0.6313\n",
      "Epoch 1969/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1092 - acc: 0.9728Epoch 01969: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1129 - acc: 0.9710 - val_loss: 1.6177 - val_acc: 0.6465\n",
      "Epoch 1970/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1212 - acc: 0.9688Epoch 01970: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1223 - acc: 0.9672 - val_loss: 1.6486 - val_acc: 0.6414\n",
      "Epoch 1971/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1490 - acc: 0.9565Epoch 01971: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 0.1453 - acc: 0.9571 - val_loss: 1.6540 - val_acc: 0.6465\n",
      "Epoch 1972/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1140 - acc: 0.9728Epoch 01972: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 0.1181 - acc: 0.9722 - val_loss: 1.6334 - val_acc: 0.6566\n",
      "Epoch 1973/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1043 - acc: 0.9755Epoch 01973: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1039 - acc: 0.9747 - val_loss: 1.6099 - val_acc: 0.6566\n",
      "Epoch 1974/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0928 - acc: 0.9755Epoch 01974: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.0931 - acc: 0.9773 - val_loss: 1.6590 - val_acc: 0.6010\n",
      "Epoch 1975/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1104 - acc: 0.9701Epoch 01975: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1133 - acc: 0.9697 - val_loss: 1.6033 - val_acc: 0.6263\n",
      "Epoch 1976/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1261 - acc: 0.9647Epoch 01976: val_loss did not improve\n",
      "792/792 [==============================] - 1s 957us/step - loss: 0.1211 - acc: 0.9672 - val_loss: 1.6937 - val_acc: 0.6111\n",
      "Epoch 1977/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1051 - acc: 0.9769Epoch 01977: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1060 - acc: 0.9760 - val_loss: 1.6606 - val_acc: 0.6212\n",
      "Epoch 1978/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1191 - acc: 0.9728Epoch 01978: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 0.1217 - acc: 0.9710 - val_loss: 1.6642 - val_acc: 0.6313\n",
      "Epoch 1979/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1243 - acc: 0.9755Epoch 01979: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1208 - acc: 0.9773 - val_loss: 1.6610 - val_acc: 0.6364\n",
      "Epoch 1980/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1449 - acc: 0.9592Epoch 01980: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.1440 - acc: 0.9596 - val_loss: 1.6444 - val_acc: 0.6263\n",
      "Epoch 1981/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1155 - acc: 0.9688Epoch 01981: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1165 - acc: 0.9659 - val_loss: 1.7369 - val_acc: 0.5960\n",
      "Epoch 1982/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1249 - acc: 0.9688Epoch 01982: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 0.1211 - acc: 0.9710 - val_loss: 1.6186 - val_acc: 0.6313\n",
      "Epoch 1983/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1224 - acc: 0.9674Epoch 01983: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.1189 - acc: 0.9697 - val_loss: 1.6319 - val_acc: 0.6111\n",
      "Epoch 1984/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0991 - acc: 0.9755Epoch 01984: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1032 - acc: 0.9735 - val_loss: 1.5951 - val_acc: 0.6263\n",
      "Epoch 1985/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0987 - acc: 0.9755Epoch 01985: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 0.1046 - acc: 0.9747 - val_loss: 1.7111 - val_acc: 0.5859\n",
      "Epoch 1986/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1087 - acc: 0.9755Epoch 01986: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1069 - acc: 0.9760 - val_loss: 1.6543 - val_acc: 0.6414\n",
      "Epoch 1987/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1094 - acc: 0.9728Epoch 01987: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 0.1066 - acc: 0.9735 - val_loss: 1.6496 - val_acc: 0.6414\n",
      "Epoch 1988/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0938 - acc: 0.9701Epoch 01988: val_loss did not improve\n",
      "792/792 [==============================] - 1s 954us/step - loss: 0.0914 - acc: 0.9710 - val_loss: 1.6883 - val_acc: 0.6263\n",
      "Epoch 1989/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1209 - acc: 0.9674Epoch 01989: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 0.1203 - acc: 0.9672 - val_loss: 1.6705 - val_acc: 0.6566\n",
      "Epoch 1990/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1025 - acc: 0.9742Epoch 01990: val_loss did not improve\n",
      "792/792 [==============================] - 1s 951us/step - loss: 0.1072 - acc: 0.9735 - val_loss: 1.6755 - val_acc: 0.6313\n",
      "Epoch 1991/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1077 - acc: 0.9688Epoch 01991: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.1065 - acc: 0.9710 - val_loss: 1.6269 - val_acc: 0.6414\n",
      "Epoch 1992/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0881 - acc: 0.9796Epoch 01992: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 0.0915 - acc: 0.9785 - val_loss: 1.6383 - val_acc: 0.6162\n",
      "Epoch 1993/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1013 - acc: 0.9728Epoch 01993: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 0.1027 - acc: 0.9735 - val_loss: 1.6276 - val_acc: 0.6465\n",
      "Epoch 1994/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0930 - acc: 0.9823Epoch 01994: val_loss did not improve\n",
      "792/792 [==============================] - 1s 956us/step - loss: 0.0900 - acc: 0.9836 - val_loss: 1.6375 - val_acc: 0.6515\n",
      "Epoch 1995/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1043 - acc: 0.9701Epoch 01995: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 0.1127 - acc: 0.9659 - val_loss: 1.6468 - val_acc: 0.6364\n",
      "Epoch 1996/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1132 - acc: 0.9715- ETA: 0s - loss: 0.0715 - accEpoch 01996: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 0.1117 - acc: 0.9722 - val_loss: 1.6230 - val_acc: 0.6465\n",
      "Epoch 1997/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1167 - acc: 0.9701Epoch 01997: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 0.1154 - acc: 0.9722 - val_loss: 1.6320 - val_acc: 0.6414\n",
      "Epoch 1998/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0845 - acc: 0.9851Epoch 01998: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 0.0884 - acc: 0.9823 - val_loss: 1.6446 - val_acc: 0.6364\n",
      "Epoch 1999/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0966 - acc: 0.9769Epoch 01999: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 0.0956 - acc: 0.9785 - val_loss: 1.6630 - val_acc: 0.6414\n",
      "Epoch 2000/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1193 - acc: 0.9660Epoch 02000: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 0.1241 - acc: 0.9646 - val_loss: 1.6020 - val_acc: 0.6414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff6cad4c898>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of epochs to run\n",
    "epochs = 2000\n",
    "\n",
    "# Saving best model\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best1.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(train2_images, pd.get_dummies(y_train2).values, \n",
    "          validation_data=(val_images, pd.get_dummies(y_val).values),\n",
    "          epochs=epochs, batch_size=32, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990/990 [==============================] - 0s 339us/step\n",
      "Accuracy Score on training data: 0.916161616162\n",
      "990/990 [==============================] - 0s 318us/step\n",
      "Log Loss Score on training data: 0.351756336024\n",
      "594/594 [==============================] - 0s 333us/step\n",
      "Log loss score on testing data: 1.79\n"
     ]
    }
   ],
   "source": [
    "# loading best model\n",
    "model.load_weights('weights.best1.hdf5')\n",
    "\n",
    "predictions = model.predict_classes(train_images)\n",
    "\n",
    "accuracy_scores[4] = accuracy_score(pd.get_dummies(y_train).columns[predictions],y_train)\n",
    "print(\"Accuracy Score on training data:\", accuracy_scores[4])\n",
    "\n",
    "predictions = model.predict_proba(train_images)\n",
    "\n",
    "log_loss_train_scores[4]= log_loss(pd.get_dummies(y_train).values,predictions)\n",
    "print(\"Log Loss Score on training data:\", log_loss_train_scores[4])\n",
    "\n",
    "predictions= model.predict_proba([test_images])\n",
    "\n",
    "\n",
    "submission = pd.DataFrame(predictions,index=X_test.index,columns=pd.get_dummies(y_val).columns)\n",
    "\n",
    "submission.to_csv(r'submission_CNN1.csv')\n",
    "\n",
    "log_loss_CNN1 = 1.79\n",
    "print(\"Log loss score on testing data:\", log_loss_CNN1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing results for the benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>log loss train</th>\n",
       "      <th>log loss test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>96.262626</td>\n",
       "      <td>0.065841</td>\n",
       "      <td>14.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada</th>\n",
       "      <td>61.616162</td>\n",
       "      <td>2.089994</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.967854</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>98.888889</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN1</th>\n",
       "      <td>91.616162</td>\n",
       "      <td>0.351756</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  log loss train  log loss test\n",
       "DT     96.262626        0.065841          14.75\n",
       "Ada    61.616162        2.089994           2.50\n",
       "SVC   100.000000        1.967854           1.99\n",
       "KNN    98.888889        0.047699           0.14\n",
       "CNN1   91.616162        0.351756           1.79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving the log-loss metric in the new array \n",
    "log_loss_test_scores[0] = log_loss_DT\n",
    "log_loss_test_scores[1] = log_loss_Ada\n",
    "log_loss_test_scores[2] = log_loss_SVC\n",
    "log_loss_test_scores[3] = log_loss_KNN\n",
    "log_loss_test_scores[4] = log_loss_CNN1\n",
    "metrics = np.vstack([accuracy_scores*100,log_loss_train_scores,log_loss_test_scores]).T\n",
    "result_df = pd.DataFrame(metrics,index=[\"DT\",\"Ada\",\"SVC\",\"KNN\",\"CNN1\"],columns=[\"accuracy\",\"log loss train\",\"log loss test\"])\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6caad5da0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(result_df.index,result_df[\"accuracy\"],width=.4);\n",
    "plt.xlabel('Algorithm',size=13);\n",
    "plt.ylabel('Accuracy on training data',size=13);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff70c576128>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8));\n",
    "plt.bar(result_df.index,result_df[\"log loss train\"],align='edge',width=-.4,label='training loss');\n",
    "plt.bar(result_df.index,result_df[\"log loss test\"],align='edge',width=.4,label='testing loss');\n",
    "plt.xlabel('Algorithm',size=13);\n",
    "plt.ylabel('Log Loss',size=13);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "## Convolutional Neural Network using both tabular and image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 16)      80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 99)                101475    \n",
      "=================================================================\n",
      "Total params: 111,891\n",
      "Trainable params: 111,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 200)               38600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 200)               0         \n",
      "=================================================================\n",
      "Total params: 39,400\n",
      "Trainable params: 39,000\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_2 (Merge)              (None, 299)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 200)               60000     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 99)                19899     \n",
      "=================================================================\n",
      "Total params: 231,190\n",
      "Trainable params: 230,790\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "model1.add(Conv2D(filters=16, kernel_size=2,strides=2, padding='same', activation='tanh', \n",
    "                        input_shape=train2_images.shape[1:]))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Conv2D(filters=32, kernel_size=2,strides=2, padding='same', activation='tanh'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Conv2D(filters=64, kernel_size=2,strides=2, padding='same', activation='tanh'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model1.add(Dropout(0.5))\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "model1.add(Flatten())\n",
    "#model.add(Dropout(0.5))\n",
    "model1.add(Dense(99, activation='tanh'))\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(200, input_shape = X_train2.shape[1:]))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Activation('tanh'))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([model1,model2],mode='concat',concat_axis=1))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(99, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=.001, rho=0.9, epsilon=1e-08, decay=0)\n",
    "#RMSprop?\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 792 samples, validate on 198 samples\n",
      "Epoch 1/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5605 - acc: 0.0408Epoch 00001: val_loss improved from inf to 4.19098, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 2ms/step - loss: 4.5363 - acc: 0.0455 - val_loss: 4.1910 - val_acc: 0.1313\n",
      "Epoch 2/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4556 - acc: 0.2147Epoch 00002: val_loss improved from 4.19098 to 3.83167, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4317 - acc: 0.2134 - val_loss: 3.8317 - val_acc: 0.3333\n",
      "Epoch 3/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8559 - acc: 0.3736Epoch 00003: val_loss improved from 3.83167 to 3.45173, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8595 - acc: 0.3687 - val_loss: 3.4517 - val_acc: 0.6111\n",
      "Epoch 4/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3266 - acc: 0.5503Epoch 00004: val_loss improved from 3.45173 to 3.04574, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3163 - acc: 0.5518 - val_loss: 3.0457 - val_acc: 0.7879\n",
      "Epoch 5/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9048 - acc: 0.6549Epoch 00005: val_loss improved from 3.04574 to 2.62774, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9043 - acc: 0.6553 - val_loss: 2.6277 - val_acc: 0.8788\n",
      "Epoch 6/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6468 - acc: 0.7052Epoch 00006: val_loss improved from 2.62774 to 2.21890, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6486 - acc: 0.7020 - val_loss: 2.2189 - val_acc: 0.9343\n",
      "Epoch 7/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3093 - acc: 0.8315Epoch 00007: val_loss improved from 2.21890 to 1.80957, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3088 - acc: 0.8295 - val_loss: 1.8096 - val_acc: 0.9697\n",
      "Epoch 8/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1676 - acc: 0.8247Epoch 00008: val_loss improved from 1.80957 to 1.45185, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1700 - acc: 0.8245 - val_loss: 1.4518 - val_acc: 0.9848\n",
      "Epoch 9/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.9247 - acc: 0.8872Epoch 00009: val_loss improved from 1.45185 to 1.14405, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.9298 - acc: 0.8864 - val_loss: 1.1441 - val_acc: 0.9798\n",
      "Epoch 10/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.7812 - acc: 0.9171Epoch 00010: val_loss improved from 1.14405 to 0.88996, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.7749 - acc: 0.9167 - val_loss: 0.8900 - val_acc: 0.9798\n",
      "Epoch 11/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.6470 - acc: 0.9280Epoch 00011: val_loss improved from 0.88996 to 0.67411, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.6440 - acc: 0.9293 - val_loss: 0.6741 - val_acc: 0.9949\n",
      "Epoch 12/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.5439 - acc: 0.9524Epoch 00012: val_loss improved from 0.67411 to 0.52229, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.5426 - acc: 0.9508 - val_loss: 0.5223 - val_acc: 0.9798\n",
      "Epoch 13/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.4888 - acc: 0.9511Epoch 00013: val_loss improved from 0.52229 to 0.39870, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.4898 - acc: 0.9495 - val_loss: 0.3987 - val_acc: 0.9899\n",
      "Epoch 14/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3845 - acc: 0.9728Epoch 00014: val_loss improved from 0.39870 to 0.31131, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.3855 - acc: 0.9710 - val_loss: 0.3113 - val_acc: 1.0000\n",
      "Epoch 15/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3567 - acc: 0.9728Epoch 00015: val_loss improved from 0.31131 to 0.24921, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.3499 - acc: 0.9722 - val_loss: 0.2492 - val_acc: 0.9899\n",
      "Epoch 16/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.3143 - acc: 0.9715Epoch 00016: val_loss improved from 0.24921 to 0.22269, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.3167 - acc: 0.9710 - val_loss: 0.2227 - val_acc: 0.9798\n",
      "Epoch 17/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2740 - acc: 0.9796Epoch 00017: val_loss improved from 0.22269 to 0.17372, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.2729 - acc: 0.9811 - val_loss: 0.1737 - val_acc: 0.9949\n",
      "Epoch 18/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.2389 - acc: 0.9796Epoch 00018: val_loss improved from 0.17372 to 0.15887, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.2391 - acc: 0.9798 - val_loss: 0.1589 - val_acc: 0.9899\n",
      "Epoch 19/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1963 - acc: 0.9851Epoch 00019: val_loss improved from 0.15887 to 0.14072, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.2022 - acc: 0.9836 - val_loss: 0.1407 - val_acc: 0.9899\n",
      "Epoch 20/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1851 - acc: 0.9864Epoch 00020: val_loss improved from 0.14072 to 0.12283, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.1865 - acc: 0.9861 - val_loss: 0.1228 - val_acc: 1.0000\n",
      "Epoch 21/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1707 - acc: 0.9837Epoch 00021: val_loss improved from 0.12283 to 0.11005, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.1747 - acc: 0.9836 - val_loss: 0.1101 - val_acc: 1.0000\n",
      "Epoch 22/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1484 - acc: 0.9837Epoch 00022: val_loss improved from 0.11005 to 0.09923, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.1454 - acc: 0.9848 - val_loss: 0.0992 - val_acc: 1.0000\n",
      "Epoch 23/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1346 - acc: 0.9905Epoch 00023: val_loss improved from 0.09923 to 0.09825, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.1306 - acc: 0.9912 - val_loss: 0.0982 - val_acc: 0.9949\n",
      "Epoch 24/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1042 - acc: 0.9932Epoch 00024: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 0.1064 - acc: 0.9924 - val_loss: 0.1005 - val_acc: 0.9949\n",
      "Epoch 25/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1003 - acc: 0.9918Epoch 00025: val_loss improved from 0.09825 to 0.08944, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.1003 - acc: 0.9912 - val_loss: 0.0894 - val_acc: 0.9949\n",
      "Epoch 26/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0878 - acc: 0.9973Epoch 00026: val_loss improved from 0.08944 to 0.08686, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0858 - acc: 0.9975 - val_loss: 0.0869 - val_acc: 0.9949\n",
      "Epoch 27/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.1000 - acc: 0.9918Epoch 00027: val_loss improved from 0.08686 to 0.06853, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0973 - acc: 0.9924 - val_loss: 0.0685 - val_acc: 0.9899\n",
      "Epoch 28/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0831 - acc: 0.9959Epoch 00028: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 0.0817 - acc: 0.9962 - val_loss: 0.0845 - val_acc: 0.9747\n",
      "Epoch 29/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0658 - acc: 0.9986Epoch 00029: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 0.0646 - acc: 0.9987 - val_loss: 0.0708 - val_acc: 0.9949\n",
      "Epoch 30/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0696 - acc: 0.9918Epoch 00030: val_loss improved from 0.06853 to 0.05255, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0702 - acc: 0.9924 - val_loss: 0.0525 - val_acc: 0.9899\n",
      "Epoch 31/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0599 - acc: 0.9973Epoch 00031: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 0.0605 - acc: 0.9975 - val_loss: 0.0569 - val_acc: 0.9949\n",
      "Epoch 32/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0505 - acc: 0.9986Epoch 00032: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0504 - acc: 0.9987 - val_loss: 0.0650 - val_acc: 0.9899\n",
      "Epoch 33/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0486 - acc: 0.9986Epoch 00033: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 0.0490 - acc: 0.9987 - val_loss: 0.0562 - val_acc: 0.9949\n",
      "Epoch 34/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0495 - acc: 0.9946Epoch 00034: val_loss improved from 0.05255 to 0.04611, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0511 - acc: 0.9949 - val_loss: 0.0461 - val_acc: 0.9949\n",
      "Epoch 35/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0444 - acc: 0.9986Epoch 00035: val_loss improved from 0.04611 to 0.04257, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0432 - acc: 0.9987 - val_loss: 0.0426 - val_acc: 1.0000\n",
      "Epoch 36/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0390 - acc: 1.0000Epoch 00036: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 0.0391 - acc: 1.0000 - val_loss: 0.0492 - val_acc: 0.9899\n",
      "Epoch 37/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0501 - acc: 0.9946Epoch 00037: val_loss improved from 0.04257 to 0.04241, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0485 - acc: 0.9949 - val_loss: 0.0424 - val_acc: 1.0000\n",
      "Epoch 38/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0340 - acc: 0.9973Epoch 00038: val_loss improved from 0.04241 to 0.03519, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0333 - acc: 0.9975 - val_loss: 0.0352 - val_acc: 1.0000\n",
      "Epoch 39/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0277 - acc: 1.0000Epoch 00039: val_loss improved from 0.03519 to 0.03429, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 1.0000\n",
      "Epoch 40/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0322 - acc: 1.0000Epoch 00040: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 0.9949\n",
      "Epoch 41/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0307 - acc: 0.9959Epoch 00041: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 0.0301 - acc: 0.9962 - val_loss: 0.0349 - val_acc: 0.9949\n",
      "Epoch 42/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0293 - acc: 0.9986Epoch 00042: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 0.0303 - acc: 0.9975 - val_loss: 0.0370 - val_acc: 0.9949\n",
      "Epoch 43/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0287 - acc: 0.9986Epoch 00043: val_loss improved from 0.03429 to 0.03318, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0279 - acc: 0.9987 - val_loss: 0.0332 - val_acc: 0.9949\n",
      "Epoch 44/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0237 - acc: 0.9986Epoch 00044: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 0.0236 - acc: 0.9987 - val_loss: 0.0403 - val_acc: 0.9899\n",
      "Epoch 45/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0279 - acc: 0.9986Epoch 00045: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0273 - acc: 0.9987 - val_loss: 0.0488 - val_acc: 0.9899\n",
      "Epoch 46/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0263 - acc: 0.9973Epoch 00046: val_loss improved from 0.03318 to 0.02803, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0278 - acc: 0.9975 - val_loss: 0.0280 - val_acc: 1.0000\n",
      "Epoch 47/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0200 - acc: 0.9973Epoch 00047: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0201 - acc: 0.9975 - val_loss: 0.0326 - val_acc: 0.9949\n",
      "Epoch 48/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0167 - acc: 1.0000Epoch 00048: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9949\n",
      "Epoch 49/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0163 - acc: 1.0000Epoch 00049: val_loss improved from 0.02803 to 0.02586, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0259 - val_acc: 0.9949\n",
      "Epoch 50/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0167 - acc: 1.0000Epoch 00050: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 0.9949\n",
      "Epoch 51/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0172 - acc: 0.9973Epoch 00051: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0168 - acc: 0.9975 - val_loss: 0.0339 - val_acc: 0.9949\n",
      "Epoch 52/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0151 - acc: 1.0000Epoch 00052: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0174 - acc: 0.9987 - val_loss: 0.0451 - val_acc: 0.9899\n",
      "Epoch 53/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0165 - acc: 0.9973Epoch 00053: val_loss improved from 0.02586 to 0.02443, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0173 - acc: 0.9975 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 54/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0157 - acc: 1.0000Epoch 00054: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 0.9949\n",
      "Epoch 55/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0172 - acc: 0.9986Epoch 00055: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0171 - acc: 0.9987 - val_loss: 0.0421 - val_acc: 0.9899\n",
      "Epoch 56/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0131 - acc: 0.9986Epoch 00056: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 0.0128 - acc: 0.9987 - val_loss: 0.0338 - val_acc: 1.0000\n",
      "Epoch 57/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0165 - acc: 0.9959Epoch 00057: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 0.0161 - acc: 0.9962 - val_loss: 0.0385 - val_acc: 0.9949\n",
      "Epoch 58/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0105 - acc: 0.9986Epoch 00058: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0128 - acc: 0.9975 - val_loss: 0.0269 - val_acc: 0.9949\n",
      "Epoch 59/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0145 - acc: 0.9986Epoch 00059: val_loss improved from 0.02443 to 0.01790, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.9987 - val_loss: 0.0179 - val_acc: 0.9949\n",
      "Epoch 60/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0163 - acc: 0.9973Epoch 00060: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 0.0164 - acc: 0.9975 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 61/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0092 - acc: 1.0000Epoch 00061: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9949\n",
      "Epoch 62/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0104 - acc: 0.9986Epoch 00062: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 0.0103 - acc: 0.9987 - val_loss: 0.0258 - val_acc: 0.9949\n",
      "Epoch 63/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0105 - acc: 1.0000Epoch 00063: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0485 - val_acc: 0.9899\n",
      "Epoch 64/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0116 - acc: 1.0000Epoch 00064: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 0.9949\n",
      "Epoch 65/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0099 - acc: 1.0000Epoch 00065: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 0.9949\n",
      "Epoch 66/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0082 - acc: 1.0000Epoch 00066: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 0.9899\n",
      "Epoch 67/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0075 - acc: 1.0000Epoch 00067: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0291 - val_acc: 0.9949\n",
      "Epoch 68/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0065 - acc: 1.0000Epoch 00068: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 0.9899\n",
      "Epoch 69/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0062 - acc: 1.0000Epoch 00069: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 0.9949\n",
      "Epoch 70/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0058 - acc: 1.0000Epoch 00070: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9899\n",
      "Epoch 71/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0073 - acc: 0.9986Epoch 00071: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0251 - val_acc: 0.9899\n",
      "Epoch 72/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0050 - acc: 1.0000Epoch 00072: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9949\n",
      "Epoch 73/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0102 - acc: 0.9986Epoch 00073: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 0.0102 - acc: 0.9987 - val_loss: 0.0353 - val_acc: 0.9949\n",
      "Epoch 74/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0049 - acc: 0.9986Epoch 00074: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 75/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0082 - acc: 0.9986Epoch 00075: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.0236 - val_acc: 0.9949\n",
      "Epoch 76/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0052 - acc: 1.0000Epoch 00076: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 0.9899\n",
      "Epoch 77/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0042 - acc: 1.0000Epoch 00077: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 0.9899\n",
      "Epoch 78/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0037 - acc: 1.0000Epoch 00078: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 0.9899\n",
      "Epoch 79/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0037 - acc: 1.0000Epoch 00079: val_loss improved from 0.01790 to 0.01672, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9949\n",
      "Epoch 80/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0036 - acc: 1.0000Epoch 00080: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 0.9949\n",
      "Epoch 81/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0033 - acc: 1.0000Epoch 00081: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 0.9899\n",
      "Epoch 82/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0080 - acc: 0.9986Epoch 00082: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0205 - val_acc: 0.9949\n",
      "Epoch 83/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0031 - acc: 1.0000Epoch 00083: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 0.9899\n",
      "Epoch 84/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0036 - acc: 1.0000Epoch 00084: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9899\n",
      "Epoch 85/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0043 - acc: 1.0000Epoch 00085: val_loss improved from 0.01672 to 0.01335, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9949\n",
      "Epoch 86/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0031 - acc: 1.0000Epoch 00086: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9899\n",
      "Epoch 87/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0051 - acc: 1.0000Epoch 00087: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 0.9949\n",
      "Epoch 88/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0038 - acc: 0.9986Epoch 00088: val_loss improved from 0.01335 to 0.01145, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0115 - val_acc: 0.9949\n",
      "Epoch 89/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0033 - acc: 1.0000Epoch 00089: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9899\n",
      "Epoch 90/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0031 - acc: 1.0000Epoch 00090: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 0.9949\n",
      "Epoch 91/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0026 - acc: 1.0000Epoch 00091: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 0.9949\n",
      "Epoch 92/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0041 - acc: 0.9986Epoch 00092: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0218 - val_acc: 0.9949\n",
      "Epoch 93/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0025 - acc: 1.0000Epoch 00093: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 0.9949\n",
      "Epoch 94/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0027 - acc: 1.0000   - ETA: 0s - loss: 0.0018 - accEpoch 00094: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9949\n",
      "Epoch 95/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0024 - acc: 1.0000Epoch 00095: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9949\n",
      "Epoch 96/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0036 - acc: 1.0000Epoch 00096: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9949\n",
      "Epoch 97/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0018 - acc: 1.0000Epoch 00097: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9899\n",
      "Epoch 98/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 1.0000Epoch 00098: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9949\n",
      "Epoch 99/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0028 - acc: 1.0000Epoch 00099: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0267 - val_acc: 0.9899\n",
      "Epoch 100/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0035 - acc: 1.0000Epoch 00100: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9949\n",
      "Epoch 101/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0016 - acc: 1.0000Epoch 00101: val_loss improved from 0.01145 to 0.01134, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 102/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0016 - acc: 1.0000Epoch 00102: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9949\n",
      "Epoch 103/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0022 - acc: 1.0000Epoch 00103: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9949\n",
      "Epoch 104/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0020 - acc: 1.0000Epoch 00104: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 105/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0020 - acc: 1.0000Epoch 00105: val_loss improved from 0.01134 to 0.01097, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 106/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0025 - acc: 1.0000Epoch 00106: val_loss improved from 0.01097 to 0.01049, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 107/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 1.0000Epoch 00107: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 108/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 1.0000Epoch 00108: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 0.9949\n",
      "Epoch 109/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0024 - acc: 1.0000Epoch 00109: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 0.9949\n",
      "Epoch 110/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0013 - acc: 1.0000Epoch 00110: val_loss improved from 0.01049 to 0.00785, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 111/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0019 - acc: 1.0000Epoch 00111: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 112/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0026 - acc: 1.0000Epoch 00112: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9949\n",
      "Epoch 113/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0033 - acc: 0.9986Epoch 00113: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.9987 - val_loss: 0.0127 - val_acc: 0.9899\n",
      "Epoch 114/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0010 - acc: 1.0000   Epoch 00114: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 115/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0016 - acc: 1.0000  Epoch 00115: val_loss improved from 0.00785 to 0.00644, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 116/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0027 - acc: 1.0000Epoch 00116: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9949\n",
      "Epoch 117/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0028 - acc: 1.0000Epoch 00117: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 0.9798\n",
      "Epoch 118/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0019 - acc: 1.0000Epoch 00118: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0267 - val_acc: 0.9899\n",
      "Epoch 119/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0014 - acc: 1.0000Epoch 00119: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 0.9899\n",
      "Epoch 120/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0014 - acc: 1.0000Epoch 00120: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 0.9899\n",
      "Epoch 121/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 1.0000Epoch 00121: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 0.9949\n",
      "Epoch 122/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.5744e-04 - acc: 1.0000Epoch 00122: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.1230e-04 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 0.9949\n",
      "Epoch 123/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0014 - acc: 1.0000Epoch 00123: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9949\n",
      "Epoch 124/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0018 - acc: 1.0000Epoch 00124: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9949\n",
      "Epoch 125/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0024 - acc: 1.0000Epoch 00125: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9949\n",
      "Epoch 126/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0022 - acc: 1.0000 Epoch 00126: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9899\n",
      "Epoch 127/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0018 - acc: 1.0000Epoch 00127: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9949\n",
      "Epoch 128/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0033 - acc: 0.9986Epoch 00128: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 0.0032 - acc: 0.9987 - val_loss: 0.0149 - val_acc: 0.9949\n",
      "Epoch 129/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.6270e-04 - acc: 1.0000Epoch 00129: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9949\n",
      "Epoch 130/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.6697e-04 - acc: 1.0000Epoch 00130: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.9923e-04 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 0.9949\n",
      "Epoch 131/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.2229e-04 - acc: 1.0000Epoch 00131: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 9.3424e-04 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 132/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0027 - acc: 0.9986Epoch 00132: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 0.0026 - acc: 0.9987 - val_loss: 0.0256 - val_acc: 0.9899\n",
      "Epoch 133/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2457e-04 - acc: 1.0000Epoch 00133: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 9.1022e-04 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 0.9899\n",
      "Epoch 134/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 1.0000Epoch 00134: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9899\n",
      "Epoch 135/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1053e-04 - acc: 1.0000Epoch 00135: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.8956e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9949\n",
      "Epoch 136/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 1.0000Epoch 00136: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 0.9949\n",
      "Epoch 137/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0015 - acc: 1.0000Epoch 00137: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9949\n",
      "Epoch 138/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0014 - acc: 1.0000Epoch 00138: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9949\n",
      "Epoch 139/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 1.0000Epoch 00139: val_loss improved from 0.00644 to 0.00629, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 140/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0010 - acc: 1.0000 Epoch 00140: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9949\n",
      "Epoch 141/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 1.0000Epoch 00141: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 142/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.5165e-04 - acc: 1.0000Epoch 00142: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.2268e-04 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9949\n",
      "Epoch 143/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0016 - acc: 1.0000    Epoch 00143: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 144/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2367e-04 - acc: 1.0000Epoch 00144: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.0875e-04 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9949\n",
      "Epoch 145/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5388e-04 - acc: 1.0000Epoch 00145: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4933e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9949\n",
      "Epoch 146/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.2117e-04 - acc: 1.0000Epoch 00146: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.5878e-04 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 0.9949\n",
      "Epoch 147/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 1.0000   Epoch 00147: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9949\n",
      "Epoch 148/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2120e-04 - acc: 1.0000Epoch 00148: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1004e-04 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 0.9949\n",
      "Epoch 149/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0019 - acc: 1.0000Epoch 00149: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9949\n",
      "Epoch 150/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0874e-04 - acc: 1.0000Epoch 00150: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.0023e-04 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 151/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5042e-04 - acc: 1.0000Epoch 00151: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.0992e-04 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9949\n",
      "Epoch 152/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 1.0000Epoch 00152: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9949\n",
      "Epoch 153/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.3398e-04 - acc: 1.0000Epoch 00153: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.8844e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9949\n",
      "Epoch 154/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.7108e-04 - acc: 1.0000Epoch 00154: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.4840e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9949\n",
      "Epoch 155/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9620e-04 - acc: 1.0000Epoch 00155: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1251e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9949\n",
      "Epoch 156/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0019 - acc: 1.0000Epoch 00156: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9949\n",
      "Epoch 157/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0013 - acc: 1.0000Epoch 00157: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9949\n",
      "Epoch 158/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9579e-04 - acc: 1.0000Epoch 00158: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 7.5963e-04 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9949\n",
      "Epoch 159/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5353e-04 - acc: 1.0000Epoch 00159: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.7727e-04 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 0.9899\n",
      "Epoch 160/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 1.0000Epoch 00160: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9949\n",
      "Epoch 161/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2725e-04 - acc: 1.0000Epoch 00161: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4691e-04 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9949\n",
      "Epoch 162/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.2918e-04 - acc: 1.0000Epoch 00162: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.0390e-04 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9949\n",
      "Epoch 163/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3019e-04 - acc: 1.0000Epoch 00163: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 164/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.2838e-04 - acc: 1.0000Epoch 00164: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.9787e-04 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 165/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4727e-04 - acc: 1.0000Epoch 00165: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.3509e-04 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9899\n",
      "Epoch 166/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.4461e-04 - acc: 1.0000Epoch 00166: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1545e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9949\n",
      "Epoch 167/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7290e-04 - acc: 1.0000Epoch 00167: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4933e-04 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9949\n",
      "Epoch 168/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1432e-04 - acc: 1.0000Epoch 00168: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3397e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9899\n",
      "Epoch 169/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6018e-04 - acc: 1.0000Epoch 00169: val_loss improved from 0.00629 to 0.00522, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 170/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0010 - acc: 1.0000    Epoch 00170: val_loss improved from 0.00522 to 0.00380, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.6596e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 171/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8904e-04 - acc: 1.0000Epoch 00171: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 7.5310e-04 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 172/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0013 - acc: 1.0000Epoch 00172: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9949\n",
      "Epoch 173/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0011 - acc: 1.0000Epoch 00173: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9949\n",
      "Epoch 174/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0497e-04 - acc: 1.0000Epoch 00174: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8733e-04 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9949\n",
      "Epoch 175/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3489e-04 - acc: 1.0000Epoch 00175: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4934e-04 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9949\n",
      "Epoch 176/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0469e-04 - acc: 1.0000Epoch 00176: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 5.0830e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 0.9949\n",
      "Epoch 177/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0016 - acc: 0.9986Epoch 00177: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 0.0016 - acc: 0.9987 - val_loss: 0.0185 - val_acc: 0.9848\n",
      "Epoch 178/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2818e-04 - acc: 1.0000Epoch 00178: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.5094e-04 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 0.9949\n",
      "Epoch 179/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2721e-04 - acc: 1.0000Epoch 00179: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.8035e-04 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9949\n",
      "Epoch 180/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4450e-04 - acc: 1.0000Epoch 00180: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4208e-04 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 0.9949\n",
      "Epoch 181/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9764e-04 - acc: 1.0000Epoch 00181: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6703e-04 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9949\n",
      "Epoch 182/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0027e-04 - acc: 1.0000Epoch 00182: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 5.3594e-04 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9949\n",
      "Epoch 183/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0475e-04 - acc: 1.0000Epoch 00183: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 2.9349e-04 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 0.9899\n",
      "Epoch 184/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0011 - acc: 1.0000Epoch 00184: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 0.9899\n",
      "Epoch 185/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6701e-04 - acc: 1.0000Epoch 00185: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 2.5599e-04 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 0.9899\n",
      "Epoch 186/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8231e-04 - acc: 1.0000Epoch 00186: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 5.5860e-04 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 0.9899\n",
      "Epoch 187/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0010 - acc: 1.0000    Epoch 00187: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.7021e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9949\n",
      "Epoch 188/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3770e-04 - acc: 1.0000Epoch 00188: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 3.2599e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 0.9899\n",
      "Epoch 189/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4857e-04 - acc: 1.0000Epoch 00189: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 4.4111e-04 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 0.9899\n",
      "Epoch 190/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7276e-04 - acc: 1.0000Epoch 00190: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 3.5738e-04 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 0.9899\n",
      "Epoch 191/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6428e-04 - acc: 1.0000Epoch 00191: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 2.9676e-04 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9899\n",
      "Epoch 192/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7415e-04 - acc: 1.0000Epoch 00192: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.6629e-04 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 0.9949\n",
      "Epoch 193/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0010 - acc: 1.0000    Epoch 00193: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.7883e-04 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 0.9899\n",
      "Epoch 194/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6011e-04 - acc: 1.0000Epoch 00194: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4360e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9949\n",
      "Epoch 195/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9948e-04 - acc: 1.0000Epoch 00195: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 9.9018e-04 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 0.9949\n",
      "Epoch 196/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.8539e-04 - acc: 1.0000Epoch 00196: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.2868e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9949\n",
      "Epoch 197/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2850e-04 - acc: 1.0000Epoch 00197: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9800e-04 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9949\n",
      "Epoch 198/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5752e-04 - acc: 1.0000Epoch 00198: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 4.4913e-04 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 0.9949\n",
      "Epoch 199/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0122e-04 - acc: 1.0000Epoch 00199: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.2234e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9949\n",
      "Epoch 200/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9152e-04 - acc: 1.0000Epoch 00200: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 3.8876e-04 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 0.9949\n",
      "Epoch 201/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8185e-04 - acc: 1.0000Epoch 00201: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 4.1572e-04 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9899\n",
      "Epoch 202/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0010 - acc: 1.0000Epoch 00202: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.9311e-04 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 0.9899\n",
      "Epoch 203/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0011 - acc: 1.0000Epoch 00203: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 0.9899\n",
      "Epoch 204/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0410e-04 - acc: 1.0000Epoch 00204: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.8868e-04 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 0.9899\n",
      "Epoch 205/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6381e-04 - acc: 1.0000Epoch 00205: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4640e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 0.9949\n",
      "Epoch 206/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8956e-04 - acc: 1.0000Epoch 00206: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3634e-04 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 0.9899\n",
      "Epoch 207/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9984e-04 - acc: 1.0000Epoch 00207: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.2318e-04 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9899\n",
      "Epoch 208/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4850e-04 - acc: 1.0000Epoch 00208: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2996e-04 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9949\n",
      "Epoch 209/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0015 - acc: 0.9986Epoch 00209: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.9987 - val_loss: 0.0096 - val_acc: 0.9949\n",
      "Epoch 210/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0880e-04 - acc: 1.0000Epoch 00210: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9564e-04 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 211/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6302e-04 - acc: 1.0000Epoch 00211: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5457e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9949\n",
      "Epoch 212/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0890e-04 - acc: 1.0000Epoch 00212: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.8399e-04 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 0.9949\n",
      "Epoch 213/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4500e-04 - acc: 1.0000Epoch 00213: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4720e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 214/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5254e-04 - acc: 1.0000Epoch 00214: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4766e-04 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 0.9949\n",
      "Epoch 215/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 1.0000Epoch 00215: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9899\n",
      "Epoch 216/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6539e-04 - acc: 1.0000Epoch 00216: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4613e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9949\n",
      "Epoch 217/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1709e-04 - acc: 1.0000Epoch 00217: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0341e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9949\n",
      "Epoch 218/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7443e-04 - acc: 1.0000Epoch 00218: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6552e-04 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 219/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5929e-04 - acc: 1.0000Epoch 00219: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5310e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9949\n",
      "Epoch 220/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.4439e-04 - acc: 1.0000Epoch 00220: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.2484e-04 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9949\n",
      "Epoch 221/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7787e-04 - acc: 1.0000Epoch 00221: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7775e-04 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 222/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7573e-04 - acc: 1.0000Epoch 00222: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.7471e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 223/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0961e-04 - acc: 1.0000Epoch 00223: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8292e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 224/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2693e-04 - acc: 1.0000Epoch 00224: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4917e-04 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 225/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1660e-04 - acc: 1.0000Epoch 00225: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9917e-04 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9949\n",
      "Epoch 226/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2189e-04 - acc: 1.0000Epoch 00226: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0243e-04 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 0.9949\n",
      "Epoch 227/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1894e-04 - acc: 1.0000Epoch 00227: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8729e-04 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 228/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5632e-04 - acc: 1.0000Epoch 00228: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.0835e-04 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 229/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8181e-04 - acc: 1.0000Epoch 00229: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.6450e-04 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 230/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6501e-04 - acc: 1.0000Epoch 00230: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.2440e-04 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9949\n",
      "Epoch 231/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6953e-04 - acc: 1.0000Epoch 00231: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6453e-04 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9899\n",
      "Epoch 232/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6455e-04 - acc: 1.0000Epoch 00232: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6786e-04 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9949\n",
      "Epoch 233/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9352e-04 - acc: 1.0000Epoch 00233: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.8986e-04 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 234/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5797e-04 - acc: 1.0000Epoch 00234: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 7.0079e-04 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9949\n",
      "Epoch 235/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.2582e-04 - acc: 1.0000Epoch 00235: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.6589e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 236/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4467e-04 - acc: 1.0000Epoch 00236: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5016e-04 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9949\n",
      "Epoch 237/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.5483e-04 - acc: 1.0000Epoch 00237: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 0.0026 - acc: 0.9987 - val_loss: 0.0105 - val_acc: 0.9949\n",
      "Epoch 238/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1132e-04 - acc: 1.0000Epoch 00238: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9867e-04 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 0.9899\n",
      "Epoch 239/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 0.9986Epoch 00239: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.9987 - val_loss: 0.0127 - val_acc: 0.9949\n",
      "Epoch 240/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2188e-04 - acc: 1.0000Epoch 00240: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0535e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9949\n",
      "Epoch 241/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5206e-04 - acc: 1.0000Epoch 00241: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5851e-04 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9949\n",
      "Epoch 242/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1148e-04 - acc: 1.0000Epoch 00242: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0457e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9949\n",
      "Epoch 243/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1374e-04 - acc: 1.0000Epoch 00243: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1091e-04 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9949\n",
      "Epoch 244/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.2165e-04 - acc: 1.0000Epoch 00244: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.4611e-04 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9949\n",
      "Epoch 245/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9930e-04 - acc: 1.0000Epoch 00245: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.7935e-04 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 246/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1851e-04 - acc: 1.0000Epoch 00246: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1241e-04 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9899\n",
      "Epoch 247/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4862e-04 - acc: 1.0000Epoch 00247: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4778e-04 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9899\n",
      "Epoch 248/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0602e-04 - acc: 1.0000Epoch 00248: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8962e-04 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9949\n",
      "Epoch 249/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3894e-04 - acc: 1.0000Epoch 00249: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9678e-04 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9949\n",
      "Epoch 250/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9024e-04 - acc: 1.0000Epoch 00250: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9668e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9949\n",
      "Epoch 251/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0024 - acc: 0.9986   Epoch 00251: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.9987 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 252/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8093e-04 - acc: 1.0000Epoch 00252: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7405e-04 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 253/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0957e-04 - acc: 1.0000Epoch 00253: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2799e-04 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9949\n",
      "Epoch 254/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5047e-04 - acc: 1.0000Epoch 00254: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1711e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9949\n",
      "Epoch 255/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6511e-04 - acc: 1.0000Epoch 00255: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2981e-04 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9949\n",
      "Epoch 256/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6681e-04 - acc: 1.0000Epoch 00256: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5523e-04 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9949\n",
      "Epoch 257/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0919e-04 - acc: 1.0000Epoch 00257: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4593e-04 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 0.9949\n",
      "Epoch 258/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.6603e-04 - acc: 1.0000Epoch 00258: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.3669e-04 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9949\n",
      "Epoch 259/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0105e-04 - acc: 1.0000Epoch 00259: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0442e-04 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9949\n",
      "Epoch 260/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.0453e-04 - acc: 1.0000Epoch 00260: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.8179e-04 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9949\n",
      "Epoch 261/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3601e-04 - acc: 1.0000Epoch 00261: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8941e-04 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 0.9949\n",
      "Epoch 262/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3388e-04 - acc: 1.0000Epoch 00262: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2752e-04 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9949\n",
      "Epoch 263/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4356e-04 - acc: 1.0000Epoch 00263: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6030e-04 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9949\n",
      "Epoch 264/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0024 - acc: 0.9986   Epoch 00264: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.9987 - val_loss: 0.0166 - val_acc: 0.9949\n",
      "Epoch 265/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0271e-04 - acc: 1.0000Epoch 00265: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8470e-04 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 0.9949\n",
      "Epoch 266/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0049e-04 - acc: 1.0000Epoch 00266: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.7502e-04 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9949\n",
      "Epoch 267/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5837e-04 - acc: 1.0000Epoch 00267: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4258e-04 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 0.9949\n",
      "Epoch 268/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1613e-04 - acc: 1.0000Epoch 00268: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8974e-04 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 0.9949\n",
      "Epoch 269/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0419e-04 - acc: 1.0000Epoch 00269: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9265e-04 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 0.9949\n",
      "Epoch 270/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8634e-04 - acc: 1.0000Epoch 00270: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.6157e-04 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 0.9949\n",
      "Epoch 271/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4437e-04 - acc: 1.0000Epoch 00271: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2588e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9949\n",
      "Epoch 272/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4414e-04 - acc: 1.0000Epoch 00272: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4799e-04 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 273/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8122e-04 - acc: 1.0000Epoch 00273: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7966e-04 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 274/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5101e-04 - acc: 1.0000Epoch 00274: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5799e-04 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9949\n",
      "Epoch 275/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9990e-04 - acc: 1.0000Epoch 00275: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8805e-04 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 276/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9159e-04 - acc: 1.0000Epoch 00276: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8513e-04 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 277/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3703e-04 - acc: 1.0000Epoch 00277: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2932e-04 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9949\n",
      "Epoch 278/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4073e-04 - acc: 1.0000Epoch 00278: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1438e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 0.9899\n",
      "Epoch 279/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.3147e-05 - acc: 1.0000Epoch 00279: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.2141e-05 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9949\n",
      "Epoch 280/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0697e-04 - acc: 1.0000Epoch 00280: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.0221e-04 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9949\n",
      "Epoch 281/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0825e-05 - acc: 1.0000Epoch 00281: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.7310e-05 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9949\n",
      "Epoch 282/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0457e-04 - acc: 1.0000Epoch 00282: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9738e-04 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9949\n",
      "Epoch 283/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9286e-04 - acc: 1.0000Epoch 00283: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7974e-04 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 0.9848\n",
      "Epoch 284/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5758e-04 - acc: 1.0000Epoch 00284: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 1.4899e-04 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9899\n",
      "Epoch 285/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.6382e-05 - acc: 1.0000Epoch 00285: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.3314e-05 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9899\n",
      "Epoch 286/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1492e-04 - acc: 1.0000Epoch 00286: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1437e-04 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9949\n",
      "Epoch 287/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2251e-04 - acc: 1.0000Epoch 00287: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1644e-04 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9949\n",
      "Epoch 288/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5993e-04 - acc: 1.0000Epoch 00288: val_loss improved from 0.00380 to 0.00370, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7745e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 289/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5011e-04 - acc: 1.0000Epoch 00289: val_loss improved from 0.00370 to 0.00336, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3374e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 290/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3209e-04 - acc: 1.0000Epoch 00290: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.0043e-04 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9949\n",
      "Epoch 291/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0374e-04 - acc: 1.0000Epoch 00291: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0014e-04 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9949\n",
      "Epoch 292/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5879e-04 - acc: 1.0000Epoch 00292: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4495e-04 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9949\n",
      "Epoch 293/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9632e-04 - acc: 1.0000Epoch 00293: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.7119e-04 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9949\n",
      "Epoch 294/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8408e-04 - acc: 1.0000Epoch 00294: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8652e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9949\n",
      "Epoch 295/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6550e-04 - acc: 1.0000Epoch 00295: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6513e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9949\n",
      "Epoch 296/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.2221e-04 - acc: 1.0000Epoch 00296: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5867e-04 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9949\n",
      "Epoch 297/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7404e-04 - acc: 1.0000Epoch 00297: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6425e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 298/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.7226e-05 - acc: 1.0000Epoch 00298: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.0503e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 299/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1973e-05 - acc: 1.0000Epoch 00299: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0184e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 300/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1298e-04 - acc: 1.0000Epoch 00300: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9430e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9949\n",
      "Epoch 301/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0800e-04 - acc: 1.0000Epoch 00301: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0158e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 302/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.0186e-05 - acc: 1.0000Epoch 00302: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.6783e-05 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 303/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8105e-04 - acc: 1.0000Epoch 00303: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8598e-04 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9949\n",
      "Epoch 304/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6468e-04 - acc: 1.0000Epoch 00304: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5658e-04 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9949\n",
      "Epoch 305/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4795e-04 - acc: 1.0000Epoch 00305: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.5808e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 306/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1529e-04 - acc: 1.0000Epoch 00306: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1087e-04 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 307/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9032e-04 - acc: 1.0000Epoch 00307: val_loss improved from 0.00336 to 0.00316, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7941e-04 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 308/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6144e-04 - acc: 1.0000Epoch 00308: val_loss improved from 0.00316 to 0.00296, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.1654e-04 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 309/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6314e-04 - acc: 1.0000Epoch 00309: val_loss improved from 0.00296 to 0.00237, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5311e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 310/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0848e-04 - acc: 1.0000Epoch 00310: val_loss improved from 0.00237 to 0.00220, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2885e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 311/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2694e-04 - acc: 1.0000Epoch 00311: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2272e-04 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 312/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6580e-04 - acc: 1.0000Epoch 00312: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3490e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 313/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4855e-05 - acc: 1.0000Epoch 00313: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3639e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 314/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0016 - acc: 1.0000Epoch 00314: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9949\n",
      "Epoch 315/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.2318e-05 - acc: 1.0000Epoch 00315: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.7062e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 316/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0438e-05 - acc: 1.0000Epoch 00316: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8647e-05 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 317/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2639e-04 - acc: 1.0000Epoch 00317: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1983e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9899\n",
      "Epoch 318/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8188e-04 - acc: 1.0000Epoch 00318: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8243e-04 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9949\n",
      "Epoch 319/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0567e-04 - acc: 1.0000Epoch 00319: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0071e-04 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 320/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0590e-04 - acc: 1.0000Epoch 00320: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0155e-04 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 321/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0416e-04 - acc: 1.0000Epoch 00321: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8323e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9899\n",
      "Epoch 322/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.8708e-05 - acc: 1.0000Epoch 00322: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.5791e-05 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9949\n",
      "Epoch 323/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3029e-04 - acc: 1.0000Epoch 00323: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.0173e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 324/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6042e-04 - acc: 1.0000Epoch 00324: val_loss improved from 0.00220 to 0.00188, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.1636e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 325/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4662e-04 - acc: 1.0000Epoch 00325: val_loss improved from 0.00188 to 0.00145, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.1427e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 326/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5090e-04 - acc: 1.0000Epoch 00326: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3424e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 327/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0480e-05 - acc: 1.0000Epoch 00327: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0568e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 328/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5222e-04 - acc: 1.0000Epoch 00328: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0792e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 329/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9661e-04 - acc: 1.0000Epoch 00329: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.6664e-04 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9949\n",
      "Epoch 330/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1033e-04 - acc: 1.0000Epoch 00330: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8870e-04 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9949\n",
      "Epoch 331/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6389e-04 - acc: 1.0000Epoch 00331: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5359e-04 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9949\n",
      "Epoch 332/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2771e-04 - acc: 1.0000Epoch 00332: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1938e-04 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9949\n",
      "Epoch 333/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1967e-04 - acc: 1.0000Epoch 00333: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1177e-04 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9949\n",
      "Epoch 334/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4121e-05 - acc: 1.0000Epoch 00334: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7000e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 335/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0014 - acc: 0.9986Epoch 00335: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0014 - acc: 0.9987 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 336/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1084e-04 - acc: 1.0000Epoch 00336: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0398e-04 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 337/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9321e-05 - acc: 1.0000Epoch 00337: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.3768e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 338/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8305e-04 - acc: 1.0000Epoch 00338: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7809e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 339/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4587e-04 - acc: 1.0000Epoch 00339: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0692e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9949\n",
      "Epoch 340/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4649e-04 - acc: 1.0000Epoch 00340: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2248e-04 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9949\n",
      "Epoch 341/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2187e-04 - acc: 1.0000Epoch 00341: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1024e-04 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 342/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4986e-04 - acc: 1.0000Epoch 00342: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4082e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 343/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2432e-05 - acc: 1.0000Epoch 00343: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.9690e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 344/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3515e-04 - acc: 1.0000Epoch 00344: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6873e-04 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9949\n",
      "Epoch 345/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2681e-05 - acc: 1.0000Epoch 00345: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.2463e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9949\n",
      "Epoch 346/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3521e-05 - acc: 1.0000Epoch 00346: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.9041e-05 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 347/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3716e-04 - acc: 1.0000Epoch 00347: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1552e-04 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 348/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1572e-05 - acc: 1.0000Epoch 00348: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.6788e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 349/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5480e-05 - acc: 1.0000Epoch 00349: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4845e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 350/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.0543e-05 - acc: 1.0000Epoch 00350: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.5040e-05 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 0.9949\n",
      "Epoch 351/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9402e-05 - acc: 1.0000Epoch 00351: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8230e-05 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9949\n",
      "Epoch 352/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6486e-05 - acc: 1.0000Epoch 00352: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3755e-05 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 0.9949\n",
      "Epoch 353/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3874e-05 - acc: 1.0000Epoch 00353: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.8291e-05 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9949\n",
      "Epoch 354/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8443e-05 - acc: 1.0000Epoch 00354: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.5837e-05 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 355/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1262e-05 - acc: 1.0000Epoch 00355: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5733e-05 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9949\n",
      "Epoch 356/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7868e-05 - acc: 1.0000Epoch 00356: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.7055e-05 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9899\n",
      "Epoch 357/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4389e-04 - acc: 1.0000Epoch 00357: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3713e-04 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9949\n",
      "Epoch 358/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6034e-05 - acc: 1.0000Epoch 00358: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1199e-04 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9949\n",
      "Epoch 359/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3332e-05 - acc: 1.0000Epoch 00359: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.4946e-05 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9949\n",
      "Epoch 360/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7302e-05 - acc: 1.0000Epoch 00360: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.2539e-05 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9949\n",
      "Epoch 361/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8822e-05 - acc: 1.0000Epoch 00361: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.6015e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 362/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2306e-04 - acc: 1.0000Epoch 00362: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1849e-04 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 363/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.6480e-05 - acc: 1.0000Epoch 00363: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1439e-04 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9949\n",
      "Epoch 364/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9957e-04 - acc: 1.0000Epoch 00364: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7931e-04 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 365/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7783e-04 - acc: 1.0000Epoch 00365: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4710e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 366/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7076e-05 - acc: 1.0000Epoch 00366: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0540e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 367/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2570e-05 - acc: 1.0000Epoch 00367: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1981e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 368/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9631e-04 - acc: 1.0000Epoch 00368: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.0026e-04 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 369/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9012e-05 - acc: 1.0000Epoch 00369: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.0558e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 370/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3620e-05 - acc: 1.0000Epoch 00370: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2781e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 371/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2709e-05 - acc: 1.0000Epoch 00371: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5039e-05 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9949\n",
      "Epoch 372/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8404e-05 - acc: 1.0000Epoch 00372: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.0411e-05 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9949\n",
      "Epoch 373/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2822e-04 - acc: 1.0000Epoch 00373: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1470e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 374/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8508e-04 - acc: 1.0000Epoch 00374: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7668e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9899\n",
      "Epoch 375/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9927e-05 - acc: 1.0000Epoch 00375: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.6564e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9949\n",
      "Epoch 376/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7970e-05 - acc: 1.0000Epoch 00376: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.6782e-05 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 377/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5031e-05 - acc: 1.0000Epoch 00377: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6715e-05 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 378/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1273e-04 - acc: 1.0000Epoch 00378: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1002e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 379/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8542e-04 - acc: 1.0000Epoch 00379: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7293e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 380/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3382e-05 - acc: 1.0000Epoch 00380: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2394e-05 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 381/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6063e-05 - acc: 1.0000Epoch 00381: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.3959e-05 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 382/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1339e-05 - acc: 1.0000Epoch 00382: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9298e-05 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 383/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0577e-04 - acc: 1.0000Epoch 00383: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9196e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 384/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2218e-04 - acc: 1.0000Epoch 00384: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9997e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 385/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8644e-05 - acc: 1.0000Epoch 00385: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2494e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 386/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5284e-05 - acc: 1.0000Epoch 00386: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3406e-05 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 387/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3796e-05 - acc: 1.0000Epoch 00387: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.2323e-05 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 388/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9494e-05 - acc: 1.0000Epoch 00388: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8850e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 389/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7252e-05 - acc: 1.0000Epoch 00389: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4024e-05 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 390/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1200e-05 - acc: 1.0000Epoch 00390: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.6950e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 391/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3843e-05 - acc: 1.0000Epoch 00391: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3228e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 392/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8925e-05 - acc: 1.0000Epoch 00392: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.6757e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 393/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1401e-05 - acc: 1.0000Epoch 00393: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.9661e-05 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 394/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2919e-04 - acc: 1.0000Epoch 00394: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2195e-04 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9949\n",
      "Epoch 395/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1320e-05 - acc: 1.0000Epoch 00395: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.1591e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9949\n",
      "Epoch 396/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4435e-04 - acc: 1.0000Epoch 00396: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3483e-04 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 397/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5448e-05 - acc: 1.0000Epoch 00397: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2914e-05 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 0.9899\n",
      "Epoch 398/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6552e-05 - acc: 1.0000Epoch 00398: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5015e-05 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 399/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2258e-05 - acc: 1.0000Epoch 00399: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.8779e-05 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9899\n",
      "Epoch 400/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9596e-05 - acc: 1.0000Epoch 00400: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.7145e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 401/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1077e-05 - acc: 1.0000Epoch 00401: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9150e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 402/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5078e-04 - acc: 1.0000Epoch 00402: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4142e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 403/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0661e-04 - acc: 1.0000Epoch 00403: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9404e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 404/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.9257e-05 - acc: 1.0000Epoch 00404: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.5163e-05 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 405/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6271e-05 - acc: 1.0000Epoch 00405: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2326e-05 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9949\n",
      "Epoch 406/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4082e-05 - acc: 1.0000Epoch 00406: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4851e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 407/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7766e-05 - acc: 1.0000Epoch 00407: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1814e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 408/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5989e-05 - acc: 1.0000Epoch 00408: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4365e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 409/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3488e-04 - acc: 1.0000Epoch 00409: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2633e-04 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9949\n",
      "Epoch 410/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.7778e-04 - acc: 1.0000Epoch 00410: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.2311e-04 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 0.9949\n",
      "Epoch 411/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6852e-05 - acc: 1.0000Epoch 00411: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.6088e-05 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9949\n",
      "Epoch 412/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5606e-04 - acc: 1.0000Epoch 00412: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5112e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 413/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1985e-05 - acc: 1.0000Epoch 00413: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2698e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 414/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5988e-04 - acc: 1.0000Epoch 00414: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5416e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 415/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0921e-05 - acc: 1.0000Epoch 00415: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.9598e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 416/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8571e-05 - acc: 1.0000Epoch 00416: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3990e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 417/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1056e-04 - acc: 1.0000Epoch 00417: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0351e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9949\n",
      "Epoch 418/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5971e-05 - acc: 1.0000Epoch 00418: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8830e-05 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9949\n",
      "Epoch 419/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9803e-05 - acc: 1.0000Epoch 00419: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.6375e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 420/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2449e-05 - acc: 1.0000Epoch 00420: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9148e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 421/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4611e-05 - acc: 1.0000Epoch 00421: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2589e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 422/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5067e-04 - acc: 1.0000Epoch 00422: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4162e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 423/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3714e-05 - acc: 1.0000Epoch 00423: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.6681e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 424/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9881e-05 - acc: 1.0000Epoch 00424: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9279e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 425/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3716e-05 - acc: 1.0000Epoch 00425: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.2791e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 426/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0747e-05 - acc: 1.0000Epoch 00426: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.7886e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 427/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4987e-05 - acc: 1.0000Epoch 00427: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2987e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 428/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2004e-05 - acc: 1.0000Epoch 00428: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1461e-05 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 429/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6248e-05 - acc: 1.0000Epoch 00429: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5607e-05 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 430/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3536e-04 - acc: 1.0000Epoch 00430: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2075e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 431/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2229e-05 - acc: 1.0000Epoch 00431: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1153e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 432/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7630e-04 - acc: 1.0000Epoch 00432: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5690e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 433/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9480e-05 - acc: 1.0000Epoch 00433: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6175e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 434/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1066e-05 - acc: 1.0000Epoch 00434: val_loss improved from 0.00145 to 0.00091, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7621e-05 - acc: 1.0000 - val_loss: 9.0872e-04 - val_acc: 1.0000\n",
      "Epoch 435/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3418e-04 - acc: 1.0000Epoch 00435: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1808e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 436/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2500e-04 - acc: 1.0000Epoch 00436: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2542e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 437/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8076e-05 - acc: 1.0000Epoch 00437: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6737e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 438/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5716e-05 - acc: 1.0000Epoch 00438: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4922e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 439/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9450e-05 - acc: 1.0000Epoch 00439: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1413e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 440/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0577e-05 - acc: 1.0000Epoch 00440: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.0928e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9949\n",
      "Epoch 441/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8647e-05 - acc: 1.0000Epoch 00441: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9944e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 442/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6672e-05 - acc: 1.0000Epoch 00442: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.0713e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 443/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6253e-05 - acc: 1.0000Epoch 00443: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5416e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 444/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8777e-05 - acc: 1.0000Epoch 00444: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.7230e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 445/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1898e-05 - acc: 1.0000Epoch 00445: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2283e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 446/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3715e-05 - acc: 1.0000Epoch 00446: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3609e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9949\n",
      "Epoch 447/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8466e-05 - acc: 1.0000Epoch 00447: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.8552e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 448/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9360e-05 - acc: 1.0000Epoch 00448: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8478e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 449/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7951e-05 - acc: 1.0000Epoch 00449: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6092e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 450/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4710e-05 - acc: 1.0000Epoch 00450: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.0470e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 451/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6764e-04 - acc: 1.0000Epoch 00451: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.3476e-04 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 452/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3599e-05 - acc: 1.0000Epoch 00452: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.0513e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 453/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5324e-05 - acc: 1.0000Epoch 00453: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7752e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 454/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4801e-05 - acc: 1.0000Epoch 00454: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.8584e-05 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 455/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.1458e-05 - acc: 1.0000Epoch 00455: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.6731e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 456/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.3777e-05 - acc: 1.0000Epoch 00456: val_loss improved from 0.00091 to 0.00046, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.8270e-05 - acc: 1.0000 - val_loss: 4.6409e-04 - val_acc: 1.0000\n",
      "Epoch 457/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1711e-04 - acc: 1.0000Epoch 00457: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1092e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 458/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3805e-04 - acc: 1.0000Epoch 00458: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2861e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 459/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4777e-05 - acc: 1.0000Epoch 00459: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.2539e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 460/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8589e-05 - acc: 1.0000Epoch 00460: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7759e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 461/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0561e-04 - acc: 1.0000Epoch 00461: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.8488e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 462/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2057e-04 - acc: 1.0000Epoch 00462: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1234e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 463/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8360e-05 - acc: 1.0000Epoch 00463: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7557e-05 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 464/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0670e-05 - acc: 1.0000Epoch 00464: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9392e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 465/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2051e-05 - acc: 1.0000Epoch 00465: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1100e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 466/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3411e-05 - acc: 1.0000Epoch 00466: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2619e-05 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 467/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7942e-05 - acc: 1.0000Epoch 00467: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7495e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 468/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1034e-04 - acc: 1.0000Epoch 00468: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0493e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 469/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.5221e-05 - acc: 1.0000Epoch 00469: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.8953e-05 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9949\n",
      "Epoch 470/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0675e-04 - acc: 1.0000Epoch 00470: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0376e-04 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9949\n",
      "Epoch 471/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3962e-05 - acc: 1.0000Epoch 00471: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6182e-05 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9949\n",
      "Epoch 472/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2807e-05 - acc: 1.0000Epoch 00472: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.7044e-05 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 473/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3684e-05 - acc: 1.0000Epoch 00473: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9834e-05 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9899\n",
      "Epoch 474/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7715e-04 - acc: 1.0000Epoch 00474: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5817e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 475/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1453e-05 - acc: 1.0000Epoch 00475: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0009e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 476/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6822e-04 - acc: 1.0000Epoch 00476: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.7652e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 477/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1014e-04 - acc: 1.0000Epoch 00477: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9636e-04 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9949\n",
      "Epoch 478/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1251e-05 - acc: 1.0000Epoch 00478: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8565e-05 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9949\n",
      "Epoch 479/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7584e-05 - acc: 1.0000Epoch 00479: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6854e-05 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 480/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7659e-04 - acc: 1.0000Epoch 00480: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6572e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9899\n",
      "Epoch 481/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2692e-04 - acc: 1.0000Epoch 00481: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1308e-04 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9899\n",
      "Epoch 482/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0218e-05 - acc: 1.0000Epoch 00482: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0619e-05 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9949\n",
      "Epoch 483/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5539e-04 - acc: 1.0000Epoch 00483: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3756e-04 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 484/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.4919e-05 - acc: 1.0000Epoch 00484: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 8.8705e-05 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9949\n",
      "Epoch 485/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0627e-04 - acc: 1.0000Epoch 00485: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 1.9215e-04 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 486/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.9983e-05 - acc: 1.0000Epoch 00486: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.3475e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 487/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7869e-05 - acc: 1.0000Epoch 00487: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 8.1804e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 488/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0723e-04 - acc: 1.0000Epoch 00488: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.0625e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 489/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6671e-05 - acc: 1.0000Epoch 00489: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 4.5795e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 490/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.5266e-05 - acc: 1.0000Epoch 00490: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.5268e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 491/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2589e-05 - acc: 1.0000Epoch 00491: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.0436e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 492/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6727e-05 - acc: 1.0000Epoch 00492: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.1496e-05 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9949\n",
      "Epoch 493/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7521e-05 - acc: 1.0000Epoch 00493: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 8.6604e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 494/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3906e-06 - acc: 1.0000Epoch 00494: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.3968e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 495/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5287e-05 - acc: 1.0000Epoch 00495: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 5.4568e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 496/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1146e-05 - acc: 1.0000Epoch 00496: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.2238e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 497/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.8597e-05 - acc: 1.0000Epoch 00497: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 9.4454e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 498/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5266e-04 - acc: 1.0000Epoch 00498: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 2.3511e-04 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9949\n",
      "Epoch 499/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9293e-06 - acc: 1.0000Epoch 00499: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 8.2156e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 500/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3276e-05 - acc: 1.0000Epoch 00500: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 3.1240e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 501/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9805e-06 - acc: 1.0000Epoch 00501: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 6.6047e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 502/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8214e-05 - acc: 1.0000Epoch 00502: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 5.4438e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 503/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1330e-04 - acc: 1.0000Epoch 00503: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.0605e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 504/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2212e-04 - acc: 1.0000Epoch 00504: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 4.0661e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 505/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9373e-05 - acc: 1.0000Epoch 00505: val_loss did not improve\n",
      "792/792 [==============================] - 1s 963us/step - loss: 1.8663e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 506/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3689e-05 - acc: 1.0000Epoch 00506: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 2.2081e-05 - acc: 1.0000 - val_loss: 7.5559e-04 - val_acc: 1.0000\n",
      "Epoch 507/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1025e-05 - acc: 1.0000Epoch 00507: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 2.0009e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 508/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7536e-05 - acc: 1.0000Epoch 00508: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 2.6061e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 509/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8018e-05 - acc: 1.0000Epoch 00509: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 3.5714e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 510/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8086e-04 - acc: 1.0000Epoch 00510: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 3.6835e-04 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 511/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8246e-04 - acc: 1.0000Epoch 00511: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4267e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 512/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3331e-05 - acc: 1.0000Epoch 00512: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 3.6556e-05 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 513/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8541e-04 - acc: 1.0000Epoch 00513: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 1.7259e-04 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9949\n",
      "Epoch 514/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8585e-05 - acc: 1.0000Epoch 00514: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 2.7649e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 515/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9611e-04 - acc: 1.0000Epoch 00515: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 8.3292e-04 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 516/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0257e-05 - acc: 1.0000Epoch 00516: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 2.9313e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9949\n",
      "Epoch 517/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4241e-05 - acc: 1.0000Epoch 00517: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.3325e-05 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 518/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6162e-05 - acc: 1.0000Epoch 00518: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6891e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9949\n",
      "Epoch 519/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9328e-04 - acc: 1.0000Epoch 00519: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.8039e-04 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9949\n",
      "Epoch 520/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2721e-04 - acc: 1.0000Epoch 00520: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1847e-04 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9949\n",
      "Epoch 521/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5765e-05 - acc: 1.0000Epoch 00521: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5175e-05 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9949\n",
      "Epoch 522/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3338e-05 - acc: 1.0000Epoch 00522: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.3538e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 523/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8504e-05 - acc: 1.0000Epoch 00523: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7447e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 524/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3862e-05 - acc: 1.0000Epoch 00524: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.0240e-05 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9949\n",
      "Epoch 525/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2311e-05 - acc: 1.0000Epoch 00525: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.9361e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 526/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3597e-05 - acc: 1.0000Epoch 00526: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1316e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9899\n",
      "Epoch 527/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4535e-05 - acc: 1.0000Epoch 00527: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4038e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9949\n",
      "Epoch 528/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8296e-05 - acc: 1.0000Epoch 00528: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.0726e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9949\n",
      "Epoch 529/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6568e-04 - acc: 1.0000Epoch 00529: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5481e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9949\n",
      "Epoch 530/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5902e-05 - acc: 1.0000Epoch 00530: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4872e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 531/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4868e-05 - acc: 1.0000Epoch 00531: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3298e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 532/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1857e-05 - acc: 1.0000Epoch 00532: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8344e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 533/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1370e-05 - acc: 1.0000Epoch 00533: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8769e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 534/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1984e-05 - acc: 1.0000Epoch 00534: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1020e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 535/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7098e-05 - acc: 1.0000Epoch 00535: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4301e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 536/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4515e-05 - acc: 1.0000Epoch 00536: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3386e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 537/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0030e-04 - acc: 1.0000Epoch 00537: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0751e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9949\n",
      "Epoch 538/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2336e-04 - acc: 1.0000Epoch 00538: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.9572e-04 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9949\n",
      "Epoch 539/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8494e-05 - acc: 1.0000Epoch 00539: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8044e-05 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9949\n",
      "Epoch 540/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0318e-04 - acc: 1.0000Epoch 00540: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8907e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 541/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7987e-05 - acc: 1.0000Epoch 00541: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.2439e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 542/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4021e-05 - acc: 1.0000Epoch 00542: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3899e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 543/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6294e-05 - acc: 1.0000Epoch 00543: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.7208e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 544/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9296e-04 - acc: 1.0000Epoch 00544: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7277e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 545/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0894e-05 - acc: 1.0000Epoch 00545: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3352e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 546/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0021 - acc: 0.9986Epoch 00546: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.9987 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 547/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5811e-05 - acc: 1.0000Epoch 00547: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3348e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 548/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4035e-06 - acc: 1.0000Epoch 00548: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.3861e-06 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 549/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0374e-04 - acc: 1.0000Epoch 00549: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5778e-04 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9949\n",
      "Epoch 550/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9384e-05 - acc: 1.0000Epoch 00550: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.6374e-05 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 0.9949\n",
      "Epoch 551/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.5041e-04 - acc: 1.0000Epoch 00551: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.9038e-04 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9949\n",
      "Epoch 552/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5932e-05 - acc: 1.0000Epoch 00552: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.6010e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 553/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.5028e-06 - acc: 1.0000Epoch 00553: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.1425e-06 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 554/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8804e-05 - acc: 1.0000Epoch 00554: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2789e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 555/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9194e-05 - acc: 1.0000Epoch 00555: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.7098e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 556/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1284e-05 - acc: 1.0000Epoch 00556: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0531e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 557/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1459e-04 - acc: 1.0000Epoch 00557: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0827e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 558/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0055e-05 - acc: 1.0000Epoch 00558: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8424e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 559/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0743e-05 - acc: 1.0000Epoch 00559: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9688e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 560/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2176e-05 - acc: 1.0000Epoch 00560: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3537e-05 - acc: 1.0000 - val_loss: 6.7956e-04 - val_acc: 1.0000\n",
      "Epoch 561/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3810e-05 - acc: 1.0000Epoch 00561: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3107e-05 - acc: 1.0000 - val_loss: 8.7237e-04 - val_acc: 1.0000\n",
      "Epoch 562/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8077e-04 - acc: 1.0000Epoch 00562: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6930e-04 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 563/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8529e-05 - acc: 1.0000Epoch 00563: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7513e-05 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9949\n",
      "Epoch 564/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3677e-06 - acc: 1.0000Epoch 00564: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3971e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9949\n",
      "Epoch 565/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3925e-05 - acc: 1.0000Epoch 00565: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.9110e-05 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 566/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3263e-05 - acc: 1.0000Epoch 00566: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1734e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 567/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5519e-05 - acc: 1.0000Epoch 00567: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.7358e-05 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 0.9899\n",
      "Epoch 568/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7430e-04 - acc: 1.0000Epoch 00568: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6392e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9949\n",
      "Epoch 569/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2602e-05 - acc: 1.0000Epoch 00569: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3031e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 570/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2624e-04 - acc: 1.0000Epoch 00570: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4806e-04 - acc: 1.0000 - val_loss: 9.0084e-04 - val_acc: 1.0000\n",
      "Epoch 571/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.4886e-05 - acc: 1.0000Epoch 00571: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.9860e-05 - acc: 1.0000 - val_loss: 5.0470e-04 - val_acc: 1.0000\n",
      "Epoch 572/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1190e-04 - acc: 1.0000Epoch 00572: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1751e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 573/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8402e-06 - acc: 1.0000Epoch 00573: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.1970e-06 - acc: 1.0000 - val_loss: 6.1838e-04 - val_acc: 1.0000\n",
      "Epoch 574/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5432e-05 - acc: 1.0000Epoch 00574: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3410e-05 - acc: 1.0000 - val_loss: 8.1502e-04 - val_acc: 1.0000\n",
      "Epoch 575/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5476e-05 - acc: 1.0000Epoch 00575: val_loss improved from 0.00046 to 0.00026, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3952e-05 - acc: 1.0000 - val_loss: 2.5665e-04 - val_acc: 1.0000\n",
      "Epoch 576/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0161e-04 - acc: 1.0000Epoch 00576: val_loss improved from 0.00026 to 0.00021, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8878e-04 - acc: 1.0000 - val_loss: 2.1310e-04 - val_acc: 1.0000\n",
      "Epoch 577/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5911e-05 - acc: 1.0000Epoch 00577: val_loss improved from 0.00021 to 0.00012, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4787e-05 - acc: 1.0000 - val_loss: 1.2364e-04 - val_acc: 1.0000\n",
      "Epoch 578/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0217e-05 - acc: 1.0000Epoch 00578: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9500e-05 - acc: 1.0000 - val_loss: 2.2606e-04 - val_acc: 1.0000\n",
      "Epoch 579/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2222e-05 - acc: 1.0000Epoch 00579: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1812e-05 - acc: 1.0000 - val_loss: 1.6460e-04 - val_acc: 1.0000\n",
      "Epoch 580/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9245e-05 - acc: 1.0000Epoch 00580: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4325e-05 - acc: 1.0000 - val_loss: 6.6754e-04 - val_acc: 1.0000\n",
      "Epoch 581/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5259e-05 - acc: 1.0000Epoch 00581: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7825e-05 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9949\n",
      "Epoch 582/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6645e-05 - acc: 1.0000Epoch 00582: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4092e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 583/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0610e-04 - acc: 1.0000Epoch 00583: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0190e-04 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9949\n",
      "Epoch 584/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1184e-04 - acc: 1.0000Epoch 00584: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9735e-04 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 0.9949\n",
      "Epoch 585/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5936e-05 - acc: 1.0000Epoch 00585: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3738e-05 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9949\n",
      "Epoch 586/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0825e-05 - acc: 1.0000Epoch 00586: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0203e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 587/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2797e-05 - acc: 1.0000Epoch 00587: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3091e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 588/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4071e-05 - acc: 1.0000Epoch 00588: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2617e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 589/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1028e-04 - acc: 1.0000Epoch 00589: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.9458e-04 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9949\n",
      "Epoch 590/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3292e-04 - acc: 1.0000Epoch 00590: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2372e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 591/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4524e-04 - acc: 1.0000Epoch 00591: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 0.0096 - val_acc: 0.9899\n",
      "Epoch 592/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7413e-05 - acc: 1.0000Epoch 00592: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4653e-05 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9949\n",
      "Epoch 593/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0021 - acc: 0.9986   Epoch 00593: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.9987 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 594/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0118e-05 - acc: 1.0000Epoch 00594: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7844e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 595/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0480e-04 - acc: 1.0000Epoch 00595: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.8039e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 596/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8945e-05 - acc: 1.0000Epoch 00596: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.3768e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 597/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0738e-05 - acc: 1.0000Epoch 00597: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0518e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 598/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1582e-04 - acc: 1.0000Epoch 00598: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1125e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 599/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6409e-05 - acc: 1.0000Epoch 00599: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8546e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 600/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5436e-05 - acc: 1.0000Epoch 00600: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.1586e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 601/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9429e-05 - acc: 1.0000Epoch 00601: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7586e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 602/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0604e-06 - acc: 1.0000Epoch 00602: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2957e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 603/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1602e-05 - acc: 1.0000Epoch 00603: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0232e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 604/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8494e-05 - acc: 1.0000Epoch 00604: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4708e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 605/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0150e-05 - acc: 1.0000Epoch 00605: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8843e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 606/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1771e-05 - acc: 1.0000Epoch 00606: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1009e-05 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9949\n",
      "Epoch 607/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8818e-05 - acc: 1.0000Epoch 00607: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.7611e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 608/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6574e-06 - acc: 1.0000Epoch 00608: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.5170e-06 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 609/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6934e-05 - acc: 1.0000Epoch 00609: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5421e-05 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9949\n",
      "Epoch 610/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1167e-05 - acc: 1.0000Epoch 00610: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5141e-05 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 611/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0016 - acc: 0.9986 Epoch 00611: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 0.0016 - acc: 0.9987 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 612/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3507e-05 - acc: 1.0000Epoch 00612: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 4.9787e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 613/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4816e-04 - acc: 1.0000Epoch 00613: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.3787e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 614/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1212e-06 - acc: 1.0000Epoch 00614: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 1.5615e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 615/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6368e-05 - acc: 1.0000Epoch 00615: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 5.2476e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 616/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1642e-05 - acc: 1.0000Epoch 00616: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 2.0227e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 617/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2309e-05 - acc: 1.0000Epoch 00617: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0834e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 618/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4581e-05 - acc: 1.0000Epoch 00618: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3972e-05 - acc: 1.0000 - val_loss: 7.1418e-04 - val_acc: 1.0000\n",
      "Epoch 619/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6162e-04 - acc: 1.0000Epoch 00619: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5090e-04 - acc: 1.0000 - val_loss: 4.3166e-04 - val_acc: 1.0000\n",
      "Epoch 620/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7636e-05 - acc: 1.0000Epoch 00620: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5829e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 621/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7481e-05 - acc: 1.0000Epoch 00621: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.2960e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 622/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6514e-04 - acc: 1.0000Epoch 00622: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5694e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 623/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6021e-04 - acc: 1.0000Epoch 00623: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.9972e-04 - acc: 1.0000 - val_loss: 6.3804e-04 - val_acc: 1.0000\n",
      "Epoch 624/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5219e-05 - acc: 1.0000Epoch 00624: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6254e-05 - acc: 1.0000 - val_loss: 4.0184e-04 - val_acc: 1.0000\n",
      "Epoch 625/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1009e-05 - acc: 1.0000Epoch 00625: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1348e-05 - acc: 1.0000 - val_loss: 8.4750e-04 - val_acc: 1.0000\n",
      "Epoch 626/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6395e-05 - acc: 1.0000Epoch 00626: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4881e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 627/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4313e-05 - acc: 1.0000Epoch 00627: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0295e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 628/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4454e-05 - acc: 1.0000Epoch 00628: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2166e-05 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 629/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2236e-04 - acc: 1.0000Epoch 00629: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1453e-04 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9949\n",
      "Epoch 630/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7965e-05 - acc: 1.0000Epoch 00630: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.7909e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 631/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.4775e-06 - acc: 1.0000Epoch 00631: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.4213e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 632/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4600e-05 - acc: 1.0000Epoch 00632: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3816e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 633/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3881e-05 - acc: 1.0000Epoch 00633: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2932e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 634/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5345e-04 - acc: 1.0000Epoch 00634: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.2186e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 635/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5544e-05 - acc: 1.0000Epoch 00635: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4469e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 636/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1322e-05 - acc: 1.0000Epoch 00636: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9509e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 637/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4666e-05 - acc: 1.0000Epoch 00637: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.1848e-05 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 638/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0560e-05 - acc: 1.0000Epoch 00638: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4615e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 639/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2203e-05 - acc: 1.0000Epoch 00639: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0056e-05 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 640/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8413e-04 - acc: 1.0000Epoch 00640: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7175e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9949\n",
      "Epoch 641/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4288e-05 - acc: 1.0000Epoch 00641: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1934e-05 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9949\n",
      "Epoch 642/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1412e-05 - acc: 1.0000Epoch 00642: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.0646e-05 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9949\n",
      "Epoch 643/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4378e-05 - acc: 1.0000Epoch 00643: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3408e-05 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 644/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6686e-06 - acc: 1.0000Epoch 00644: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5843e-06 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 645/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9906e-05 - acc: 1.0000Epoch 00645: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1885e-05 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 646/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2574e-04 - acc: 1.0000Epoch 00646: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1701e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 647/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1890e-05 - acc: 1.0000Epoch 00647: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1501e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 648/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6005e-05 - acc: 1.0000Epoch 00648: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3375e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 649/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2137e-06 - acc: 1.0000Epoch 00649: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.8807e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 650/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2913e-06 - acc: 1.0000Epoch 00650: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.3697e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 651/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6358e-05 - acc: 1.0000Epoch 00651: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5274e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 652/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2917e-05 - acc: 1.0000Epoch 00652: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2102e-05 - acc: 1.0000 - val_loss: 7.0166e-04 - val_acc: 1.0000\n",
      "Epoch 653/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6560e-05 - acc: 1.0000Epoch 00653: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5740e-05 - acc: 1.0000 - val_loss: 9.3069e-04 - val_acc: 1.0000\n",
      "Epoch 654/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6907e-06 - acc: 1.0000Epoch 00654: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.5975e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 655/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2118e-05 - acc: 1.0000Epoch 00655: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0063e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 656/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1382e-04 - acc: 1.0000Epoch 00656: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0584e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 657/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7795e-05 - acc: 1.0000Epoch 00657: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7049e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 658/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.0394e-06 - acc: 1.0000Epoch 00658: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.9192e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 659/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1281e-05 - acc: 1.0000Epoch 00659: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0432e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 660/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0014 - acc: 0.9986  Epoch 00660: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.9987 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 661/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5993e-06 - acc: 1.0000Epoch 00661: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6584e-06 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9949\n",
      "Epoch 662/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0801e-05 - acc: 1.0000Epoch 00662: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0086e-05 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9949\n",
      "Epoch 663/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4823e-05 - acc: 1.0000Epoch 00663: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.2240e-05 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9949\n",
      "Epoch 664/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1295e-05 - acc: 1.0000Epoch 00664: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0880e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9949\n",
      "Epoch 665/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4717e-05 - acc: 1.0000Epoch 00665: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3791e-05 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9949\n",
      "Epoch 666/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 0.9986Epoch 00666: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.9987 - val_loss: 0.0178 - val_acc: 0.9949\n",
      "Epoch 667/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0619e-05 - acc: 1.0000Epoch 00667: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0518e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9899\n",
      "Epoch 668/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3741e-06 - acc: 1.0000Epoch 00668: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.2448e-06 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9949\n",
      "Epoch 669/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0886e-04 - acc: 1.0000Epoch 00669: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0143e-04 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 670/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4325e-05 - acc: 1.0000Epoch 00670: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3602e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 671/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6419e-05 - acc: 1.0000Epoch 00671: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5435e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 672/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9246e-06 - acc: 1.0000Epoch 00672: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8032e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 673/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.6368e-06 - acc: 1.0000Epoch 00673: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.2654e-06 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 674/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.8018e-06 - acc: 1.0000Epoch 00674: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.2195e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 675/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0828e-04 - acc: 1.0000Epoch 00675: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0065e-04 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9949\n",
      "Epoch 676/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6790e-06 - acc: 1.0000Epoch 00676: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4596e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 677/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0494e-05 - acc: 1.0000Epoch 00677: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9461e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 678/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9003e-05 - acc: 1.0000Epoch 00678: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.5064e-05 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9949\n",
      "Epoch 679/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0007e-05 - acc: 1.0000Epoch 00679: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.3548e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 680/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6683e-05 - acc: 1.0000Epoch 00680: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5535e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 681/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3850e-06 - acc: 1.0000Epoch 00681: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.9077e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 682/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7572e-05 - acc: 1.0000Epoch 00682: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7934e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 683/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1770e-05 - acc: 1.0000Epoch 00683: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.0310e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 684/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1566e-04 - acc: 1.0000Epoch 00684: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0847e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9949\n",
      "Epoch 685/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.4569e-06 - acc: 1.0000Epoch 00685: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5006e-06 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 686/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3922e-05 - acc: 1.0000Epoch 00686: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3657e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 687/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1672e-04 - acc: 1.0000Epoch 00687: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5205e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 688/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2566e-05 - acc: 1.0000Epoch 00688: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0795e-05 - acc: 1.0000 - val_loss: 7.5437e-04 - val_acc: 1.0000\n",
      "Epoch 689/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7013e-06 - acc: 1.0000Epoch 00689: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4056e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 690/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5394e-06 - acc: 1.0000Epoch 00690: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.2206e-06 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9949\n",
      "Epoch 691/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.7792e-06 - acc: 1.0000Epoch 00691: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.9975e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 692/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.4897e-06 - acc: 1.0000Epoch 00692: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1325e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 693/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.7090e-06 - acc: 1.0000Epoch 00693: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4027e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 694/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2194e-05 - acc: 1.0000Epoch 00694: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0153e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 695/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.4502e-06 - acc: 1.0000Epoch 00695: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1800e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 696/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2184e-05 - acc: 1.0000Epoch 00696: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0080e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 697/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6291e-05 - acc: 1.0000Epoch 00697: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1584e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9949\n",
      "Epoch 698/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1679e-05 - acc: 1.0000Epoch 00698: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0158e-05 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9949\n",
      "Epoch 699/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8664e-04 - acc: 1.0000Epoch 00699: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7606e-04 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 700/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8236e-05 - acc: 1.0000Epoch 00700: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7610e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 701/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5138e-05 - acc: 1.0000Epoch 00701: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3017e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9949\n",
      "Epoch 702/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6404e-06 - acc: 1.0000Epoch 00702: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.5636e-06 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9949\n",
      "Epoch 703/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6820e-06 - acc: 1.0000Epoch 00703: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.2911e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9949\n",
      "Epoch 704/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3266e-06 - acc: 1.0000Epoch 00704: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3065e-06 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9949\n",
      "Epoch 705/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6411e-04 - acc: 1.0000Epoch 00705: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5253e-04 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9949\n",
      "Epoch 706/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6199e-05 - acc: 1.0000Epoch 00706: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5180e-05 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9949\n",
      "Epoch 707/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3452e-04 - acc: 1.0000Epoch 00707: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2001e-04 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 0.9949\n",
      "Epoch 708/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0163e-05 - acc: 1.0000Epoch 00708: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.5185e-06 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 0.9949\n",
      "Epoch 709/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3636e-05 - acc: 1.0000Epoch 00709: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2759e-05 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 0.9949\n",
      "Epoch 710/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6449e-05 - acc: 1.0000Epoch 00710: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4759e-05 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9949\n",
      "Epoch 711/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3268e-05 - acc: 1.0000Epoch 00711: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 3.1039e-05 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 0.9949\n",
      "Epoch 712/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4527e-05 - acc: 1.0000Epoch 00712: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4066e-05 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 0.9949\n",
      "Epoch 713/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.5808e-06 - acc: 1.0000Epoch 00713: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.1046e-06 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9949\n",
      "Epoch 714/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2718e-06 - acc: 1.0000Epoch 00714: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 3.6356e-06 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9949\n",
      "Epoch 715/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1250e-04 - acc: 1.0000Epoch 00715: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 2.9056e-04 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9949\n",
      "Epoch 716/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7851e-06 - acc: 1.0000Epoch 00716: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.8377e-06 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9949\n",
      "Epoch 717/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9079e-05 - acc: 1.0000Epoch 00717: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.7756e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 718/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7190e-05 - acc: 1.0000Epoch 00718: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 7.4390e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 719/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0010 - acc: 0.9986   Epoch 00719: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 0.0019 - acc: 0.9975 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 720/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.7353e-06 - acc: 1.0000Epoch 00720: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.3558e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 721/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0656e-06 - acc: 1.0000Epoch 00721: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0176e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 722/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3896e-06 - acc: 1.0000Epoch 00722: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.5472e-06 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 723/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0032e-04 - acc: 1.0000Epoch 00723: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.4840e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9949\n",
      "Epoch 724/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9360e-05 - acc: 1.0000Epoch 00724: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.4364e-05 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9899\n",
      "Epoch 725/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0869e-05 - acc: 1.0000Epoch 00725: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8760e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9949\n",
      "Epoch 726/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.5849e-06 - acc: 1.0000Epoch 00726: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.9898e-06 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 727/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6018e-05 - acc: 1.0000Epoch 00727: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3081e-05 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 728/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9220e-05 - acc: 1.0000Epoch 00728: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.5429e-05 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9949\n",
      "Epoch 729/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7652e-05 - acc: 1.0000Epoch 00729: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8770e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9949\n",
      "Epoch 730/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9189e-05 - acc: 1.0000Epoch 00730: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8960e-05 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9949\n",
      "Epoch 731/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0317e-05 - acc: 1.0000Epoch 00731: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1793e-05 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 0.9949\n",
      "Epoch 732/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5802e-04 - acc: 1.0000Epoch 00732: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3987e-04 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9949\n",
      "Epoch 733/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.0406e-05 - acc: 1.0000Epoch 00733: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.4327e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9949\n",
      "Epoch 734/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9153e-06 - acc: 1.0000Epoch 00734: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.3987e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 735/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1687e-05 - acc: 1.0000Epoch 00735: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0979e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9949\n",
      "Epoch 736/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2872e-04 - acc: 1.0000Epoch 00736: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1967e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 737/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1513e-06 - acc: 1.0000Epoch 00737: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9662e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 738/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2035e-04 - acc: 1.0000Epoch 00738: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2400e-04 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9949\n",
      "Epoch 739/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3270e-05 - acc: 1.0000Epoch 00739: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1472e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 740/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4355e-05 - acc: 1.0000Epoch 00740: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1970e-05 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9949\n",
      "Epoch 741/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2902e-05 - acc: 1.0000Epoch 00741: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1305e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9949\n",
      "Epoch 742/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3805e-04 - acc: 1.0000Epoch 00742: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.7266e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9899\n",
      "Epoch 743/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1650e-05 - acc: 1.0000Epoch 00743: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8283e-05 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9949\n",
      "Epoch 744/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8862e-05 - acc: 1.0000Epoch 00744: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7931e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 745/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1895e-05 - acc: 1.0000Epoch 00745: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1324e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 746/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0737e-05 - acc: 1.0000Epoch 00746: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8020e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9949\n",
      "Epoch 747/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0238e-05 - acc: 1.0000Epoch 00747: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.7993e-06 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9949\n",
      "Epoch 748/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6109e-04 - acc: 1.0000Epoch 00748: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6064e-04 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9949\n",
      "Epoch 749/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2085e-05 - acc: 1.0000Epoch 00749: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.7875e-05 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 0.9949\n",
      "Epoch 750/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.8078e-06 - acc: 1.0000Epoch 00750: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.3594e-06 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9949\n",
      "Epoch 751/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.3354e-05 - acc: 1.0000Epoch 00751: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.0331e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 752/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6938e-06 - acc: 1.0000Epoch 00752: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.1465e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 753/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1412e-06 - acc: 1.0000Epoch 00753: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8155e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 754/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6716e-06 - acc: 1.0000Epoch 00754: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.7964e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 755/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9387e-06 - acc: 1.0000Epoch 00755: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6724e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 756/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3934e-05 - acc: 1.0000Epoch 00756: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1564e-05 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9949\n",
      "Epoch 757/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8692e-04 - acc: 1.0000Epoch 00757: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6694e-04 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9949\n",
      "Epoch 758/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0013 - acc: 0.9986 Epoch 00758: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.9987 - val_loss: 0.0109 - val_acc: 0.9949\n",
      "Epoch 759/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6482e-06 - acc: 1.0000Epoch 00759: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.5848e-06 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9949\n",
      "Epoch 760/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9891e-04 - acc: 1.0000Epoch 00760: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.6366e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 761/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5261e-05 - acc: 1.0000Epoch 00761: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5567e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 762/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0289e-05 - acc: 1.0000Epoch 00762: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.5951e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 763/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4542e-05 - acc: 1.0000Epoch 00763: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2935e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 764/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8732e-06 - acc: 1.0000Epoch 00764: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.3570e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 765/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4442e-05 - acc: 1.0000Epoch 00765: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4285e-05 - acc: 1.0000 - val_loss: 8.8438e-04 - val_acc: 1.0000\n",
      "Epoch 766/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0992e-04 - acc: 1.0000Epoch 00766: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0222e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 767/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6601e-05 - acc: 1.0000Epoch 00767: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4869e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 768/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2840e-05 - acc: 1.0000Epoch 00768: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.9918e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 769/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2576e-05 - acc: 1.0000Epoch 00769: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8948e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 770/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6952e-04 - acc: 1.0000Epoch 00770: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5772e-04 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9949\n",
      "Epoch 771/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0213e-05 - acc: 1.0000Epoch 00771: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.8689e-06 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9949\n",
      "Epoch 772/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4866e-05 - acc: 1.0000Epoch 00772: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.0323e-05 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9949\n",
      "Epoch 773/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9905e-05 - acc: 1.0000Epoch 00773: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9695e-05 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9949\n",
      "Epoch 774/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2115e-05 - acc: 1.0000Epoch 00774: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0556e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 775/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.4785e-06 - acc: 1.0000Epoch 00775: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6387e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 776/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7006e-05 - acc: 1.0000Epoch 00776: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7137e-05 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9949\n",
      "Epoch 777/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1874e-05 - acc: 1.0000Epoch 00777: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8348e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 778/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1436e-04 - acc: 1.0000Epoch 00778: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9399e-04 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9949\n",
      "Epoch 779/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8601e-06 - acc: 1.0000Epoch 00779: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.4282e-06 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9949\n",
      "Epoch 780/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1704e-05 - acc: 1.0000Epoch 00780: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1362e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 781/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0861e-05 - acc: 1.0000Epoch 00781: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7331e-05 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9949\n",
      "Epoch 782/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4963e-05 - acc: 1.0000Epoch 00782: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4704e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 783/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2389e-06 - acc: 1.0000Epoch 00783: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1237e-06 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 784/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0615e-06 - acc: 1.0000Epoch 00784: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8684e-06 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 785/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1826e-06 - acc: 1.0000Epoch 00785: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.9607e-06 - acc: 1.0000 - val_loss: 9.3360e-04 - val_acc: 1.0000\n",
      "Epoch 786/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1667e-05 - acc: 1.0000Epoch 00786: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8194e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 787/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0569e-05 - acc: 1.0000Epoch 00787: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6309e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 788/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8225e-05 - acc: 1.0000Epoch 00788: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6960e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 789/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5685e-06 - acc: 1.0000Epoch 00789: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.1222e-06 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 790/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4370e-05 - acc: 1.0000Epoch 00790: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1543e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9949\n",
      "Epoch 791/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0635e-05 - acc: 1.0000Epoch 00791: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.9677e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 792/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.8879e-06 - acc: 1.0000Epoch 00792: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5354e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 793/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7612e-06 - acc: 1.0000Epoch 00793: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.0677e-06 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 794/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4786e-05 - acc: 1.0000Epoch 00794: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3897e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9949\n",
      "Epoch 795/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9369e-06 - acc: 1.0000Epoch 00795: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1317e-06 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9899\n",
      "Epoch 796/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9445e-04 - acc: 1.0000Epoch 00796: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7430e-04 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9949\n",
      "Epoch 797/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8404e-06 - acc: 1.0000Epoch 00797: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5320e-06 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9949\n",
      "Epoch 798/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1409e-05 - acc: 1.0000Epoch 00798: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 1.5164e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9949\n",
      "Epoch 799/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0510e-04 - acc: 1.0000Epoch 00799: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 1.9065e-04 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9949\n",
      "Epoch 800/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0006e-05 - acc: 1.0000Epoch 00800: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 3.1688e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 801/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8522e-05 - acc: 1.0000Epoch 00801: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.7312e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 802/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.4738e-05 - acc: 1.0000Epoch 00802: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.8229e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 803/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8150e-06 - acc: 1.0000Epoch 00803: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.1733e-06 - acc: 1.0000 - val_loss: 9.7113e-04 - val_acc: 1.0000\n",
      "Epoch 804/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1029e-06 - acc: 1.0000Epoch 00804: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5140e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 805/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0001e-05 - acc: 1.0000Epoch 00805: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.3288e-06 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 806/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6437e-06 - acc: 1.0000Epoch 00806: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.4039e-06 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 807/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3887e-04 - acc: 1.0000Epoch 00807: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2257e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9949\n",
      "Epoch 808/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9999e-06 - acc: 1.0000Epoch 00808: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5214e-06 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9949\n",
      "Epoch 809/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1575e-06 - acc: 1.0000Epoch 00809: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.0763e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9949\n",
      "Epoch 810/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0496e-06 - acc: 1.0000Epoch 00810: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.0645e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 811/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1274e-04 - acc: 1.0000Epoch 00811: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9080e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 812/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7364e-04 - acc: 1.0000Epoch 00812: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6217e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 813/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7384e-05 - acc: 1.0000Epoch 00813: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4913e-05 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 814/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9595e-05 - acc: 1.0000Epoch 00814: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.6957e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 815/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5950e-05 - acc: 1.0000Epoch 00815: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5046e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 816/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0391e-05 - acc: 1.0000Epoch 00816: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.7066e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 817/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6381e-05 - acc: 1.0000Epoch 00817: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4577e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 818/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9884e-05 - acc: 1.0000Epoch 00818: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8914e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 819/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2183e-06 - acc: 1.0000Epoch 00819: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0173e-06 - acc: 1.0000 - val_loss: 9.8800e-04 - val_acc: 1.0000\n",
      "Epoch 820/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3237e-06 - acc: 1.0000Epoch 00820: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.9981e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 821/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.0897e-06 - acc: 1.0000Epoch 00821: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.6127e-06 - acc: 1.0000 - val_loss: 5.1431e-04 - val_acc: 1.0000\n",
      "Epoch 822/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9104e-06 - acc: 1.0000Epoch 00822: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7263e-06 - acc: 1.0000 - val_loss: 2.5070e-04 - val_acc: 1.0000\n",
      "Epoch 823/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3549e-05 - acc: 1.0000Epoch 00823: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2646e-05 - acc: 1.0000 - val_loss: 8.7303e-04 - val_acc: 1.0000\n",
      "Epoch 824/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7153e-05 - acc: 1.0000Epoch 00824: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5985e-05 - acc: 1.0000 - val_loss: 1.3452e-04 - val_acc: 1.0000\n",
      "Epoch 825/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0581e-05 - acc: 1.0000Epoch 00825: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8375e-05 - acc: 1.0000 - val_loss: 5.6760e-04 - val_acc: 1.0000\n",
      "Epoch 826/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5384e-05 - acc: 1.0000Epoch 00826: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4306e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 827/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1533e-05 - acc: 1.0000Epoch 00827: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 1.0957e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9949\n",
      "Epoch 828/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4353e-05 - acc: 1.0000Epoch 00828: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3419e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 829/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9251e-05 - acc: 1.0000Epoch 00829: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4463e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 830/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1480e-06 - acc: 1.0000Epoch 00830: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8850e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 831/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5275e-06 - acc: 1.0000Epoch 00831: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4514e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 832/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3889e-05 - acc: 1.0000Epoch 00832: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2354e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 833/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8923e-05 - acc: 1.0000Epoch 00833: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4710e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 834/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7612e-06 - acc: 1.0000Epoch 00834: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4393e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 835/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2806e-06 - acc: 1.0000Epoch 00835: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1295e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 836/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8395e-06 - acc: 1.0000Epoch 00836: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.4953e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 837/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5151e-06 - acc: 1.0000Epoch 00837: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.0092e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 838/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8936e-05 - acc: 1.0000Epoch 00838: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6989e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 839/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8448e-06 - acc: 1.0000Epoch 00839: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6927e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 840/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9954e-06 - acc: 1.0000Epoch 00840: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6654e-06 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9949\n",
      "Epoch 841/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1582e-06 - acc: 1.0000Epoch 00841: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.3028e-06 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 0.9949\n",
      "Epoch 842/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9020e-05 - acc: 1.0000Epoch 00842: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7775e-05 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9949\n",
      "Epoch 843/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0392e-05 - acc: 1.0000Epoch 00843: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.6867e-06 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9949\n",
      "Epoch 844/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7068e-04 - acc: 1.0000Epoch 00844: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.3037e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 845/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6621e-05 - acc: 1.0000Epoch 00845: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4829e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 846/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7420e-05 - acc: 1.0000Epoch 00846: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0238e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 847/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4233e-05 - acc: 1.0000Epoch 00847: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9776e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 848/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.1790e-06 - acc: 1.0000Epoch 00848: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.1156e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 849/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0981e-04 - acc: 1.0000Epoch 00849: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7539e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 850/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7340e-06 - acc: 1.0000Epoch 00850: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5756e-06 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9949\n",
      "Epoch 851/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1176e-05 - acc: 1.0000Epoch 00851: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.2098e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 852/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4927e-05 - acc: 1.0000Epoch 00852: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.4103e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 853/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7437e-04 - acc: 1.0000Epoch 00853: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6279e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 854/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8890e-06 - acc: 1.0000Epoch 00854: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.8395e-06 - acc: 1.0000 - val_loss: 7.2173e-04 - val_acc: 1.0000\n",
      "Epoch 855/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.1111e-05 - acc: 1.0000Epoch 00855: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.5406e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 856/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3039e-05 - acc: 1.0000Epoch 00856: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2198e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 857/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.2626e-06 - acc: 1.0000Epoch 00857: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.2978e-06 - acc: 1.0000 - val_loss: 8.4683e-04 - val_acc: 1.0000\n",
      "Epoch 858/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7552e-04 - acc: 1.0000Epoch 00858: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6359e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 859/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7001e-05 - acc: 1.0000Epoch 00859: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8523e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 860/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2809e-05 - acc: 1.0000Epoch 00860: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1941e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 861/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0634e-06 - acc: 1.0000Epoch 00861: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 1.0674e-06 - acc: 1.0000 - val_loss: 8.3954e-04 - val_acc: 1.0000\n",
      "Epoch 862/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0033e-06 - acc: 1.0000Epoch 00862: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3460e-06 - acc: 1.0000 - val_loss: 6.6872e-04 - val_acc: 1.0000\n",
      "Epoch 863/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0500e-05 - acc: 1.0000Epoch 00863: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9091e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 864/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9152e-04 - acc: 1.0000Epoch 00864: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.6391e-04 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9949\n",
      "Epoch 865/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6475e-06 - acc: 1.0000Epoch 00865: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5634e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 866/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0362e-06 - acc: 1.0000Epoch 00866: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6614e-06 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 0.9949\n",
      "Epoch 867/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7859e-06 - acc: 1.0000Epoch 00867: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.1753e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 868/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5502e-06 - acc: 1.0000Epoch 00868: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3284e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 869/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2098e-05 - acc: 1.0000Epoch 00869: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9875e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 870/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5953e-06 - acc: 1.0000Epoch 00870: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0445e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 871/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3674e-05 - acc: 1.0000Epoch 00871: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2388e-05 - acc: 1.0000 - val_loss: 8.2905e-04 - val_acc: 1.0000\n",
      "Epoch 872/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3787e-06 - acc: 1.0000Epoch 00872: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1364e-06 - acc: 1.0000 - val_loss: 3.8361e-04 - val_acc: 1.0000\n",
      "Epoch 873/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5668e-04 - acc: 1.0000Epoch 00873: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 1.4563e-04 - acc: 1.0000 - val_loss: 3.6475e-04 - val_acc: 1.0000\n",
      "Epoch 874/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5614e-06 - acc: 1.0000Epoch 00874: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 3.3188e-06 - acc: 1.0000 - val_loss: 3.6627e-04 - val_acc: 1.0000\n",
      "Epoch 875/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2852e-05 - acc: 1.0000Epoch 00875: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2220e-05 - acc: 1.0000 - val_loss: 5.3063e-04 - val_acc: 1.0000\n",
      "Epoch 876/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5024e-04 - acc: 1.0000Epoch 00876: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3304e-04 - acc: 1.0000 - val_loss: 5.1462e-04 - val_acc: 1.0000\n",
      "Epoch 877/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5687e-05 - acc: 1.0000Epoch 00877: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8629e-05 - acc: 1.0000 - val_loss: 8.3579e-04 - val_acc: 1.0000\n",
      "Epoch 878/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0342e-05 - acc: 1.0000Epoch 00878: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6797e-04 - acc: 1.0000 - val_loss: 8.7310e-04 - val_acc: 1.0000\n",
      "Epoch 879/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8143e-05 - acc: 1.0000Epoch 00879: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0549e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 880/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2571e-06 - acc: 1.0000Epoch 00880: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.3009e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 881/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.3734e-06 - acc: 1.0000Epoch 00881: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.9015e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 882/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1369e-06 - acc: 1.0000Epoch 00882: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4737e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 883/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0413e-05 - acc: 1.0000Epoch 00883: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9192e-05 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9949\n",
      "Epoch 884/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1621e-06 - acc: 1.0000Epoch 00884: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0119e-06 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9949\n",
      "Epoch 885/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5064e-04 - acc: 1.0000Epoch 00885: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4005e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9949\n",
      "Epoch 886/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.4839e-06 - acc: 1.0000Epoch 00886: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1857e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 887/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.9909e-07 - acc: 1.0000Epoch 00887: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.4975e-07 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 888/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0147e-04 - acc: 1.0000Epoch 00888: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.4359e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 889/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3430e-06 - acc: 1.0000Epoch 00889: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.9494e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 890/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7272e-06 - acc: 1.0000Epoch 00890: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4664e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 891/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4994e-05 - acc: 1.0000Epoch 00891: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2588e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 892/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5523e-06 - acc: 1.0000Epoch 00892: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.0976e-06 - acc: 1.0000 - val_loss: 8.2869e-04 - val_acc: 1.0000\n",
      "Epoch 893/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8290e-04 - acc: 1.0000Epoch 00893: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6395e-04 - acc: 1.0000 - val_loss: 5.0020e-04 - val_acc: 1.0000\n",
      "Epoch 894/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7152e-05 - acc: 1.0000Epoch 00894: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7029e-05 - acc: 1.0000 - val_loss: 5.5458e-04 - val_acc: 1.0000\n",
      "Epoch 895/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0538e-05 - acc: 1.0000Epoch 00895: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8395e-05 - acc: 1.0000 - val_loss: 3.0832e-04 - val_acc: 1.0000\n",
      "Epoch 896/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1517e-05 - acc: 1.0000Epoch 00896: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0752e-05 - acc: 1.0000 - val_loss: 2.2361e-04 - val_acc: 1.0000\n",
      "Epoch 897/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2379e-06 - acc: 1.0000Epoch 00897: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.6671e-06 - acc: 1.0000 - val_loss: 4.3044e-04 - val_acc: 1.0000\n",
      "Epoch 898/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1655e-05 - acc: 1.0000Epoch 00898: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 4.8267e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 899/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9604e-06 - acc: 1.0000Epoch 00899: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9196e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 900/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9245e-06 - acc: 1.0000Epoch 00900: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 6.6101e-06 - acc: 1.0000 - val_loss: 5.2527e-04 - val_acc: 1.0000\n",
      "Epoch 901/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6004e-06 - acc: 1.0000Epoch 00901: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 3.4072e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 902/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9394e-05 - acc: 1.0000Epoch 00902: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 3.7150e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 903/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9519e-06 - acc: 1.0000Epoch 00903: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 8.3753e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 904/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3611e-05 - acc: 1.0000Epoch 00904: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.2684e-05 - acc: 1.0000 - val_loss: 7.5255e-04 - val_acc: 1.0000\n",
      "Epoch 905/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.8284e-05 - acc: 1.0000Epoch 00905: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.2193e-05 - acc: 1.0000 - val_loss: 6.2265e-04 - val_acc: 1.0000\n",
      "Epoch 906/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9972e-06 - acc: 1.0000Epoch 00906: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0694e-06 - acc: 1.0000 - val_loss: 4.2800e-04 - val_acc: 1.0000\n",
      "Epoch 907/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1505e-06 - acc: 1.0000Epoch 00907: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0308e-06 - acc: 1.0000 - val_loss: 4.1099e-04 - val_acc: 1.0000\n",
      "Epoch 908/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1099e-06 - acc: 1.0000Epoch 00908: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.6610e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 909/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9541e-04 - acc: 1.0000Epoch 00909: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8161e-04 - acc: 1.0000 - val_loss: 3.9109e-04 - val_acc: 1.0000\n",
      "Epoch 910/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.8588e-05 - acc: 1.0000Epoch 00910: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.1626e-05 - acc: 1.0000 - val_loss: 9.6828e-04 - val_acc: 1.0000\n",
      "Epoch 911/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8203e-06 - acc: 1.0000Epoch 00911: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6367e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 912/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3571e-06 - acc: 1.0000Epoch 00912: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3133e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 913/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5904e-06 - acc: 1.0000Epoch 00913: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.5356e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 914/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2600e-06 - acc: 1.0000Epoch 00914: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 4.9099e-06 - acc: 1.0000 - val_loss: 4.8673e-04 - val_acc: 1.0000\n",
      "Epoch 915/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4776e-04 - acc: 1.0000Epoch 00915: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 1.3737e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 916/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1208e-05 - acc: 1.0000Epoch 00916: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 1.0446e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 917/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3080e-05 - acc: 1.0000Epoch 00917: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 1.2225e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 918/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4961e-06 - acc: 1.0000Epoch 00918: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 6.0678e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 919/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2666e-05 - acc: 1.0000Epoch 00919: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 4.8985e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 920/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1237e-06 - acc: 1.0000Epoch 00920: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 2.9372e-06 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 921/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7498e-06 - acc: 1.0000Epoch 00921: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 8.1870e-06 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9949\n",
      "Epoch 922/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0061 - acc: 0.9986    Epoch 00922: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0069 - val_acc: 0.9949\n",
      "Epoch 923/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0013 - acc: 0.9986Epoch 00923: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.9987 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 924/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4668e-05 - acc: 1.0000Epoch 00924: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5487e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 925/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.4334e-04 - acc: 1.0000Epoch 00925: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.9079e-04 - acc: 1.0000 - val_loss: 9.8757e-04 - val_acc: 1.0000\n",
      "Epoch 926/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7824e-05 - acc: 1.0000Epoch 00926: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.5941e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 927/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6059e-06 - acc: 1.0000Epoch 00927: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3895e-06 - acc: 1.0000 - val_loss: 6.1921e-04 - val_acc: 1.0000\n",
      "Epoch 928/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.0129e-06 - acc: 1.0000Epoch 00928: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9128e-05 - acc: 1.0000 - val_loss: 9.5708e-04 - val_acc: 1.0000\n",
      "Epoch 929/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9468e-06 - acc: 1.0000Epoch 00929: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6089e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 930/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2394e-04 - acc: 1.0000Epoch 00930: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 2.0814e-04 - acc: 1.0000 - val_loss: 6.9983e-04 - val_acc: 1.0000\n",
      "Epoch 931/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7189e-06 - acc: 1.0000Epoch 00931: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7674e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 932/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2557e-06 - acc: 1.0000Epoch 00932: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 4.9856e-06 - acc: 1.0000 - val_loss: 5.8778e-04 - val_acc: 1.0000\n",
      "Epoch 933/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5294e-06 - acc: 1.0000Epoch 00933: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.4906e-06 - acc: 1.0000 - val_loss: 7.8658e-04 - val_acc: 1.0000\n",
      "Epoch 934/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4217e-06 - acc: 1.0000Epoch 00934: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.5555e-06 - acc: 1.0000 - val_loss: 5.8338e-04 - val_acc: 1.0000\n",
      "Epoch 935/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7206e-05 - acc: 1.0000Epoch 00935: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 2.5308e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 936/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4086e-05 - acc: 1.0000Epoch 00936: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 5.9593e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 937/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6562e-06 - acc: 1.0000Epoch 00937: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.0757e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 938/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6998e-05 - acc: 1.0000Epoch 00938: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.5818e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 939/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0007e-05 - acc: 1.0000Epoch 00939: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 9.3582e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 940/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.0747e-06 - acc: 1.0000Epoch 00940: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 8.4472e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 941/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6300e-05 - acc: 1.0000Epoch 00941: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0578e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 942/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0777e-04 - acc: 1.0000Epoch 00942: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8640e-04 - acc: 1.0000 - val_loss: 6.7628e-04 - val_acc: 1.0000\n",
      "Epoch 943/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9743e-04 - acc: 1.0000Epoch 00943: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7660e-04 - acc: 1.0000 - val_loss: 6.7300e-04 - val_acc: 1.0000\n",
      "Epoch 944/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1940e-04 - acc: 1.0000Epoch 00944: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9691e-04 - acc: 1.0000 - val_loss: 8.6677e-04 - val_acc: 1.0000\n",
      "Epoch 945/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6473e-05 - acc: 1.0000Epoch 00945: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4535e-05 - acc: 1.0000 - val_loss: 8.4431e-04 - val_acc: 1.0000\n",
      "Epoch 946/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3824e-06 - acc: 1.0000Epoch 00946: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.2013e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 947/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5841e-05 - acc: 1.0000Epoch 00947: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4763e-05 - acc: 1.0000 - val_loss: 7.3574e-04 - val_acc: 1.0000\n",
      "Epoch 948/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8598e-06 - acc: 1.0000Epoch 00948: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.6350e-06 - acc: 1.0000 - val_loss: 7.7724e-04 - val_acc: 1.0000\n",
      "Epoch 949/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0962e-06 - acc: 1.0000Epoch 00949: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3626e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 950/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0666e-04 - acc: 1.0000Epoch 00950: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.9183e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 951/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5017e-05 - acc: 1.0000Epoch 00951: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3058e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 952/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5829e-05 - acc: 1.0000Epoch 00952: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.2617e-05 - acc: 1.0000 - val_loss: 5.3377e-04 - val_acc: 1.0000\n",
      "Epoch 953/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9787e-06 - acc: 1.0000Epoch 00953: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.4758e-06 - acc: 1.0000 - val_loss: 9.0576e-04 - val_acc: 1.0000\n",
      "Epoch 954/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0569e-06 - acc: 1.0000Epoch 00954: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1774e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 955/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0680e-05 - acc: 1.0000Epoch 00955: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5704e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 956/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0461e-04 - acc: 1.0000Epoch 00956: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9016e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 957/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1936e-06 - acc: 1.0000Epoch 00957: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.9110e-06 - acc: 1.0000 - val_loss: 9.3495e-04 - val_acc: 1.0000\n",
      "Epoch 958/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1904e-05 - acc: 1.0000Epoch 00958: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.9433e-05 - acc: 1.0000 - val_loss: 7.0830e-04 - val_acc: 1.0000\n",
      "Epoch 959/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7744e-06 - acc: 1.0000Epoch 00959: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8312e-06 - acc: 1.0000 - val_loss: 5.2003e-04 - val_acc: 1.0000\n",
      "Epoch 960/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8187e-06 - acc: 1.0000Epoch 00960: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.2947e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 961/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7054e-05 - acc: 1.0000Epoch 00961: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 3.4466e-05 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 962/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5591e-06 - acc: 1.0000Epoch 00962: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3536e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 963/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0014 - acc: 0.9986    Epoch 00963: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.9987 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 964/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6027e-06 - acc: 1.0000Epoch 00964: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.3155e-06 - acc: 1.0000 - val_loss: 8.2602e-04 - val_acc: 1.0000\n",
      "Epoch 965/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2770e-05 - acc: 1.0000Epoch 00965: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 3.1368e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 966/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3294e-05 - acc: 1.0000Epoch 00966: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1141e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 967/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1606e-05 - acc: 1.0000Epoch 00967: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0801e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 968/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7449e-05 - acc: 1.0000Epoch 00968: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4204e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 969/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1466e-04 - acc: 1.0000Epoch 00969: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.9957e-04 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9949\n",
      "Epoch 970/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6569e-05 - acc: 1.0000Epoch 00970: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 2.4709e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 971/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5487e-06 - acc: 1.0000Epoch 00971: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 7.0579e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 972/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9868e-06 - acc: 1.0000Epoch 00972: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8029e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 973/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7670e-04 - acc: 1.0000Epoch 00973: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6440e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 974/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6315e-06 - acc: 1.0000Epoch 00974: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6305e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 975/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4351e-07 - acc: 1.0000Epoch 00975: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3387e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 976/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1849e-06 - acc: 1.0000Epoch 00976: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3740e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 977/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0708e-06 - acc: 1.0000Epoch 00977: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1581e-06 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 978/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.6230e-07 - acc: 1.0000- ETA: 0s - loss: 5.9499e-07 - accEpoch 00978: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 9.0765e-07 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 979/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9449e-04 - acc: 1.0000Epoch 00979: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 4.5962e-04 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 980/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.7493e-06 - acc: 1.0000Epoch 00980: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.3914e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 981/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0295e-05 - acc: 1.0000Epoch 00981: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8900e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 982/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3210e-06 - acc: 1.0000Epoch 00982: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 6.5503e-06 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 983/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9679e-05 - acc: 1.0000Epoch 00983: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 2.0754e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 984/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.8297e-05 - acc: 1.0000Epoch 00984: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 9.1405e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 985/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1423e-05 - acc: 1.0000Epoch 00985: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.2003e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 986/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9325e-05 - acc: 1.0000Epoch 00986: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.5141e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 987/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.3247e-06 - acc: 1.0000Epoch 00987: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 8.7054e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 988/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5557e-06 - acc: 1.0000Epoch 00988: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 2.3880e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 989/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2395e-05 - acc: 1.0000Epoch 00989: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 6.4774e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 990/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.4439e-06 - acc: 1.0000Epoch 00990: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 7.8833e-06 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 991/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2509e-06 - acc: 1.0000Epoch 00991: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2006e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 992/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3011e-05 - acc: 1.0000Epoch 00992: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1642e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 993/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7831e-05 - acc: 1.0000Epoch 00993: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.7765e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 994/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7051e-06 - acc: 1.0000Epoch 00994: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 4.6672e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 995/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9526e-06 - acc: 1.0000Epoch 00995: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 5.5505e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 996/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6617e-06 - acc: 1.0000Epoch 00996: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 5.3730e-06 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 997/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1806e-04 - acc: 1.0000Epoch 00997: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 2.0272e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 998/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9475e-06 - acc: 1.0000Epoch 00998: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 8.8120e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 999/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7967e-05 - acc: 1.0000Epoch 00999: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.6705e-05 - acc: 1.0000 - val_loss: 7.7685e-04 - val_acc: 1.0000\n",
      "Epoch 1000/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0943e-06 - acc: 1.0000Epoch 01000: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 3.8294e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1001/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1564e-06 - acc: 1.0000Epoch 01001: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 2.0494e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1002/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3926e-06 - acc: 1.0000Epoch 01002: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3077e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1003/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2073e-05 - acc: 1.0000Epoch 01003: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.9461e-05 - acc: 1.0000 - val_loss: 5.5843e-04 - val_acc: 1.0000\n",
      "Epoch 1004/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9934e-06 - acc: 1.0000Epoch 01004: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8816e-06 - acc: 1.0000 - val_loss: 9.5326e-04 - val_acc: 1.0000\n",
      "Epoch 1005/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6065e-06 - acc: 1.0000Epoch 01005: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.0998e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1006/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2676e-06 - acc: 1.0000Epoch 01006: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 3.0558e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1007/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3343e-04 - acc: 1.0000Epoch 01007: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 4.9577e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1008/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.6390e-07 - acc: 1.0000Epoch 01008: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.0139e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1009/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.8003e-05 - acc: 1.0000Epoch 01009: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4962e-05 - acc: 1.0000 - val_loss: 9.5909e-04 - val_acc: 1.0000\n",
      "Epoch 1010/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5430e-06 - acc: 1.0000Epoch 01010: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.2306e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1011/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6563e-06 - acc: 1.0000Epoch 01011: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 8.0544e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1012/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0579e-06 - acc: 1.0000Epoch 01012: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 4.7187e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1013/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6712e-05 - acc: 1.0000Epoch 01013: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 2.6153e-05 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9949\n",
      "Epoch 1014/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6167e-05 - acc: 1.0000Epoch 01014: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 3.4336e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1015/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7409e-05 - acc: 1.0000Epoch 01015: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 4.8164e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9949\n",
      "Epoch 1016/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4428e-06 - acc: 1.0000Epoch 01016: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 4.1923e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1017/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8575e-05 - acc: 1.0000Epoch 01017: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.7336e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1018/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9309e-06 - acc: 1.0000Epoch 01018: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9144e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1019/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1860e-05 - acc: 1.0000Epoch 01019: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 2.0384e-05 - acc: 1.0000 - val_loss: 5.4938e-04 - val_acc: 1.0000\n",
      "Epoch 1020/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7893e-05 - acc: 1.0000Epoch 01020: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 2.6036e-05 - acc: 1.0000 - val_loss: 7.3436e-04 - val_acc: 1.0000\n",
      "Epoch 1021/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3457e-06 - acc: 1.0000Epoch 01021: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 3.2328e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1022/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2463e-05 - acc: 1.0000Epoch 01022: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 3.0186e-05 - acc: 1.0000 - val_loss: 8.1888e-04 - val_acc: 1.0000\n",
      "Epoch 1023/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.7070e-05 - acc: 1.0000Epoch 01023: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 9.0236e-05 - acc: 1.0000 - val_loss: 9.7605e-04 - val_acc: 1.0000\n",
      "Epoch 1024/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7081e-06 - acc: 1.0000Epoch 01024: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 3.7001e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1025/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.0919e-06 - acc: 1.0000Epoch 01025: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 7.6418e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1026/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0089 - acc: 0.9986Epoch 01026: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 0.0082 - acc: 0.9987 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 1027/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.8885e-07 - acc: 1.0000Epoch 01027: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 9.4263e-07 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1028/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5900e-05 - acc: 1.0000Epoch 01028: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 1.4797e-05 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9949\n",
      "Epoch 1029/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5722e-06 - acc: 1.0000Epoch 01029: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 4.3090e-06 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9949\n",
      "Epoch 1030/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1622e-06 - acc: 1.0000Epoch 01030: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 6.6739e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1031/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2732e-05 - acc: 1.0000Epoch 01031: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 3.0438e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1032/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4966e-05 - acc: 1.0000Epoch 01032: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3220e-05 - acc: 1.0000 - val_loss: 9.6334e-04 - val_acc: 1.0000\n",
      "Epoch 1033/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2931e-05 - acc: 1.0000Epoch 01033: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.2037e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1034/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1960e-05 - acc: 1.0000Epoch 01034: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 6.7390e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1035/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9706e-05 - acc: 1.0000Epoch 01035: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.8324e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1036/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1762e-04 - acc: 1.0000Epoch 01036: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0280e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1037/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3050e-05 - acc: 1.0000Epoch 01037: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4233e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1038/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5888e-05 - acc: 1.0000Epoch 01038: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3571e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1039/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9759e-05 - acc: 1.0000Epoch 01039: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9175e-05 - acc: 1.0000 - val_loss: 7.0557e-04 - val_acc: 1.0000\n",
      "Epoch 1040/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.4096e-06 - acc: 1.0000Epoch 01040: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.9311e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1041/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.6935e-06 - acc: 1.0000Epoch 01041: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2106e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1042/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0870e-05 - acc: 1.0000Epoch 01042: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 3.7996e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1043/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.1723e-07 - acc: 1.0000Epoch 01043: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 1.1374e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1044/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5415e-05 - acc: 1.0000Epoch 01044: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 2.3829e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1045/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9354e-05 - acc: 1.0000Epoch 01045: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 6.4490e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1046/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8494e-05 - acc: 1.0000Epoch 01046: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 3.5952e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1047/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4637e-04 - acc: 1.0000Epoch 01047: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 2.2899e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1048/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1290e-05 - acc: 1.0000Epoch 01048: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.9920e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1049/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0783e-06 - acc: 1.0000Epoch 01049: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 3.8280e-06 - acc: 1.0000 - val_loss: 5.6723e-04 - val_acc: 1.0000\n",
      "Epoch 1050/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1174e-06 - acc: 1.0000Epoch 01050: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 2.5354e-06 - acc: 1.0000 - val_loss: 7.6194e-04 - val_acc: 1.0000\n",
      "Epoch 1051/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6612e-05 - acc: 1.0000Epoch 01051: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 2.4993e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1052/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8632e-06 - acc: 1.0000Epoch 01052: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 2.9330e-06 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 1053/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9137e-04 - acc: 1.0000Epoch 01053: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 5.4957e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1054/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8191e-06 - acc: 1.0000- ETA: 0s - loss: 1.2309e-05 - accEpoch 01054: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 5.4257e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1055/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6655e-06 - acc: 1.0000Epoch 01055: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2761e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1056/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1170e-05 - acc: 1.0000Epoch 01056: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0399e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1057/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4593e-06 - acc: 1.0000- ETA: 0s - loss: 5.4355e-06 - accEpoch 01057: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 2.2984e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1058/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7622e-06 - acc: 1.0000Epoch 01058: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 1.6566e-06 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1059/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3439e-04 - acc: 1.0000Epoch 01059: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 3.1078e-04 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 0.9949\n",
      "Epoch 1060/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3922e-06 - acc: 1.0000Epoch 01060: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 3.2823e-06 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 0.9949\n",
      "Epoch 1061/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0948e-06 - acc: 1.0000Epoch 01061: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 2.2203e-06 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9899\n",
      "Epoch 1062/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6912e-07 - acc: 1.0000Epoch 01062: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 6.8194e-07 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9949\n",
      "Epoch 1063/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4173e-06 - acc: 1.0000Epoch 01063: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 6.6053e-06 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9949\n",
      "Epoch 1064/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1071e-06 - acc: 1.0000Epoch 01064: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 6.6143e-06 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9949\n",
      "Epoch 1065/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.4562e-06 - acc: 1.0000Epoch 01065: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.0675e-06 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9949\n",
      "Epoch 1066/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4252e-06 - acc: 1.0000Epoch 01066: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4468e-06 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9949\n",
      "Epoch 1067/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6910e-06 - acc: 1.0000Epoch 01067: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6034e-06 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9949\n",
      "Epoch 1068/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6997e-05 - acc: 1.0000Epoch 01068: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4638e-05 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 1069/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2951e-06 - acc: 1.0000Epoch 01069: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0861e-06 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 1070/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4843e-05 - acc: 1.0000Epoch 01070: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4151e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1071/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0499e-06 - acc: 1.0000Epoch 01071: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3502e-06 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 1072/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9927e-05 - acc: 1.0000Epoch 01072: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.5702e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1073/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0301e-06 - acc: 1.0000Epoch 01073: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8989e-06 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9949\n",
      "Epoch 1074/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3056e-06 - acc: 1.0000Epoch 01074: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1173e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1075/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7095e-06 - acc: 1.0000Epoch 01075: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7984e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1076/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2551e-06 - acc: 1.0000Epoch 01076: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 2.1924e-06 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9949\n",
      "Epoch 1077/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2568e-06 - acc: 1.0000Epoch 01077: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.9641e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1078/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1028e-06 - acc: 1.0000Epoch 01078: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5295e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1079/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1766e-05 - acc: 1.0000Epoch 01079: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 1.2157e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1080/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4170e-05 - acc: 1.0000Epoch 01080: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.1051e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9949\n",
      "Epoch 1081/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9425e-06 - acc: 1.0000Epoch 01081: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8069e-06 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9949\n",
      "Epoch 1082/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0641e-05 - acc: 1.0000Epoch 01082: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0770e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9949\n",
      "Epoch 1083/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7932e-05 - acc: 1.0000Epoch 01083: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.6677e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1084/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4493e-05 - acc: 1.0000Epoch 01084: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1736e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1085/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.7350e-05 - acc: 1.0000Epoch 01085: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 7.2295e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1086/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0010e-05 - acc: 1.0000Epoch 01086: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 9.3751e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1087/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6871e-06 - acc: 1.0000Epoch 01087: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.5836e-06 - acc: 1.0000 - val_loss: 9.0268e-04 - val_acc: 1.0000\n",
      "Epoch 1088/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3863e-06 - acc: 1.0000Epoch 01088: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 2.3123e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1089/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8913e-05 - acc: 1.0000Epoch 01089: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 5.4901e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 1090/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3668e-06 - acc: 1.0000Epoch 01090: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 5.0203e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1091/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6517e-06 - acc: 1.0000Epoch 01091: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.5839e-06 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9949\n",
      "Epoch 1092/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0745e-05 - acc: 1.0000Epoch 01092: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.0025e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1093/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3291e-06 - acc: 1.0000Epoch 01093: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2578e-06 - acc: 1.0000 - val_loss: 9.9758e-04 - val_acc: 1.0000\n",
      "Epoch 1094/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1429e-05 - acc: 1.0000Epoch 01094: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0653e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1095/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5453e-05 - acc: 1.0000Epoch 01095: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.4547e-05 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9949\n",
      "Epoch 1096/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8746e-05 - acc: 1.0000Epoch 01096: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.7846e-05 - acc: 1.0000 - val_loss: 9.4329e-04 - val_acc: 1.0000\n",
      "Epoch 1097/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3373e-06 - acc: 1.0000Epoch 01097: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 7.6042e-06 - acc: 1.0000 - val_loss: 9.4243e-04 - val_acc: 1.0000\n",
      "Epoch 1098/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5382e-05 - acc: 1.0000Epoch 01098: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3598e-05 - acc: 1.0000 - val_loss: 4.8173e-04 - val_acc: 1.0000\n",
      "Epoch 1099/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6498e-06 - acc: 1.0000Epoch 01099: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 1.5446e-06 - acc: 1.0000 - val_loss: 4.6217e-04 - val_acc: 1.0000\n",
      "Epoch 1100/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4863e-06 - acc: 1.0000Epoch 01100: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 2.3385e-06 - acc: 1.0000 - val_loss: 9.3554e-04 - val_acc: 1.0000\n",
      "Epoch 1101/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.4404e-06 - acc: 1.0000Epoch 01101: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 7.9468e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1102/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8584e-05 - acc: 1.0000Epoch 01102: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7451e-05 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9949\n",
      "Epoch 1103/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1250e-04 - acc: 1.0000Epoch 01103: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.9756e-04 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 1104/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3041e-05 - acc: 1.0000Epoch 01104: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.9338e-05 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9949\n",
      "Epoch 1105/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3494e-04 - acc: 1.0000Epoch 01105: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2541e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9949\n",
      "Epoch 1106/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1069e-06 - acc: 1.0000Epoch 01106: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0464e-06 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 1107/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6254e-06 - acc: 1.0000Epoch 01107: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5738e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1108/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8310e-05 - acc: 1.0000Epoch 01108: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6323e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1109/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1675e-06 - acc: 1.0000Epoch 01109: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5732e-06 - acc: 1.0000 - val_loss: 3.6787e-04 - val_acc: 1.0000\n",
      "Epoch 1110/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3258e-05 - acc: 1.0000Epoch 01110: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2494e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1111/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.0576e-07 - acc: 1.0000Epoch 01111: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.8160e-07 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 1112/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4061e-06 - acc: 1.0000Epoch 01112: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 1.3200e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1113/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3279e-06 - acc: 1.0000Epoch 01113: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 5.4911e-05 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 0.9899\n",
      "Epoch 1114/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7667e-05 - acc: 1.0000Epoch 01114: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 2.5944e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9949\n",
      "Epoch 1115/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2419e-05 - acc: 1.0000Epoch 01115: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0887e-05 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9949\n",
      "Epoch 1116/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.4723e-06 - acc: 1.0000Epoch 01116: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2937e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1117/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2388e-07 - acc: 1.0000Epoch 01117: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.8745e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1118/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9519e-06 - acc: 1.0000Epoch 01118: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 6.4785e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1119/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6235e-05 - acc: 1.0000Epoch 01119: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2446e-05 - acc: 1.0000 - val_loss: 5.4680e-04 - val_acc: 1.0000\n",
      "Epoch 1120/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0143e-05 - acc: 1.0000Epoch 01120: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.4377e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1121/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7243e-05 - acc: 1.0000Epoch 01121: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6037e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1122/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0143e-05 - acc: 1.0000Epoch 01122: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1513e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1123/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3013e-06 - acc: 1.0000Epoch 01123: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1738e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 1124/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3198e-04 - acc: 1.0000Epoch 01124: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2273e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1125/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2746e-06 - acc: 1.0000Epoch 01125: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.7058e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1126/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9867e-06 - acc: 1.0000Epoch 01126: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7883e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1127/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4233e-05 - acc: 1.0000Epoch 01127: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3913e-05 - acc: 1.0000 - val_loss: 2.3001e-04 - val_acc: 1.0000\n",
      "Epoch 1128/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1134e-05 - acc: 1.0000Epoch 01128: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8967e-05 - acc: 1.0000 - val_loss: 1.5644e-04 - val_acc: 1.0000\n",
      "Epoch 1129/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9886e-06 - acc: 1.0000Epoch 01129: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8811e-06 - acc: 1.0000 - val_loss: 1.4907e-04 - val_acc: 1.0000\n",
      "Epoch 1130/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1230e-06 - acc: 1.0000Epoch 01130: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.4772e-05 - acc: 1.0000 - val_loss: 1.4382e-04 - val_acc: 1.0000\n",
      "Epoch 1131/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2330e-05 - acc: 1.0000Epoch 01131: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.1483e-05 - acc: 1.0000 - val_loss: 1.2753e-04 - val_acc: 1.0000\n",
      "Epoch 1132/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0439e-06 - acc: 1.0000Epoch 01132: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 4.7241e-06 - acc: 1.0000 - val_loss: 1.6440e-04 - val_acc: 1.0000\n",
      "Epoch 1133/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7347e-05 - acc: 1.0000Epoch 01133: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 2.5467e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1134/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.8574e-06 - acc: 1.0000Epoch 01134: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 9.1725e-06 - acc: 1.0000 - val_loss: 7.3302e-04 - val_acc: 1.0000\n",
      "Epoch 1135/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2914e-06 - acc: 1.0000Epoch 01135: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1937e-06 - acc: 1.0000 - val_loss: 7.2523e-04 - val_acc: 1.0000\n",
      "Epoch 1136/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7963e-04 - acc: 1.0000Epoch 01136: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 5.3868e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1137/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8637e-06 - acc: 1.0000Epoch 01137: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 1.7459e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1138/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2941e-05 - acc: 1.0000Epoch 01138: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.2129e-05 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9949\n",
      "Epoch 1139/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9838e-06 - acc: 1.0000Epoch 01139: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.1499e-05 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9949\n",
      "Epoch 1140/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.0012e-04 - acc: 1.0000Epoch 01140: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.3675e-04 - acc: 1.0000 - val_loss: 9.7396e-04 - val_acc: 1.0000\n",
      "Epoch 1141/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0695e-06 - acc: 1.0000Epoch 01141: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.3539e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1142/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5018e-05 - acc: 1.0000Epoch 01142: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 2.3303e-05 - acc: 1.0000 - val_loss: 8.9692e-04 - val_acc: 1.0000\n",
      "Epoch 1143/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1571e-05 - acc: 1.0000Epoch 01143: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 1.0825e-05 - acc: 1.0000 - val_loss: 9.1366e-04 - val_acc: 1.0000\n",
      "Epoch 1144/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1554e-05 - acc: 1.0000Epoch 01144: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 1.0763e-05 - acc: 1.0000 - val_loss: 1.5243e-04 - val_acc: 1.0000\n",
      "Epoch 1145/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3220e-06 - acc: 1.0000Epoch 01145: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 5.9226e-06 - acc: 1.0000 - val_loss: 3.1760e-04 - val_acc: 1.0000\n",
      "Epoch 1146/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5949e-06 - acc: 1.0000Epoch 01146: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 6.1626e-06 - acc: 1.0000 - val_loss: 3.1899e-04 - val_acc: 1.0000\n",
      "Epoch 1147/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5165e-06 - acc: 1.0000Epoch 01147: val_loss did not improve\n",
      "792/792 [==============================] - 1s 966us/step - loss: 3.3290e-06 - acc: 1.0000 - val_loss: 8.3162e-04 - val_acc: 1.0000\n",
      "Epoch 1148/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9998e-06 - acc: 1.0000Epoch 01148: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 6.5665e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1149/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6377e-06 - acc: 1.0000Epoch 01149: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 2.4652e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 1150/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6046e-06 - acc: 1.0000Epoch 01150: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 2.5816e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 1151/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2227e-06 - acc: 1.0000Epoch 01151: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.9054e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1152/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7812e-06 - acc: 1.0000Epoch 01152: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3633e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1153/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4230e-06 - acc: 1.0000Epoch 01153: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5113e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1154/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6852e-06 - acc: 1.0000Epoch 01154: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.3346e-06 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 1155/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9958e-06 - acc: 1.0000Epoch 01155: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 5.6021e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1156/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3846e-05 - acc: 1.0000Epoch 01156: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.2975e-05 - acc: 1.0000 - val_loss: 9.1402e-04 - val_acc: 1.0000\n",
      "Epoch 1157/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7595e-07 - acc: 1.0000Epoch 01157: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.0442e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1158/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7225e-06 - acc: 1.0000Epoch 01158: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4331e-06 - acc: 1.0000 - val_loss: 4.2650e-04 - val_acc: 1.0000\n",
      "Epoch 1159/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2441e-06 - acc: 1.0000Epoch 01159: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 4.8898e-06 - acc: 1.0000 - val_loss: 8.1273e-04 - val_acc: 1.0000\n",
      "Epoch 1160/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.8134e-06 - acc: 1.0000Epoch 01160: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0060 - val_acc: 0.9949\n",
      "Epoch 1161/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.8383e-06 - acc: 1.0000Epoch 01161: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4738e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 1162/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5267e-04 - acc: 1.0000Epoch 01162: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 7.0098e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 1163/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5664e-05 - acc: 1.0000Epoch 01163: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.4668e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 1164/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0058 - acc: 0.9986Epoch 01164: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0092 - val_acc: 0.9949\n",
      "Epoch 1165/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0886e-06 - acc: 1.0000Epoch 01165: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.6001e-06 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9949\n",
      "Epoch 1166/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8705e-05 - acc: 1.0000Epoch 01166: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.7407e-05 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 0.9899\n",
      "Epoch 1167/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8068e-06 - acc: 1.0000Epoch 01167: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 2.6698e-06 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9949\n",
      "Epoch 1168/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.7263e-06 - acc: 1.0000Epoch 01168: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.3268e-06 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9949\n",
      "Epoch 1169/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2549e-06 - acc: 1.0000Epoch 01169: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 4.9008e-06 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 0.9899\n",
      "Epoch 1170/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1794e-05 - acc: 1.0000Epoch 01170: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 1.0989e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 1171/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4979e-05 - acc: 1.0000Epoch 01171: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 1.3969e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1172/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1914e-05 - acc: 1.0000Epoch 01172: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 1.1252e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1173/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2662e-06 - acc: 1.0000Epoch 01173: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2330e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1174/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7507e-07 - acc: 1.0000Epoch 01174: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 8.8446e-07 - acc: 1.0000 - val_loss: 9.6364e-04 - val_acc: 1.0000\n",
      "Epoch 1175/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4424e-04 - acc: 1.0000Epoch 01175: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3406e-04 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 1176/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1537e-05 - acc: 1.0000Epoch 01176: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 2.9324e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 1177/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3498e-06 - acc: 1.0000Epoch 01177: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.2628e-06 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 1178/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1696e-06 - acc: 1.0000Epoch 01178: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 5.7477e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1179/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7851e-06 - acc: 1.0000Epoch 01179: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 1.6962e-06 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 1180/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0758e-05 - acc: 1.0000Epoch 01180: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 2.4803e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9949\n",
      "Epoch 1181/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9207e-06 - acc: 1.0000Epoch 01181: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 5.1010e-06 - acc: 1.0000 - val_loss: 7.4912e-04 - val_acc: 1.0000\n",
      "Epoch 1182/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7141e-05 - acc: 1.0000Epoch 01182: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 1.6021e-05 - acc: 1.0000 - val_loss: 4.8380e-04 - val_acc: 1.0000\n",
      "Epoch 1183/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3264e-05 - acc: 1.0000Epoch 01183: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2347e-05 - acc: 1.0000 - val_loss: 9.0218e-04 - val_acc: 1.0000\n",
      "Epoch 1184/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7292e-06 - acc: 1.0000Epoch 01184: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5119e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 1185/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.6997e-05 - acc: 1.0000Epoch 01185: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 7.1571e-05 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9949\n",
      "Epoch 1186/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1281e-05 - acc: 1.0000Epoch 01186: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 3.2319e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1187/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8707e-04 - acc: 1.0000Epoch 01187: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 5.4558e-04 - acc: 1.0000 - val_loss: 2.2399e-04 - val_acc: 1.0000\n",
      "Epoch 1188/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1272e-06 - acc: 1.0000Epoch 01188: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 3.1476e-06 - acc: 1.0000 - val_loss: 1.6559e-04 - val_acc: 1.0000\n",
      "Epoch 1189/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2547e-05 - acc: 1.0000Epoch 01189: val_loss improved from 0.00012 to 0.00004, saving model to weights.best2.hdf5\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.8367e-05 - acc: 1.0000 - val_loss: 3.6526e-05 - val_acc: 1.0000\n",
      "Epoch 1190/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2315e-05 - acc: 1.0000Epoch 01190: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 3.9598e-05 - acc: 1.0000 - val_loss: 6.4954e-05 - val_acc: 1.0000\n",
      "Epoch 1191/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7259e-05 - acc: 1.0000Epoch 01191: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 4.3988e-05 - acc: 1.0000 - val_loss: 1.5465e-04 - val_acc: 1.0000\n",
      "Epoch 1192/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 0.9986  Epoch 01192: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.9987 - val_loss: 1.0927e-04 - val_acc: 1.0000\n",
      "Epoch 1193/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2150e-06 - acc: 1.0000Epoch 01193: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1377e-05 - acc: 1.0000 - val_loss: 6.5885e-05 - val_acc: 1.0000\n",
      "Epoch 1194/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.2308e-06 - acc: 1.0000Epoch 01194: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5965e-06 - acc: 1.0000 - val_loss: 1.0027e-04 - val_acc: 1.0000\n",
      "Epoch 1195/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0277e-06 - acc: 1.0000Epoch 01195: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 4.7119e-06 - acc: 1.0000 - val_loss: 1.0787e-04 - val_acc: 1.0000\n",
      "Epoch 1196/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0975e-06 - acc: 1.0000Epoch 01196: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9659e-06 - acc: 1.0000 - val_loss: 1.1724e-04 - val_acc: 1.0000\n",
      "Epoch 1197/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7057e-06 - acc: 1.0000Epoch 01197: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 2.5592e-06 - acc: 1.0000 - val_loss: 3.3767e-04 - val_acc: 1.0000\n",
      "Epoch 1198/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1850e-06 - acc: 1.0000Epoch 01198: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 2.0407e-06 - acc: 1.0000 - val_loss: 3.9889e-04 - val_acc: 1.0000\n",
      "Epoch 1199/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7735e-06 - acc: 1.0000Epoch 01199: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7382e-06 - acc: 1.0000 - val_loss: 9.8881e-04 - val_acc: 1.0000\n",
      "Epoch 1200/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.4205e-06 - acc: 1.0000Epoch 01200: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.6759e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1201/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6588e-06 - acc: 1.0000Epoch 01201: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.5690e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1202/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1438e-04 - acc: 1.0000Epoch 01202: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 4.7825e-04 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9949\n",
      "Epoch 1203/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5331e-05 - acc: 1.0000Epoch 01203: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7392e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 1204/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6152e-05 - acc: 1.0000Epoch 01204: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2217e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1205/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7539e-06 - acc: 1.0000Epoch 01205: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.2417e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1206/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4487e-05 - acc: 1.0000Epoch 01206: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 4.0980e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1207/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1895e-05 - acc: 1.0000Epoch 01207: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 1.1315e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1208/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.7076e-06 - acc: 1.0000Epoch 01208: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 7.1954e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1209/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1883e-06 - acc: 1.0000Epoch 01209: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.1376e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1210/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9391e-05 - acc: 1.0000Epoch 01210: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 5.5247e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1211/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0160e-05 - acc: 1.0000Epoch 01211: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 2.8057e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1212/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0387e-05 - acc: 1.0000Epoch 01212: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8962e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9949\n",
      "Epoch 1213/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0214e-06 - acc: 1.0000Epoch 01213: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3644e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1214/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5256e-06 - acc: 1.0000Epoch 01214: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 6.0773e-06 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 1215/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3101e-05 - acc: 1.0000Epoch 01215: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.3143e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 1216/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1165e-06 - acc: 1.0000Epoch 01216: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 4.8005e-06 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9949\n",
      "Epoch 1217/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.3518e-04 - acc: 1.0000Epoch 01217: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 7.7618e-04 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9949\n",
      "Epoch 1218/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3636e-06 - acc: 1.0000Epoch 01218: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2947e-06 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9949\n",
      "Epoch 1219/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9021e-06 - acc: 1.0000Epoch 01219: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.7853e-06 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9949\n",
      "Epoch 1220/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0058e-06 - acc: 1.0000Epoch 01220: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 2.9295e-06 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9949\n",
      "Epoch 1221/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4508e-06 - acc: 1.0000Epoch 01221: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3679e-06 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9949\n",
      "Epoch 1222/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5779e-05 - acc: 1.0000Epoch 01222: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.0443e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9949\n",
      "Epoch 1223/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6778e-06 - acc: 1.0000Epoch 01223: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5706e-06 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9949\n",
      "Epoch 1224/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0568e-05 - acc: 1.0000Epoch 01224: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9150e-05 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9949\n",
      "Epoch 1225/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.4816e-07 - acc: 1.0000Epoch 01225: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3345e-06 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9949\n",
      "Epoch 1226/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4584e-05 - acc: 1.0000Epoch 01226: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3777e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9949\n",
      "Epoch 1227/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0177e-05 - acc: 1.0000Epoch 01227: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8213e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 1228/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4081e-06 - acc: 1.0000Epoch 01228: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3191e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9949\n",
      "Epoch 1229/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3032e-06 - acc: 1.0000Epoch 01229: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0805e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9949\n",
      "Epoch 1230/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6124e-05 - acc: 1.0000Epoch 01230: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6928e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9949\n",
      "Epoch 1231/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9435e-07 - acc: 1.0000Epoch 01231: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 5.6603e-07 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9949\n",
      "Epoch 1232/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1849e-07 - acc: 1.0000Epoch 01232: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 9.8728e-07 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9949\n",
      "Epoch 1233/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1565e-06 - acc: 1.0000Epoch 01233: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 5.1514e-06 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9949\n",
      "Epoch 1234/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.6454e-06 - acc: 1.0000Epoch 01234: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 7.2124e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1235/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1331e-05 - acc: 1.0000Epoch 01235: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.0550e-05 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9949\n",
      "Epoch 1236/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4586e-06 - acc: 1.0000Epoch 01236: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 2.3014e-06 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 1237/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0384e-06 - acc: 1.0000Epoch 01237: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8463e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1238/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4353e-06 - acc: 1.0000Epoch 01238: val_loss did not improve\n",
      "792/792 [==============================] - 1s 955us/step - loss: 4.4245e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 1239/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3058e-06 - acc: 1.0000Epoch 01239: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 1.2552e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1240/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3041e-05 - acc: 1.0000Epoch 01240: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 2.1573e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1241/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2051e-05 - acc: 1.0000Epoch 01241: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 7.6284e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1242/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3135e-06 - acc: 1.0000Epoch 01242: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 1.2539e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1243/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8837e-04 - acc: 1.0000Epoch 01243: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 3.6093e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1244/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0242e-05 - acc: 1.0000Epoch 01244: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 9.6110e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1245/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7182e-06 - acc: 1.0000Epoch 01245: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 3.4811e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1246/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2269e-05 - acc: 1.0000Epoch 01246: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 2.0738e-05 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 1247/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0164e-05 - acc: 1.0000Epoch 01247: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 1.8763e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1248/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8529e-06 - acc: 1.0000Epoch 01248: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 1.7828e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1249/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3620e-06 - acc: 1.0000Epoch 01249: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 4.9994e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1250/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0270e-06 - acc: 1.0000Epoch 01250: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 4.1865e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1251/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.5552e-07 - acc: 1.0000Epoch 01251: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 9.0196e-07 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1252/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4334e-06 - acc: 1.0000Epoch 01252: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 3.1997e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1253/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0245e-06 - acc: 1.0000Epoch 01253: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 9.8950e-07 - acc: 1.0000 - val_loss: 9.6249e-04 - val_acc: 1.0000\n",
      "Epoch 1254/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7533e-06 - acc: 1.0000Epoch 01254: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 3.5292e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1255/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1347e-05 - acc: 1.0000Epoch 01255: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.7142e-05 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 1256/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3712e-06 - acc: 1.0000Epoch 01256: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2482e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1257/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9731e-04 - acc: 1.0000Epoch 01257: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 1.8352e-04 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 1258/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8490e-06 - acc: 1.0000Epoch 01258: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 1.7410e-06 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9949\n",
      "Epoch 1259/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5582e-06 - acc: 1.0000Epoch 01259: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 1.4640e-06 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9949\n",
      "Epoch 1260/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5700e-07 - acc: 1.0000Epoch 01260: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 4.3387e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 1261/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.1798e-07 - acc: 1.0000Epoch 01261: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 7.8528e-07 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9949\n",
      "Epoch 1262/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.4401e-06 - acc: 1.0000Epoch 01262: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6509e-06 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 1263/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0853e-07 - acc: 1.0000Epoch 01263: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 6.1585e-07 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9949\n",
      "Epoch 1264/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9877e-06 - acc: 1.0000Epoch 01264: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 1.8980e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 1265/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7855e-07 - acc: 1.0000Epoch 01265: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 1.4445e-06 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9949\n",
      "Epoch 1266/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6890e-06 - acc: 1.0000Epoch 01266: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.7314e-06 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9949\n",
      "Epoch 1267/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1181e-06 - acc: 1.0000Epoch 01267: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 1.0483e-06 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9949\n",
      "Epoch 1268/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2718e-05 - acc: 1.0000Epoch 01268: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 2.1120e-05 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9949\n",
      "Epoch 1269/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3034e-06 - acc: 1.0000Epoch 01269: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4073e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 1270/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.8239e-07 - acc: 1.0000Epoch 01270: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 7.2310e-07 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1271/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6299e-04 - acc: 1.0000Epoch 01271: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.5149e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1272/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8833e-05 - acc: 1.0000Epoch 01272: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.6100e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1273/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3729e-05 - acc: 1.0000Epoch 01273: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2823e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1274/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4414e-05 - acc: 1.0000Epoch 01274: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1292e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1275/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.3194e-07 - acc: 1.0000Epoch 01275: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 7.8463e-07 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1276/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6307e-05 - acc: 1.0000Epoch 01276: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 6.1644e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1277/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1393e-05 - acc: 1.0000Epoch 01277: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.0596e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1278/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.0493e-07 - acc: 1.0000Epoch 01278: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 7.7015e-07 - acc: 1.0000 - val_loss: 7.5168e-04 - val_acc: 1.0000\n",
      "Epoch 1279/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8995e-05 - acc: 1.0000Epoch 01279: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 3.6270e-05 - acc: 1.0000 - val_loss: 3.5869e-04 - val_acc: 1.0000\n",
      "Epoch 1280/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8442e-06 - acc: 1.0000Epoch 01280: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 3.6271e-06 - acc: 1.0000 - val_loss: 6.6129e-04 - val_acc: 1.0000\n",
      "Epoch 1281/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6425e-06 - acc: 1.0000Epoch 01281: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.5757e-06 - acc: 1.0000 - val_loss: 4.8526e-04 - val_acc: 1.0000\n",
      "Epoch 1282/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1314e-06 - acc: 1.0000Epoch 01282: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 3.0088e-06 - acc: 1.0000 - val_loss: 9.0872e-04 - val_acc: 1.0000\n",
      "Epoch 1283/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5055e-06 - acc: 1.0000Epoch 01283: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.2573e-06 - acc: 1.0000 - val_loss: 4.5286e-04 - val_acc: 1.0000\n",
      "Epoch 1284/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2595e-04 - acc: 1.0000Epoch 01284: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 2.1009e-04 - acc: 1.0000 - val_loss: 5.0397e-04 - val_acc: 1.0000\n",
      "Epoch 1285/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3121e-05 - acc: 1.0000Epoch 01285: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 4.9377e-05 - acc: 1.0000 - val_loss: 5.7489e-04 - val_acc: 1.0000\n",
      "Epoch 1286/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4261e-05 - acc: 1.0000Epoch 01286: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3269e-05 - acc: 1.0000 - val_loss: 5.3679e-04 - val_acc: 1.0000\n",
      "Epoch 1287/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6595e-07 - acc: 1.0000Epoch 01287: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 8.1526e-07 - acc: 1.0000 - val_loss: 7.9186e-04 - val_acc: 1.0000\n",
      "Epoch 1288/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7596e-06 - acc: 1.0000Epoch 01288: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.6570e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1289/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7524e-06 - acc: 1.0000Epoch 01289: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.5285e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1290/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5859e-06 - acc: 1.0000Epoch 01290: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.1628e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1291/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9513e-05 - acc: 1.0000Epoch 01291: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 3.8106e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1292/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7077e-05 - acc: 1.0000Epoch 01292: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.0935e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1293/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0188e-06 - acc: 1.0000Epoch 01293: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9399e-06 - acc: 1.0000 - val_loss: 9.8921e-04 - val_acc: 1.0000\n",
      "Epoch 1294/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7649e-06 - acc: 1.0000Epoch 01294: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 4.4416e-06 - acc: 1.0000 - val_loss: 8.8856e-04 - val_acc: 1.0000\n",
      "Epoch 1295/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5827e-05 - acc: 1.0000Epoch 01295: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 1.4720e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1296/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2180e-06 - acc: 1.0000Epoch 01296: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 9.6368e-06 - acc: 1.0000 - val_loss: 5.4563e-04 - val_acc: 1.0000\n",
      "Epoch 1297/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4924e-06 - acc: 1.0000Epoch 01297: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 2.3328e-06 - acc: 1.0000 - val_loss: 6.7181e-04 - val_acc: 1.0000\n",
      "Epoch 1298/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2449e-07 - acc: 1.0000Epoch 01298: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 5.8982e-07 - acc: 1.0000 - val_loss: 4.1917e-04 - val_acc: 1.0000\n",
      "Epoch 1299/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7043e-06 - acc: 1.0000Epoch 01299: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 1.5983e-06 - acc: 1.0000 - val_loss: 6.4913e-04 - val_acc: 1.0000\n",
      "Epoch 1300/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0026e-06 - acc: 1.0000Epoch 01300: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 1.8717e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1301/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4653e-05 - acc: 1.0000Epoch 01301: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 2.2953e-05 - acc: 1.0000 - val_loss: 8.9818e-04 - val_acc: 1.0000\n",
      "Epoch 1302/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.9019e-07 - acc: 1.0000Epoch 01302: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 9.2860e-07 - acc: 1.0000 - val_loss: 5.8274e-04 - val_acc: 1.0000\n",
      "Epoch 1303/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0415e-06 - acc: 1.0000Epoch 01303: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 2.8353e-06 - acc: 1.0000 - val_loss: 2.9625e-04 - val_acc: 1.0000\n",
      "Epoch 1304/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7119e-05 - acc: 1.0000Epoch 01304: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 3.4542e-05 - acc: 1.0000 - val_loss: 6.0288e-04 - val_acc: 1.0000\n",
      "Epoch 1305/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7468e-06 - acc: 1.0000Epoch 01305: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 3.5097e-06 - acc: 1.0000 - val_loss: 3.5695e-04 - val_acc: 1.0000\n",
      "Epoch 1306/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1521e-06 - acc: 1.0000Epoch 01306: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 4.7965e-06 - acc: 1.0000 - val_loss: 2.4945e-04 - val_acc: 1.0000\n",
      "Epoch 1307/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6605e-07 - acc: 1.0000Epoch 01307: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.5078e-07 - acc: 1.0000 - val_loss: 6.8205e-04 - val_acc: 1.0000\n",
      "Epoch 1308/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5340e-06 - acc: 1.0000Epoch 01308: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4589e-06 - acc: 1.0000 - val_loss: 3.8076e-04 - val_acc: 1.0000\n",
      "Epoch 1309/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9149e-06 - acc: 1.0000Epoch 01309: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4361e-06 - acc: 1.0000 - val_loss: 3.4321e-04 - val_acc: 1.0000\n",
      "Epoch 1310/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6810e-05 - acc: 1.0000Epoch 01310: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2821e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1311/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9993e-07 - acc: 1.0000Epoch 01311: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5120e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1312/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9675e-07 - acc: 1.0000Epoch 01312: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 5.8052e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1313/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9725e-06 - acc: 1.0000Epoch 01313: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 2.8035e-06 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 1314/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.8667e-07 - acc: 1.0000Epoch 01314: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 8.6499e-07 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 1315/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4567e-06 - acc: 1.0000Epoch 01315: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 6.4505e-06 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9949\n",
      "Epoch 1316/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0768e-06 - acc: 1.0000Epoch 01316: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 6.5880e-06 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9949\n",
      "Epoch 1317/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.2475e-07 - acc: 1.0000Epoch 01317: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.2724e-07 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 1318/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2879e-06 - acc: 1.0000Epoch 01318: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0649e-06 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 1319/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8785e-06 - acc: 1.0000Epoch 01319: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7544e-06 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 1320/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5435e-04 - acc: 1.0000Epoch 01320: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3638e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1321/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5479e-06 - acc: 1.0000Epoch 01321: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1927e-06 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1322/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7571e-07 - acc: 1.0000Epoch 01322: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4829e-07 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 1323/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2077e-07 - acc: 1.0000Epoch 01323: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5658e-07 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1324/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3193e-06 - acc: 1.0000Epoch 01324: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4064e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1325/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9064e-06 - acc: 1.0000Epoch 01325: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7096e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1326/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5851e-06 - acc: 1.0000Epoch 01326: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.6038e-06 - acc: 1.0000 - val_loss: 8.5454e-04 - val_acc: 1.0000\n",
      "Epoch 1327/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6045e-06 - acc: 1.0000Epoch 01327: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9933e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1328/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3027e-06 - acc: 1.0000Epoch 01328: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2572e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1329/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.7317e-06 - acc: 1.0000Epoch 01329: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.2797e-06 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 1330/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6286e-04 - acc: 1.0000Epoch 01330: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5135e-04 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 0.9899\n",
      "Epoch 1331/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1947e-06 - acc: 1.0000Epoch 01331: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.8588e-06 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9949\n",
      "Epoch 1332/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1963e-07 - acc: 1.0000Epoch 01332: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9042e-07 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9949\n",
      "Epoch 1333/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8042e-06 - acc: 1.0000Epoch 01333: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.5916e-06 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9949\n",
      "Epoch 1334/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2762e-05 - acc: 1.0000Epoch 01334: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1873e-05 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9899\n",
      "Epoch 1335/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2718e-07 - acc: 1.0000Epoch 01335: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 3.1262e-07 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 0.9899\n",
      "Epoch 1336/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3696e-06 - acc: 1.0000Epoch 01336: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.5646e-06 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 0.9899\n",
      "Epoch 1337/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8511e-05 - acc: 1.0000Epoch 01337: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.7220e-05 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9949\n",
      "Epoch 1338/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3076e-07 - acc: 1.0000Epoch 01338: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.9330e-06 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9949\n",
      "Epoch 1339/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8675e-06 - acc: 1.0000Epoch 01339: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 2.0343e-06 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9949\n",
      "Epoch 1340/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9011e-07 - acc: 1.0000Epoch 01340: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 7.6796e-07 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9949\n",
      "Epoch 1341/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7066e-05 - acc: 1.0000Epoch 01341: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 3.4499e-05 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 1342/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.7033e-07 - acc: 1.0000Epoch 01342: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 9.9851e-07 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 1343/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9356e-06 - acc: 1.0000Epoch 01343: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 8.3252e-06 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9949\n",
      "Epoch 1344/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0125e-06 - acc: 1.0000Epoch 01344: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 2.1597e-06 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 1345/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.1637e-06 - acc: 1.0000Epoch 01345: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.5951e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1346/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6247e-06 - acc: 1.0000Epoch 01346: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 2.7821e-06 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 1347/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1001e-05 - acc: 1.0000Epoch 01347: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.9654e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1348/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1062e-04 - acc: 1.0000Epoch 01348: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.0296e-04 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 1349/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0988e-07 - acc: 1.0000Epoch 01349: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 4.8949e-07 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 1350/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0502e-06 - acc: 1.0000- ETA: 0s - loss: 8.4876e-07 - aEpoch 01350: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.1673e-06 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9949\n",
      "Epoch 1351/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0499e-06 - acc: 1.0000Epoch 01351: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7647e-06 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9949\n",
      "Epoch 1352/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9288e-06 - acc: 1.0000Epoch 01352: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 4.5974e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 1353/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1427e-06 - acc: 1.0000Epoch 01353: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 6.6503e-06 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1354/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8927e-05 - acc: 1.0000Epoch 01354: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 2.6904e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 1355/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.6101e-07 - acc: 1.0000Epoch 01355: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 7.1721e-07 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 1356/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6937e-06 - acc: 1.0000Epoch 01356: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 2.9456e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1357/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.1916e-06 - acc: 1.0000Epoch 01357: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.7595e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1358/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0067e-06 - acc: 1.0000Epoch 01358: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 1.8969e-06 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1359/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2203e-06 - acc: 1.0000Epoch 01359: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 3.9316e-06 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 1360/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4582e-06 - acc: 1.0000Epoch 01360: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3653e-06 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9949\n",
      "Epoch 1361/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8995e-04 - acc: 1.0000Epoch 01361: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 2.7038e-04 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 1362/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.3639e-07 - acc: 1.0000Epoch 01362: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 9.0804e-07 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 1363/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2209e-06 - acc: 1.0000Epoch 01363: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 7.7122e-05 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9949\n",
      "Epoch 1364/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5947e-05 - acc: 1.0000Epoch 01364: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.1695e-04 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9899\n",
      "Epoch 1365/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4521e-04 - acc: 1.0000Epoch 01365: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 2.2789e-04 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 1366/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.7262e-07 - acc: 1.0000Epoch 01366: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 6.4636e-07 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 1367/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9429e-05 - acc: 1.0000Epoch 01367: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8069e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1368/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4670e-05 - acc: 1.0000Epoch 01368: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 2.2937e-05 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 1369/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3641e-06 - acc: 1.0000Epoch 01369: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2962e-06 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9949\n",
      "Epoch 1370/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4490e-06 - acc: 1.0000Epoch 01370: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.3763e-06 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 1371/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1220e-05 - acc: 1.0000Epoch 01371: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 1.0462e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9949\n",
      "Epoch 1372/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0013 - acc: 0.9986Epoch 01372: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.9987 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 1373/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9428e-06 - acc: 1.0000Epoch 01373: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.8861e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1374/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7619e-06 - acc: 1.0000Epoch 01374: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 2.5828e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1375/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.4670e-06 - acc: 1.0000Epoch 01375: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 8.8062e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1376/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4518e-07 - acc: 1.0000Epoch 01376: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 4.4004e-07 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1377/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0431e-05 - acc: 1.0000Epoch 01377: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 4.6910e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1378/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9869e-05 - acc: 1.0000Epoch 01378: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7825e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1379/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8408e-06 - acc: 1.0000Epoch 01379: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9922e-06 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 1380/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4420e-05 - acc: 1.0000Epoch 01380: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2033e-05 - acc: 1.0000 - val_loss: 7.9990e-04 - val_acc: 1.0000\n",
      "Epoch 1381/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3454e-04 - acc: 1.0000Epoch 01381: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1802e-04 - acc: 1.0000 - val_loss: 9.7934e-04 - val_acc: 1.0000\n",
      "Epoch 1382/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3672e-06 - acc: 1.0000Epoch 01382: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.4482e-06 - acc: 1.0000 - val_loss: 9.4924e-04 - val_acc: 1.0000\n",
      "Epoch 1383/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0088e-05 - acc: 1.0000Epoch 01383: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 1.9319e-05 - acc: 1.0000 - val_loss: 5.1681e-04 - val_acc: 1.0000\n",
      "Epoch 1384/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0154e-06 - acc: 1.0000Epoch 01384: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 9.5417e-07 - acc: 1.0000 - val_loss: 6.4073e-04 - val_acc: 1.0000\n",
      "Epoch 1385/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1740e-07 - acc: 1.0000Epoch 01385: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 8.8693e-07 - acc: 1.0000 - val_loss: 7.0965e-04 - val_acc: 1.0000\n",
      "Epoch 1386/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4031e-06 - acc: 1.0000Epoch 01386: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.3263e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1387/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4194e-07 - acc: 1.0000Epoch 01387: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.5983e-07 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 1388/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3629e-06 - acc: 1.0000Epoch 01388: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9234e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1389/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.6864e-06 - acc: 1.0000Epoch 01389: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.0102e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1390/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.7819e-06 - acc: 1.0000Epoch 01390: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 6.3522e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1391/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.8725e-06 - acc: 1.0000Epoch 01391: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 6.4525e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1392/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2404e-06 - acc: 1.0000Epoch 01392: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 3.0221e-06 - acc: 1.0000 - val_loss: 7.9846e-04 - val_acc: 1.0000\n",
      "Epoch 1393/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1613e-06 - acc: 1.0000Epoch 01393: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 2.0179e-06 - acc: 1.0000 - val_loss: 8.6298e-04 - val_acc: 1.0000\n",
      "Epoch 1394/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0321e-06 - acc: 1.0000Epoch 01394: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 4.7339e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1395/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.7496e-07 - acc: 1.0000Epoch 01395: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 9.1709e-07 - acc: 1.0000 - val_loss: 8.2069e-04 - val_acc: 1.0000\n",
      "Epoch 1396/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.8111e-05 - acc: 1.0000Epoch 01396: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 9.2497e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1397/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0628e-06 - acc: 1.0000Epoch 01397: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 2.0086e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1398/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1391e-06 - acc: 1.0000Epoch 01398: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0836e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1399/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8042e-06 - acc: 1.0000Epoch 01399: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 3.5446e-06 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9949\n",
      "Epoch 1400/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2022e-05 - acc: 1.0000Epoch 01400: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 7.6282e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1401/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5341e-06 - acc: 1.0000Epoch 01401: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 1.5068e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1402/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1215e-06 - acc: 1.0000Epoch 01402: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 1.0595e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1403/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2185e-06 - acc: 1.0000Epoch 01403: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 2.2402e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1404/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0617e-06 - acc: 1.0000Epoch 01404: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 9.9695e-07 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 1405/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.4688e-04 - acc: 1.0000Epoch 01405: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 6.9411e-04 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 1406/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6920e-06 - acc: 1.0000Epoch 01406: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.5860e-06 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 1407/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0034 - acc: 0.9986Epoch 01407: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 1408/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1869e-06 - acc: 1.0000Epoch 01408: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.2822e-05 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 1409/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8848e-07 - acc: 1.0000Epoch 01409: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.8964e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 1410/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5580e-05 - acc: 1.0000Epoch 01410: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 5.1828e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1411/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1995e-06 - acc: 1.0000Epoch 01411: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 2.9898e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1412/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9982e-06 - acc: 1.0000Epoch 01412: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 3.7335e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1413/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1732e-07 - acc: 1.0000Epoch 01413: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 5.2366e-07 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1414/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8786e-05 - acc: 1.0000Epoch 01414: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7467e-05 - acc: 1.0000 - val_loss: 6.7511e-04 - val_acc: 1.0000\n",
      "Epoch 1415/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.8863e-05 - acc: 1.0000Epoch 01415: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.2127e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1416/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.3981e-07 - acc: 1.0000Epoch 01416: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0740e-06 - acc: 1.0000 - val_loss: 8.0808e-04 - val_acc: 1.0000\n",
      "Epoch 1417/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0783e-05 - acc: 1.0000Epoch 01417: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0083e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1418/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0794e-06 - acc: 1.0000Epoch 01418: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 2.9362e-06 - acc: 1.0000 - val_loss: 8.6160e-04 - val_acc: 1.0000\n",
      "Epoch 1419/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4960e-05 - acc: 1.0000Epoch 01419: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 3.2501e-05 - acc: 1.0000 - val_loss: 5.7565e-04 - val_acc: 1.0000\n",
      "Epoch 1420/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7721e-05 - acc: 1.0000Epoch 01420: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.6493e-05 - acc: 1.0000 - val_loss: 7.0061e-04 - val_acc: 1.0000\n",
      "Epoch 1421/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1810e-06 - acc: 1.0000Epoch 01421: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 2.0430e-06 - acc: 1.0000 - val_loss: 8.2078e-04 - val_acc: 1.0000\n",
      "Epoch 1422/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0981e-06 - acc: 1.0000Epoch 01422: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 1.9656e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1423/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2877e-06 - acc: 1.0000Epoch 01423: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 1.2051e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1424/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6934e-07 - acc: 1.0000Epoch 01424: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 5.3826e-07 - acc: 1.0000 - val_loss: 9.5546e-04 - val_acc: 1.0000\n",
      "Epoch 1425/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5446e-05 - acc: 1.0000Epoch 01425: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.4384e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9949\n",
      "Epoch 1426/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9170e-06 - acc: 1.0000Epoch 01426: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 1.7905e-06 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 1427/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2050e-05 - acc: 1.0000Epoch 01427: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 0.0027 - acc: 0.9987 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1428/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8106e-07 - acc: 1.0000Epoch 01428: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8136e-07 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 1429/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0868e-04 - acc: 1.0000Epoch 01429: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0102e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1430/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2841e-06 - acc: 1.0000Epoch 01430: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1351e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1431/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2100e-06 - acc: 1.0000Epoch 01431: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 5.7881e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1432/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7875e-07 - acc: 1.0000Epoch 01432: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 8.2677e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1433/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.5785e-07 - acc: 1.0000Epoch 01433: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 8.2549e-07 - acc: 1.0000 - val_loss: 9.0713e-04 - val_acc: 1.0000\n",
      "Epoch 1434/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6274e-04 - acc: 1.0000Epoch 01434: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 1.5183e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1435/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.4022e-07 - acc: 1.0000Epoch 01435: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 7.5200e-07 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 1436/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4314e-06 - acc: 1.0000Epoch 01436: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 5.3058e-06 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9949\n",
      "Epoch 1437/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1686e-05 - acc: 1.0000Epoch 01437: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.9457e-05 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9949\n",
      "Epoch 1438/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6661e-06 - acc: 1.0000Epoch 01438: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0185e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1439/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.3640e-07 - acc: 1.0000Epoch 01439: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.9713e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1440/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2841e-05 - acc: 1.0000Epoch 01440: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1709e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9899\n",
      "Epoch 1441/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2996e-05 - acc: 1.0000Epoch 01441: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2094e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9949\n",
      "Epoch 1442/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2974e-06 - acc: 1.0000Epoch 01442: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2526e-06 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9949\n",
      "Epoch 1443/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1358e-06 - acc: 1.0000Epoch 01443: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9935e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9949\n",
      "Epoch 1444/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1356e-06 - acc: 1.0000Epoch 01444: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9942e-06 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9949\n",
      "Epoch 1445/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7518e-06 - acc: 1.0000Epoch 01445: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 4.5451e-06 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9949\n",
      "Epoch 1446/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7391e-06 - acc: 1.0000Epoch 01446: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 3.4854e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1447/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.1757e-07 - acc: 1.0000Epoch 01447: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 7.9784e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1448/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1307e-06 - acc: 1.0000Epoch 01448: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 3.9068e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1449/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.2823e-06 - acc: 1.0000Epoch 01449: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 7.7056e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 1450/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8229e-06 - acc: 1.0000Epoch 01450: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 3.0590e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1451/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7553e-06 - acc: 1.0000Epoch 01451: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.6555e-06 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 1452/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2615e-05 - acc: 1.0000Epoch 01452: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.2258e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1453/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4100e-05 - acc: 1.0000Epoch 01453: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 4.1003e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1454/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6983e-06 - acc: 1.0000Epoch 01454: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 1.7981e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1455/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1366e-07 - acc: 1.0000Epoch 01455: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 6.8337e-07 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 1456/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5494e-06 - acc: 1.0000Epoch 01456: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6901e-06 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 1457/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4841e-06 - acc: 1.0000Epoch 01457: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5260e-06 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 1458/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6409e-05 - acc: 1.0000Epoch 01458: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 1.6079e-05 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 1459/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1276e-06 - acc: 1.0000Epoch 01459: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 1.0565e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1460/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5453e-06 - acc: 1.0000Epoch 01460: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 6.0909e-06 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9949\n",
      "Epoch 1461/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2558e-06 - acc: 1.0000Epoch 01461: val_loss did not improve\n",
      "792/792 [==============================] - 1s 948us/step - loss: 1.1877e-06 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9949\n",
      "Epoch 1462/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0619e-04 - acc: 1.0000Epoch 01462: val_loss did not improve\n",
      "792/792 [==============================] - 1s 960us/step - loss: 1.9162e-04 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9949\n",
      "Epoch 1463/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.2347e-06 - acc: 1.0000Epoch 01463: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 6.7491e-06 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 1464/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1792e-05 - acc: 1.0000Epoch 01464: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 1.1357e-05 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 1465/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1408e-06 - acc: 1.0000Epoch 01465: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 1.1088e-05 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 1466/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.7941e-07 - acc: 1.0000Epoch 01466: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 7.2793e-07 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 1467/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.4412e-06 - acc: 1.0000Epoch 01467: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.7826e-06 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 1468/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0642e-06 - acc: 1.0000Epoch 01468: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 1.0035e-06 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 1469/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8996e-06 - acc: 1.0000Epoch 01469: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8195e-06 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 1470/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1415e-06 - acc: 1.0000Epoch 01470: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1117e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 1471/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.3851e-07 - acc: 1.0000Epoch 01471: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 1.0151e-06 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 1472/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3492e-04 - acc: 1.0000Epoch 01472: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 1.2540e-04 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 1473/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8113e-06 - acc: 1.0000Epoch 01473: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.7223e-06 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9949\n",
      "Epoch 1474/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0918e-06 - acc: 1.0000Epoch 01474: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 1.0666e-06 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 1475/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9228e-07 - acc: 1.0000Epoch 01475: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 2.8094e-07 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 1476/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0592e-04 - acc: 1.0000Epoch 01476: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 4.7022e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 1477/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7872e-06 - acc: 1.0000Epoch 01477: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 3.5329e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 1478/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7533e-06 - acc: 1.0000Epoch 01478: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 8.1603e-06 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 1479/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5406e-06 - acc: 1.0000Epoch 01479: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 6.0871e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1480/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2581e-05 - acc: 1.0000Epoch 01480: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 2.1037e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9949\n",
      "Epoch 1481/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9191e-07 - acc: 1.0000Epoch 01481: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 5.4962e-07 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 1482/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3981e-06 - acc: 1.0000Epoch 01482: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9593e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1483/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7009e-06 - acc: 1.0000Epoch 01483: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 3.4533e-06 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 1484/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6427e-07 - acc: 1.0000Epoch 01484: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 3.5101e-07 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1485/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1694e-06 - acc: 1.0000Epoch 01485: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1047e-06 - acc: 1.0000 - val_loss: 6.9612e-04 - val_acc: 1.0000\n",
      "Epoch 1486/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.9441e-05 - acc: 1.0000Epoch 01486: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.2418e-05 - acc: 1.0000 - val_loss: 5.7160e-04 - val_acc: 1.0000\n",
      "Epoch 1487/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.6526e-07 - acc: 1.0000Epoch 01487: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.2560e-07 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 1488/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4184e-06 - acc: 1.0000Epoch 01488: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 4.1338e-06 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1489/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2737e-06 - acc: 1.0000Epoch 01489: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.1978e-06 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9949\n",
      "Epoch 1490/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3549e-06 - acc: 1.0000Epoch 01490: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1522e-06 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9949\n",
      "Epoch 1491/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6555e-06 - acc: 1.0000Epoch 01491: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3406e-06 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9949\n",
      "Epoch 1492/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9015e-06 - acc: 1.0000Epoch 01492: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.5648e-06 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9949\n",
      "Epoch 1493/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6750e-06 - acc: 1.0000Epoch 01493: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2844e-06 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9949\n",
      "Epoch 1494/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6197e-06 - acc: 1.0000Epoch 01494: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 1.5227e-06 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 0.9949\n",
      "Epoch 1495/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0641e-05 - acc: 1.0000Epoch 01495: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 9.9162e-06 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9899\n",
      "Epoch 1496/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0027e-07 - acc: 1.0000Epoch 01496: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 4.7377e-07 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9949\n",
      "Epoch 1497/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9576e-06 - acc: 1.0000Epoch 01497: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 7.4072e-06 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 1498/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1994e-06 - acc: 1.0000Epoch 01498: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.1307e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 1499/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2307e-05 - acc: 1.0000Epoch 01499: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 7.4773e-05 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9949\n",
      "Epoch 1500/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8633e-04 - acc: 1.0000Epoch 01500: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 3.5907e-04 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9949\n",
      "Epoch 1501/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9783e-06 - acc: 1.0000Epoch 01501: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 4.6615e-06 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9949\n",
      "Epoch 1502/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8863e-06 - acc: 1.0000Epoch 01502: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.7651e-06 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9949\n",
      "Epoch 1503/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6595e-06 - acc: 1.0000Epoch 01503: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 3.4488e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1504/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1059e-07 - acc: 1.0000Epoch 01504: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 8.5704e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1505/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3398e-05 - acc: 1.0000Epoch 01505: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 6.8241e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 1506/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9159e-07 - acc: 1.0000Epoch 01506: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.0196e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1507/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2571e-05 - acc: 1.0000Epoch 01507: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 4.8864e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1508/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2898e-06 - acc: 1.0000Epoch 01508: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 4.1837e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1509/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.2506e-06 - acc: 1.0000Epoch 01509: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 6.8071e-06 - acc: 1.0000 - val_loss: 8.1059e-04 - val_acc: 1.0000\n",
      "Epoch 1510/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5864e-07 - acc: 1.0000Epoch 01510: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.3088e-07 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1511/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3576e-05 - acc: 1.0000Epoch 01511: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 1.2630e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1512/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0033 - acc: 0.9986   Epoch 01512: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 0.0030 - acc: 0.9987 - val_loss: 9.3309e-04 - val_acc: 1.0000\n",
      "Epoch 1513/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.8758e-06 - acc: 1.0000Epoch 01513: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.3376e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 1514/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1945e-06 - acc: 1.0000Epoch 01514: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0594e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1515/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4951e-06 - acc: 1.0000Epoch 01515: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4008e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1516/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0863e-05 - acc: 1.0000Epoch 01516: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6569e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1517/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4182e-06 - acc: 1.0000Epoch 01517: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1941e-06 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1518/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1846e-05 - acc: 1.0000Epoch 01518: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5410e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1519/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6325e-06 - acc: 1.0000Epoch 01519: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3852e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1520/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5015e-06 - acc: 1.0000Epoch 01520: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.2277e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1521/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8979e-06 - acc: 1.0000Epoch 01521: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.0134e-06 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 1522/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7288e-07 - acc: 1.0000Epoch 01522: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4810e-07 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 1523/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0259e-06 - acc: 1.0000Epoch 01523: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9251e-06 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9949\n",
      "Epoch 1524/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7700e-04 - acc: 1.0000Epoch 01524: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.7018e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9899\n",
      "Epoch 1525/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2905e-06 - acc: 1.0000Epoch 01525: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 3.0670e-06 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9949\n",
      "Epoch 1526/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4372e-06 - acc: 1.0000Epoch 01526: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3511e-06 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9949\n",
      "Epoch 1527/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4029e-04 - acc: 1.0000Epoch 01527: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2418e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 1528/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4351e-05 - acc: 1.0000Epoch 01528: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.3351e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9899\n",
      "Epoch 1529/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7856e-07 - acc: 1.0000Epoch 01529: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 5.4608e-07 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9949\n",
      "Epoch 1530/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9752e-04 - acc: 1.0000Epoch 01530: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 2.7665e-04 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9949\n",
      "Epoch 1531/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9120e-06 - acc: 1.0000Epoch 01531: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4322e-06 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9949\n",
      "Epoch 1532/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3100e-06 - acc: 1.0000Epoch 01532: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1558e-06 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 1533/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0715e-06 - acc: 1.0000Epoch 01533: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9360e-06 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9949\n",
      "Epoch 1534/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7931e-06 - acc: 1.0000Epoch 01534: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.6209e-06 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9949\n",
      "Epoch 1535/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7102e-06 - acc: 1.0000Epoch 01535: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5326e-06 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9949\n",
      "Epoch 1536/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8494e-05 - acc: 1.0000Epoch 01536: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4381e-05 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9949\n",
      "Epoch 1537/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3548e-07 - acc: 1.0000Epoch 01537: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 5.1237e-07 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9949\n",
      "Epoch 1538/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0659e-04 - acc: 1.0000Epoch 01538: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 3.7861e-04 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 1539/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0530e-07 - acc: 1.0000Epoch 01539: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 6.5025e-07 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 1540/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0179e-05 - acc: 1.0000Epoch 01540: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 9.6694e-06 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 1541/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7716e-05 - acc: 1.0000Epoch 01541: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.6496e-05 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 1542/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9619e-06 - acc: 1.0000Epoch 01542: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 8.3373e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1543/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2708e-07 - acc: 1.0000Epoch 01543: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9644e-07 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1544/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0039 - acc: 0.9986Epoch 01544: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 1545/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6104e-06 - acc: 1.0000Epoch 01545: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.6686e-06 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 1546/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3338e-06 - acc: 1.0000Epoch 01546: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 5.9234e-06 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 1547/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9550e-06 - acc: 1.0000Epoch 01547: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 4.6162e-06 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9949\n",
      "Epoch 1548/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9070e-05 - acc: 1.0000Epoch 01548: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 4.8432e-05 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 1549/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4171e-06 - acc: 1.0000Epoch 01549: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9734e-06 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 1550/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7094e-05 - acc: 1.0000Epoch 01550: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 1.5894e-05 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 1551/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1498e-05 - acc: 1.0000Epoch 01551: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 1.9988e-05 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 1552/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1649e-06 - acc: 1.0000Epoch 01552: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 3.8790e-06 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 1553/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.2750e-07 - acc: 1.0000Epoch 01553: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 8.7260e-07 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9899\n",
      "Epoch 1554/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0447e-05 - acc: 1.0000Epoch 01554: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.7201e-06 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9949\n",
      "Epoch 1555/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6964e-07 - acc: 1.0000Epoch 01555: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4652e-07 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9949\n",
      "Epoch 1556/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4952e-06 - acc: 1.0000Epoch 01556: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8561e-06 - acc: 1.0000 - val_loss: 0.0259 - val_acc: 0.9899\n",
      "Epoch 1557/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7684e-06 - acc: 1.0000Epoch 01557: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.5103e-06 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9949\n",
      "Epoch 1558/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8455e-06 - acc: 1.0000Epoch 01558: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7749e-06 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 0.9949\n",
      "Epoch 1559/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2970e-06 - acc: 1.0000Epoch 01559: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.9312e-06 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9949\n",
      "Epoch 1560/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2905e-06 - acc: 1.0000Epoch 01560: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1521e-06 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 0.9899\n",
      "Epoch 1561/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0933e-05 - acc: 1.0000Epoch 01561: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9462e-05 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9949\n",
      "Epoch 1562/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9246e-07 - acc: 1.0000Epoch 01562: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 3.8142e-07 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9949\n",
      "Epoch 1563/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7763e-06 - acc: 1.0000Epoch 01563: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.6227e-06 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9949\n",
      "Epoch 1564/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5666e-07 - acc: 1.0000Epoch 01564: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4303e-06 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9949\n",
      "Epoch 1565/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2234e-06 - acc: 1.0000Epoch 01565: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1737e-06 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9949\n",
      "Epoch 1566/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2078e-05 - acc: 1.0000Epoch 01566: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.1237e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1567/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3455e-06 - acc: 1.0000Epoch 01567: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 3.1563e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1568/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7736e-07 - acc: 1.0000Epoch 01568: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 5.4512e-07 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 1569/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2121e-05 - acc: 1.0000Epoch 01569: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0572e-05 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 1570/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9815e-07 - acc: 1.0000Epoch 01570: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.5014e-07 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 1571/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.8119e-07 - acc: 1.0000Epoch 01571: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 6.4755e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1572/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0963e-06 - acc: 1.0000Epoch 01572: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.9565e-06 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9949\n",
      "Epoch 1573/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6277e-06 - acc: 1.0000Epoch 01573: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 3.4452e-06 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 1574/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1026e-05 - acc: 1.0000Epoch 01574: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 5.4405e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9949\n",
      "Epoch 1575/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3866e-04 - acc: 1.0000Epoch 01575: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 2.2182e-04 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9949\n",
      "Epoch 1576/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1279e-07 - acc: 1.0000Epoch 01576: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 4.4170e-07 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9949\n",
      "Epoch 1577/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6274e-06 - acc: 1.0000Epoch 01577: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 5.2449e-06 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9949\n",
      "Epoch 1578/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0261e-06 - acc: 1.0000Epoch 01578: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 1.8934e-06 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9949\n",
      "Epoch 1579/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4057e-04 - acc: 1.0000Epoch 01579: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.3065e-04 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 1580/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4481e-06 - acc: 1.0000Epoch 01580: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2834e-06 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9949\n",
      "Epoch 1581/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0810e-06 - acc: 1.0000Epoch 01581: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.7809e-06 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9949\n",
      "Epoch 1582/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4183e-07 - acc: 1.0000Epoch 01582: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.0519e-07 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9949\n",
      "Epoch 1583/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1973e-06 - acc: 1.0000Epoch 01583: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1247e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1584/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4477e-06 - acc: 1.0000Epoch 01584: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3095e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1585/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6071e-07 - acc: 1.0000Epoch 01585: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 4.4524e-07 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1586/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5102e-05 - acc: 1.0000Epoch 01586: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 4.1927e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 1587/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.3379e-06 - acc: 1.0000Epoch 01587: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.1863e-05 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 1588/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3208e-06 - acc: 1.0000Epoch 01588: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 2.0507e-06 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 1589/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3940e-05 - acc: 1.0000Epoch 01589: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 5.0147e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 1590/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0592e-06 - acc: 1.0000Epoch 01590: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.0080e-06 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1591/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.4854e-06 - acc: 1.0000Epoch 01591: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 6.9431e-06 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9949\n",
      "Epoch 1592/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3927e-05 - acc: 1.0000Epoch 01592: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 1.2962e-05 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9949\n",
      "Epoch 1593/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8026e-05 - acc: 1.0000Epoch 01593: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 5.4057e-05 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9949\n",
      "Epoch 1594/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.0493e-07 - acc: 1.0000Epoch 01594: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 8.4066e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 1595/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9768e-05 - acc: 1.0000Epoch 01595: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7688e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1596/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2926e-05 - acc: 1.0000Epoch 01596: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 2.1555e-05 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1597/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5185e-05 - acc: 1.0000Epoch 01597: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 1.4173e-05 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 1598/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7994e-06 - acc: 1.0000Epoch 01598: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.6811e-06 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 1599/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.8348e-05 - acc: 1.0000Epoch 01599: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 6.3626e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1600/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2125e-06 - acc: 1.0000Epoch 01600: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1868e-06 - acc: 1.0000 - val_loss: 9.0106e-04 - val_acc: 1.0000\n",
      "Epoch 1601/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8705e-07 - acc: 1.0000Epoch 01601: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 7.4043e-07 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1602/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9352e-07 - acc: 1.0000Epoch 01602: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.4599e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1603/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4653e-06 - acc: 1.0000Epoch 01603: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 3.2424e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1604/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9909e-06 - acc: 1.0000Epoch 01604: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 1.8620e-06 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9949\n",
      "Epoch 1605/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5206e-06 - acc: 1.0000Epoch 01605: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 2.3518e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1606/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.8365e-05 - acc: 1.0000Epoch 01606: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 8.2161e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1607/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1389e-06 - acc: 1.0000Epoch 01607: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 2.9448e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1608/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2853e-06 - acc: 1.0000Epoch 01608: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.0703e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 1609/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5339e-06 - acc: 1.0000Epoch 01609: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4411e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1610/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8768e-05 - acc: 1.0000Epoch 01610: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 3.6037e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9949\n",
      "Epoch 1611/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9071e-05 - acc: 1.0000Epoch 01611: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 2.7032e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1612/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9160e-04 - acc: 1.0000Epoch 01612: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 3.6393e-04 - acc: 1.0000 - val_loss: 9.3360e-04 - val_acc: 1.0000\n",
      "Epoch 1613/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0302e-04 - acc: 1.0000Epoch 01613: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 9.9487e-05 - acc: 1.0000 - val_loss: 8.6930e-04 - val_acc: 1.0000\n",
      "Epoch 1614/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9241e-07 - acc: 1.0000Epoch 01614: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 5.6422e-07 - acc: 1.0000 - val_loss: 8.0682e-04 - val_acc: 1.0000\n",
      "Epoch 1615/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5432e-07 - acc: 1.0000Epoch 01615: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 7.1663e-07 - acc: 1.0000 - val_loss: 8.6636e-04 - val_acc: 1.0000\n",
      "Epoch 1616/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3317e-05 - acc: 1.0000Epoch 01616: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.2387e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 1617/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0596e-07 - acc: 1.0000Epoch 01617: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 5.5205e-07 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 1618/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8144e-07 - acc: 1.0000Epoch 01618: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 4.4765e-07 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1619/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2601e-05 - acc: 1.0000Epoch 01619: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 5.9623e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1620/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8235e-05 - acc: 1.0000Epoch 01620: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.6994e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1621/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9969e-04 - acc: 1.0000Epoch 01621: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 8.3623e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 1622/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1850e-06 - acc: 1.0000Epoch 01622: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1752e-06 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9949\n",
      "Epoch 1623/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9438e-07 - acc: 1.0000Epoch 01623: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 2.8305e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9949\n",
      "Epoch 1624/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6197e-06 - acc: 1.0000Epoch 01624: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5156e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9949\n",
      "Epoch 1625/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1095e-06 - acc: 1.0000Epoch 01625: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0724e-06 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 1626/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.3565e-07 - acc: 1.0000Epoch 01626: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.3760e-07 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1627/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2450e-05 - acc: 1.0000Epoch 01627: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3058e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1628/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0302e-05 - acc: 1.0000Epoch 01628: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 9.5826e-06 - acc: 1.0000 - val_loss: 6.5004e-04 - val_acc: 1.0000\n",
      "Epoch 1629/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1996e-07 - acc: 1.0000Epoch 01629: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0760e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1630/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1432e-07 - acc: 1.0000Epoch 01630: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 3.9346e-07 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 1631/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9759e-05 - acc: 1.0000Epoch 01631: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 3.6978e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1632/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5085e-06 - acc: 1.0000Epoch 01632: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 5.1424e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1633/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9412e-07 - acc: 1.0000Epoch 01633: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 8.6755e-07 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1634/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9680e-06 - acc: 1.0000Epoch 01634: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 2.8745e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9949\n",
      "Epoch 1635/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7604e-07 - acc: 1.0000Epoch 01635: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 1.3658e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1636/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.5809e-04 - acc: 0.9986Epoch 01636: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 8.9035e-04 - acc: 0.9987 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 1637/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3842e-04 - acc: 1.0000Epoch 01637: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 5.1267e-04 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 1638/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9298e-06 - acc: 1.0000Epoch 01638: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 2.7532e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1639/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3323e-06 - acc: 1.0000Epoch 01639: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2490e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1640/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3826e-05 - acc: 1.0000Epoch 01640: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1032e-05 - acc: 1.0000 - val_loss: 4.6859e-04 - val_acc: 1.0000\n",
      "Epoch 1641/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6176e-06 - acc: 1.0000Epoch 01641: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.5120e-06 - acc: 1.0000 - val_loss: 3.4626e-04 - val_acc: 1.0000\n",
      "Epoch 1642/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0428e-07 - acc: 1.0000Epoch 01642: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8413e-07 - acc: 1.0000 - val_loss: 5.0209e-04 - val_acc: 1.0000\n",
      "Epoch 1643/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3248e-07 - acc: 1.0000Epoch 01643: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 5.3713e-07 - acc: 1.0000 - val_loss: 8.2530e-04 - val_acc: 1.0000\n",
      "Epoch 1644/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0164e-05 - acc: 1.0000Epoch 01644: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 9.4708e-06 - acc: 1.0000 - val_loss: 3.0601e-04 - val_acc: 1.0000\n",
      "Epoch 1645/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6051e-06 - acc: 1.0000Epoch 01645: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 3.3769e-06 - acc: 1.0000 - val_loss: 3.1765e-04 - val_acc: 1.0000\n",
      "Epoch 1646/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2816e-06 - acc: 1.0000Epoch 01646: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0586e-06 - acc: 1.0000 - val_loss: 5.0411e-04 - val_acc: 1.0000\n",
      "Epoch 1647/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2391e-05 - acc: 1.0000Epoch 01647: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8372e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1648/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9191e-07 - acc: 1.0000Epoch 01648: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 4.6556e-07 - acc: 1.0000 - val_loss: 7.3449e-04 - val_acc: 1.0000\n",
      "Epoch 1649/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5672e-05 - acc: 1.0000Epoch 01649: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 2.7572e-05 - acc: 1.0000 - val_loss: 9.7738e-04 - val_acc: 1.0000\n",
      "Epoch 1650/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3096e-06 - acc: 1.0000Epoch 01650: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.4697e-06 - acc: 1.0000 - val_loss: 8.2323e-04 - val_acc: 1.0000\n",
      "Epoch 1651/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.1063e-07 - acc: 1.0000Epoch 01651: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 8.5851e-07 - acc: 1.0000 - val_loss: 4.5416e-04 - val_acc: 1.0000\n",
      "Epoch 1652/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2697e-05 - acc: 1.0000Epoch 01652: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 2.1291e-05 - acc: 1.0000 - val_loss: 3.2319e-04 - val_acc: 1.0000\n",
      "Epoch 1653/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9444e-04 - acc: 1.0000Epoch 01653: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.6851e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1654/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1385e-05 - acc: 1.0000Epoch 01654: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 5.7093e-05 - acc: 1.0000 - val_loss: 2.1777e-04 - val_acc: 1.0000\n",
      "Epoch 1655/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0892e-07 - acc: 1.0000Epoch 01655: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 4.8415e-07 - acc: 1.0000 - val_loss: 3.9008e-04 - val_acc: 1.0000\n",
      "Epoch 1656/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5824e-06 - acc: 1.0000Epoch 01656: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 3.3581e-06 - acc: 1.0000 - val_loss: 4.9761e-04 - val_acc: 1.0000\n",
      "Epoch 1657/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5233e-06 - acc: 1.0000Epoch 01657: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 1.4240e-06 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9949\n",
      "Epoch 1658/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2058e-06 - acc: 1.0000Epoch 01658: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 4.0239e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1659/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6115e-06 - acc: 1.0000Epoch 01659: val_loss did not improve\n",
      "792/792 [==============================] - 1s 971us/step - loss: 4.3018e-06 - acc: 1.0000 - val_loss: 5.8655e-04 - val_acc: 1.0000\n",
      "Epoch 1660/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5998e-05 - acc: 1.0000Epoch 01660: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 3.3469e-05 - acc: 1.0000 - val_loss: 5.9623e-04 - val_acc: 1.0000\n",
      "Epoch 1661/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6947e-06 - acc: 1.0000Epoch 01661: val_loss did not improve\n",
      "792/792 [==============================] - 1s 959us/step - loss: 1.6048e-06 - acc: 1.0000 - val_loss: 4.4834e-04 - val_acc: 1.0000\n",
      "Epoch 1662/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5952e-06 - acc: 1.0000Epoch 01662: val_loss did not improve\n",
      "792/792 [==============================] - 1s 967us/step - loss: 6.1416e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1663/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4899e-06 - acc: 1.0000Epoch 01663: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 1.3936e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1664/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9056e-07 - acc: 1.0000Epoch 01664: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 1.7629e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1665/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8255e-06 - acc: 1.0000Epoch 01665: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 1.7072e-06 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 1666/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6211e-06 - acc: 1.0000Epoch 01666: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 2.4841e-06 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9949\n",
      "Epoch 1667/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0015 - acc: 0.9986Epoch 01667: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 0.0014 - acc: 0.9987 - val_loss: 0.0067 - val_acc: 0.9949\n",
      "Epoch 1668/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0811e-06 - acc: 1.0000Epoch 01668: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.0131e-06 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9949\n",
      "Epoch 1669/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4768e-07 - acc: 1.0000Epoch 01669: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 6.1092e-07 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9949\n",
      "Epoch 1670/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4962e-07 - acc: 1.0000Epoch 01670: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 3.3348e-07 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 1671/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1302e-06 - acc: 1.0000Epoch 01671: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 3.8846e-06 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9949\n",
      "Epoch 1672/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2639e-05 - acc: 1.0000Epoch 01672: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1852e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 1673/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4638e-06 - acc: 1.0000Epoch 01673: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3747e-06 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9949\n",
      "Epoch 1674/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5305e-06 - acc: 1.0000Epoch 01674: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 2.2354e-06 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9949\n",
      "Epoch 1675/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6986e-05 - acc: 1.0000Epoch 01675: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5794e-05 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9949\n",
      "Epoch 1676/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7275e-06 - acc: 1.0000Epoch 01676: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 3.1966e-06 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9949\n",
      "Epoch 1677/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6522e-06 - acc: 1.0000Epoch 01677: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 3.4024e-06 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9949\n",
      "Epoch 1678/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2085e-06 - acc: 1.0000Epoch 01678: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1385e-06 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9949\n",
      "Epoch 1679/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.6394e-06 - acc: 1.0000Epoch 01679: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.0488e-06 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 1680/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2639e-05 - acc: 1.0000Epoch 01680: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1758e-05 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9949\n",
      "Epoch 1681/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6022e-07 - acc: 1.0000Epoch 01681: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3312e-07 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9949\n",
      "Epoch 1682/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9115e-06 - acc: 1.0000Epoch 01682: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 1.9368e-06 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9949\n",
      "Epoch 1683/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 0.9986Epoch 01683: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 0.0012 - acc: 0.9987 - val_loss: 0.0137 - val_acc: 0.9949\n",
      "Epoch 1684/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9566e-04 - acc: 1.0000Epoch 01684: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7478e-04 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9949\n",
      "Epoch 1685/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9593e-04 - acc: 1.0000Epoch 01685: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.8210e-04 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9949\n",
      "Epoch 1686/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6920e-06 - acc: 1.0000Epoch 01686: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 6.2502e-06 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9949\n",
      "Epoch 1687/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.0301e-07 - acc: 1.0000Epoch 01687: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 9.6493e-07 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9949\n",
      "Epoch 1688/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3267e-06 - acc: 1.0000Epoch 01688: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 3.1035e-06 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 0.9899\n",
      "Epoch 1689/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6554e-04 - acc: 1.0000Epoch 01689: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.5385e-04 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9949\n",
      "Epoch 1690/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1087e-05 - acc: 1.0000Epoch 01690: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.9741e-05 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9949\n",
      "Epoch 1691/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1911e-07 - acc: 1.0000Epoch 01691: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 4.5819e-07 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 1692/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7509e-04 - acc: 1.0000Epoch 01692: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.6273e-04 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9949\n",
      "Epoch 1693/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8182e-04 - acc: 1.0000Epoch 01693: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6191e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9949\n",
      "Epoch 1694/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1039e-06 - acc: 1.0000Epoch 01694: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0410e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9949\n",
      "Epoch 1695/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4403e-06 - acc: 1.0000Epoch 01695: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5953e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1696/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1548e-06 - acc: 1.0000Epoch 01696: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0816e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1697/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0944e-06 - acc: 1.0000Epoch 01697: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.1111e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1698/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8440e-06 - acc: 1.0000Epoch 01698: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.2931e-06 - acc: 1.0000 - val_loss: 7.0554e-04 - val_acc: 1.0000\n",
      "Epoch 1699/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9222e-06 - acc: 1.0000Epoch 01699: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 4.5917e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1700/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4512e-06 - acc: 1.0000Epoch 01700: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 1.3593e-06 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9949\n",
      "Epoch 1701/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0355e-05 - acc: 1.0000Epoch 01701: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.8966e-05 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9949\n",
      "Epoch 1702/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4809e-06 - acc: 1.0000Epoch 01702: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 3.3190e-06 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9949\n",
      "Epoch 1703/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2788e-06 - acc: 1.0000Epoch 01703: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.1942e-06 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9949\n",
      "Epoch 1704/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2090e-06 - acc: 1.0000Epoch 01704: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0612e-06 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9949\n",
      "Epoch 1705/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2796e-06 - acc: 1.0000Epoch 01705: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.9875e-06 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9949\n",
      "Epoch 1706/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9651e-07 - acc: 1.0000Epoch 01706: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.4554e-07 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9949\n",
      "Epoch 1707/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3876e-06 - acc: 1.0000Epoch 01707: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3517e-06 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 1708/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.4068e-07 - acc: 1.0000Epoch 01708: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1637e-07 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1709/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.0997e-07 - acc: 1.0000Epoch 01709: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3489e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1710/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2961e-07 - acc: 1.0000Epoch 01710: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 3.2324e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1711/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9834e-07 - acc: 1.0000Epoch 01711: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 6.5965e-07 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9949\n",
      "Epoch 1712/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9144e-06 - acc: 1.0000Epoch 01712: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 5.5195e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1713/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0219e-06 - acc: 1.0000Epoch 01713: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 3.8159e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1714/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5533e-06 - acc: 1.0000Epoch 01714: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 2.3850e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1715/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7832e-06 - acc: 1.0000Epoch 01715: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6244e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1716/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5226e-06 - acc: 1.0000Epoch 01716: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5044e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1717/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0594e-07 - acc: 1.0000Epoch 01717: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.4248e-07 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1718/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0686e-07 - acc: 1.0000Epoch 01718: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 6.6553e-07 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 1719/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8166e-06 - acc: 1.0000Epoch 01719: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 1.7632e-06 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 1720/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5738e-07 - acc: 1.0000Epoch 01720: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 7.1348e-07 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9949\n",
      "Epoch 1721/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1627e-07 - acc: 1.0000Epoch 01721: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 3.9880e-07 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9949\n",
      "Epoch 1722/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8902e-06 - acc: 1.0000Epoch 01722: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 2.6942e-06 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9949\n",
      "Epoch 1723/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9475e-07 - acc: 1.0000Epoch 01723: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7590e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1724/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.0004e-06 - acc: 1.0000Epoch 01724: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 5.5989e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1725/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7279e-06 - acc: 1.0000Epoch 01725: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.7179e-06 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1726/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0357e-07 - acc: 1.0000Epoch 01726: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 4.8618e-07 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9949\n",
      "Epoch 1727/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1928e-06 - acc: 1.0000Epoch 01727: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 2.0951e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1728/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.4678e-06 - acc: 1.0000Epoch 01728: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 6.0233e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1729/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3169e-06 - acc: 1.0000Epoch 01729: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 3.0910e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1730/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5792e-07 - acc: 1.0000Epoch 01730: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 5.2690e-07 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 1731/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3878e-07 - acc: 1.0000Epoch 01731: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 4.2476e-07 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1732/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7658e-06 - acc: 1.0000Epoch 01732: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.0690e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1733/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3685e-06 - acc: 1.0000Epoch 01733: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 1.5247e-06 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 1734/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1518e-05 - acc: 1.0000Epoch 01734: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 1.0713e-05 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9949\n",
      "Epoch 1735/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.9147e-07 - acc: 1.0000Epoch 01735: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1914e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1736/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4007e-06 - acc: 1.0000Epoch 01736: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 4.0980e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 1737/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4190e-07 - acc: 1.0000Epoch 01737: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.7131e-07 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1738/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.9180e-07 - acc: 1.0000Epoch 01738: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.0475e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1739/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.5676e-07 - acc: 1.0000Epoch 01739: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 7.1198e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1740/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5624e-06 - acc: 1.0000Epoch 01740: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.4610e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1741/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6224e-06 - acc: 1.0000Epoch 01741: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5168e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1742/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5951e-07 - acc: 1.0000Epoch 01742: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4486e-07 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1743/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1945e-06 - acc: 1.0000Epoch 01743: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 6.7386e-06 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9949\n",
      "Epoch 1744/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9513e-07 - acc: 1.0000Epoch 01744: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 4.9227e-07 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1745/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.7194e-06 - acc: 1.0000Epoch 01745: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.1888e-06 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 1746/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3209e-06 - acc: 1.0000Epoch 01746: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 4.0241e-06 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9949\n",
      "Epoch 1747/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9530e-07 - acc: 1.0000Epoch 01747: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 4.0032e-07 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 1748/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5148e-06 - acc: 1.0000Epoch 01748: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.2860e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1749/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3488e-06 - acc: 1.0000Epoch 01749: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 2.2575e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 1750/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4962e-07 - acc: 1.0000Epoch 01750: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 3.3332e-07 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9949\n",
      "Epoch 1751/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1378e-04 - acc: 1.0000Epoch 01751: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 1.0577e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9949\n",
      "Epoch 1752/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7107e-05 - acc: 1.0000Epoch 01752: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 1.5907e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 1753/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.9653e-07 - acc: 1.0000Epoch 01753: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 4.7225e-07 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 1754/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0060e-07 - acc: 1.0000Epoch 01754: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5950e-07 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9949\n",
      "Epoch 1755/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8505e-06 - acc: 1.0000Epoch 01755: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 3.5955e-06 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9949\n",
      "Epoch 1756/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4061e-07 - acc: 1.0000Epoch 01756: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3591e-07 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9949\n",
      "Epoch 1757/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1544e-06 - acc: 1.0000Epoch 01757: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.0821e-06 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9949\n",
      "Epoch 1758/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9359e-06 - acc: 1.0000Epoch 01758: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 2.7383e-06 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9949\n",
      "Epoch 1759/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1760e-06 - acc: 1.0000Epoch 01759: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 3.0068e-06 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9949\n",
      "Epoch 1760/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1163e-07 - acc: 1.0000Epoch 01760: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 5.7839e-07 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9949\n",
      "Epoch 1761/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8592e-07 - acc: 1.0000Epoch 01761: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 4.6112e-07 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9949\n",
      "Epoch 1762/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1200e-06 - acc: 1.0000Epoch 01762: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 5.7067e-06 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9899\n",
      "Epoch 1763/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3824e-06 - acc: 1.0000Epoch 01763: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 5.0119e-06 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9949\n",
      "Epoch 1764/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.7219e-07 - acc: 1.0000Epoch 01764: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.4107e-07 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9949\n",
      "Epoch 1765/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.6567e-07 - acc: 1.0000Epoch 01765: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 9.0582e-07 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9949\n",
      "Epoch 1766/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.2493e-07 - acc: 1.0000Epoch 01766: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 6.9512e-07 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9949\n",
      "Epoch 1767/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.8860e-06 - acc: 1.0000Epoch 01767: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 6.4085e-06 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9949\n",
      "Epoch 1768/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.7827e-07 - acc: 1.0000Epoch 01768: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 9.1822e-07 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9949\n",
      "Epoch 1769/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0015 - acc: 0.9986Epoch 01769: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 0.0014 - acc: 0.9987 - val_loss: 0.0068 - val_acc: 0.9949\n",
      "Epoch 1770/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6649e-07 - acc: 1.0000Epoch 01770: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 4.5518e-07 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 1771/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.5462e-07 - acc: 1.0000Epoch 01771: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.7614e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1772/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5772e-06 - acc: 1.0000Epoch 01772: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4984e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1773/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7167e-07 - acc: 1.0000Epoch 01773: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 4.4780e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1774/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8554e-05 - acc: 1.0000Epoch 01774: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 4.5876e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1775/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5374e-07 - acc: 1.0000Epoch 01775: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 3.3761e-07 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 1776/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0039e-07 - acc: 1.0000Epoch 01776: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.8141e-07 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 1777/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9755e-07 - acc: 1.0000Epoch 01777: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 6.5703e-07 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 1778/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8659e-07 - acc: 1.0000Epoch 01778: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 5.5385e-07 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9949\n",
      "Epoch 1779/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8986e-05 - acc: 1.0000Epoch 01779: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 3.6244e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1780/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2675e-06 - acc: 1.0000Epoch 01780: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.8340e-06 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1781/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 0.0018 - acc: 0.9986Epoch 01781: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.9987 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1782/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8614e-07 - acc: 1.0000Epoch 01782: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 7.4072e-07 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1783/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5504e-07 - acc: 1.0000Epoch 01783: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.1988e-07 - acc: 1.0000 - val_loss: 5.0587e-04 - val_acc: 1.0000\n",
      "Epoch 1784/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0771e-07 - acc: 1.0000Epoch 01784: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 6.6745e-07 - acc: 1.0000 - val_loss: 5.4596e-04 - val_acc: 1.0000\n",
      "Epoch 1785/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4063e-06 - acc: 1.0000Epoch 01785: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 3.1921e-06 - acc: 1.0000 - val_loss: 6.8920e-04 - val_acc: 1.0000\n",
      "Epoch 1786/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7207e-07 - acc: 1.0000Epoch 01786: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 4.4840e-07 - acc: 1.0000 - val_loss: 9.2491e-04 - val_acc: 1.0000\n",
      "Epoch 1787/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9446e-07 - acc: 1.0000Epoch 01787: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 2.8523e-07 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1788/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8203e-07 - acc: 1.0000Epoch 01788: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 7.3682e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1789/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9244e-06 - acc: 1.0000Epoch 01789: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.7967e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1790/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.0003e-05 - acc: 1.0000Epoch 01790: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 8.3660e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1791/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0721e-06 - acc: 1.0000Epoch 01791: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 1.0209e-06 - acc: 1.0000 - val_loss: 8.0797e-04 - val_acc: 1.0000\n",
      "Epoch 1792/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2575e-05 - acc: 1.0000Epoch 01792: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8884e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1793/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9956e-07 - acc: 1.0000Epoch 01793: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4423e-07 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1794/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1927e-07 - acc: 1.0000Epoch 01794: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1611e-07 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1795/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9639e-07 - acc: 1.0000Epoch 01795: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.9253e-07 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 1796/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.4829e-07 - acc: 1.0000Epoch 01796: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2420e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1797/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4066e-05 - acc: 1.0000Epoch 01797: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 2.3674e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1798/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0729e-05 - acc: 1.0000Epoch 01798: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.9798e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1799/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0820e-07 - acc: 1.0000Epoch 01799: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8092e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1800/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2993e-07 - acc: 1.0000Epoch 01800: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 4.4742e-07 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9949\n",
      "Epoch 1801/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9578e-06 - acc: 1.0000Epoch 01801: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8278e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9949\n",
      "Epoch 1802/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8976e-06 - acc: 1.0000Epoch 01802: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7720e-06 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9949\n",
      "Epoch 1803/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3215e-07 - acc: 1.0000Epoch 01803: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 4.1198e-07 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9949\n",
      "Epoch 1804/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5238e-04 - acc: 1.0000Epoch 01804: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 6.0635e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9949\n",
      "Epoch 1805/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0645e-06 - acc: 1.0000Epoch 01805: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 2.8611e-06 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9949\n",
      "Epoch 1806/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.4624e-07 - acc: 1.0000Epoch 01806: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.0472e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1807/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5476e-07 - acc: 1.0000Epoch 01807: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 5.3247e-07 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1808/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.2947e-07 - acc: 1.0000Epoch 01808: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.9919e-07 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1809/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6954e-06 - acc: 1.0000Epoch 01809: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5843e-06 - acc: 1.0000 - val_loss: 6.0472e-04 - val_acc: 1.0000\n",
      "Epoch 1810/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.2574e-05 - acc: 1.0000Epoch 01810: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.8159e-05 - acc: 1.0000 - val_loss: 8.9415e-04 - val_acc: 1.0000\n",
      "Epoch 1811/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1858e-07 - acc: 1.0000Epoch 01811: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 5.8846e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1812/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7187e-07 - acc: 1.0000Epoch 01812: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6596e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1813/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3876e-06 - acc: 1.0000Epoch 01813: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3007e-06 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9949\n",
      "Epoch 1814/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5984e-06 - acc: 1.0000Epoch 01814: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4938e-06 - acc: 1.0000 - val_loss: 1.8987e-04 - val_acc: 1.0000\n",
      "Epoch 1815/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4210e-06 - acc: 1.0000Epoch 01815: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.7100e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1816/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4346e-05 - acc: 1.0000Epoch 01816: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 2.2666e-05 - acc: 1.0000 - val_loss: 9.7080e-04 - val_acc: 1.0000\n",
      "Epoch 1817/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9152e-07 - acc: 1.0000Epoch 01817: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 7.4760e-07 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1818/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0852e-06 - acc: 1.0000Epoch 01818: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 7.0325e-06 - acc: 1.0000 - val_loss: 2.1900e-04 - val_acc: 1.0000\n",
      "Epoch 1819/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8528e-06 - acc: 1.0000Epoch 01819: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.9031e-06 - acc: 1.0000 - val_loss: 1.9374e-04 - val_acc: 1.0000\n",
      "Epoch 1820/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0059e-05 - acc: 1.0000Epoch 01820: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 6.5114e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 1821/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9373e-07 - acc: 1.0000Epoch 01821: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 2.8866e-05 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9949\n",
      "Epoch 1822/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7353e-06 - acc: 1.0000Epoch 01822: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 5.3437e-06 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9949\n",
      "Epoch 1823/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8972e-06 - acc: 1.0000Epoch 01823: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 3.6406e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 1824/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5471e-06 - acc: 1.0000Epoch 01824: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 1.4466e-06 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 1825/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.6630e-07 - acc: 1.0000Epoch 01825: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 9.0640e-07 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 1826/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.0693e-07 - acc: 1.0000Epoch 01826: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 6.6868e-07 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1827/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.6089e-04 - acc: 0.9986Epoch 01827: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.9296e-04 - acc: 0.9987 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 1828/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2273e-07 - acc: 1.0000Epoch 01828: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0834e-07 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 1829/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7482e-07 - acc: 1.0000Epoch 01829: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 5.7032e-07 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1830/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8046e-04 - acc: 1.0000Epoch 01830: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.6912e-04 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9949\n",
      "Epoch 1831/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5099e-07 - acc: 1.0000Epoch 01831: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 3.5101e-07 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9949\n",
      "Epoch 1832/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7445e-06 - acc: 1.0000Epoch 01832: val_loss did not improve\n",
      "792/792 [==============================] - 1s 970us/step - loss: 1.6306e-06 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 1833/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5165e-06 - acc: 1.0000Epoch 01833: val_loss did not improve\n",
      "792/792 [==============================] - 1s 964us/step - loss: 3.3007e-06 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9949\n",
      "Epoch 1834/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1949e-07 - acc: 1.0000Epoch 01834: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 3.0653e-07 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9949\n",
      "Epoch 1835/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0446e-06 - acc: 1.0000Epoch 01835: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 3.7682e-06 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9949\n",
      "Epoch 1836/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4587e-05 - acc: 1.0000Epoch 01836: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 1.3570e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9949\n",
      "Epoch 1837/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.5169e-07 - acc: 1.0000Epoch 01837: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 8.0923e-07 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9949\n",
      "Epoch 1838/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.4993e-07 - acc: 1.0000Epoch 01838: val_loss did not improve\n",
      "792/792 [==============================] - 1s 962us/step - loss: 8.9119e-07 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9949\n",
      "Epoch 1839/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5834e-04 - acc: 1.0000Epoch 01839: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 3.3305e-04 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9949\n",
      "Epoch 1840/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0651e-07 - acc: 1.0000Epoch 01840: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 2.8525e-06 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 1841/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2018e-07 - acc: 1.0000Epoch 01841: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 4.9386e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1842/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8459e-07 - acc: 1.0000Epoch 01842: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 5.7208e-07 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1843/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7260e-06 - acc: 1.0000Epoch 01843: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.6124e-06 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1844/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5478e-06 - acc: 1.0000Epoch 01844: val_loss did not improve\n",
      "792/792 [==============================] - 1s 972us/step - loss: 6.0933e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1845/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5636e-05 - acc: 1.0000Epoch 01845: val_loss did not improve\n",
      "792/792 [==============================] - 1s 980us/step - loss: 1.4541e-05 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9949\n",
      "Epoch 1846/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1425e-06 - acc: 1.0000Epoch 01846: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 6.6459e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1847/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.2587e-07 - acc: 1.0000Epoch 01847: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 2.1848e-07 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1848/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3699e-06 - acc: 1.0000Epoch 01848: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.3323e-06 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9949\n",
      "Epoch 1849/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.7331e-06 - acc: 1.0000Epoch 01849: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 6.2660e-06 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 1850/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5132e-07 - acc: 1.0000Epoch 01850: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4198e-07 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 1851/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0509e-07 - acc: 1.0000Epoch 01851: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.4057e-07 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9949\n",
      "Epoch 1852/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7144e-06 - acc: 1.0000Epoch 01852: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 1.8055e-06 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9949\n",
      "Epoch 1853/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.8622e-07 - acc: 1.0000Epoch 01853: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 9.2499e-07 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9949\n",
      "Epoch 1854/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1135e-06 - acc: 1.0000Epoch 01854: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 1.9724e-06 - acc: 1.0000 - val_loss: 9.0880e-04 - val_acc: 1.0000\n",
      "Epoch 1855/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.5057e-06 - acc: 1.0000Epoch 01855: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1000us/step - loss: 8.8423e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1856/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7562e-06 - acc: 1.0000Epoch 01856: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.6405e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1857/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4719e-06 - acc: 1.0000Epoch 01857: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3265e-06 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1858/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.1719e-06 - acc: 1.0000Epoch 01858: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.8149e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1859/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.1388e-07 - acc: 1.0000Epoch 01859: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.5515e-07 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1860/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.3871e-07 - acc: 1.0000Epoch 01860: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 7.9725e-07 - acc: 1.0000 - val_loss: 4.2386e-04 - val_acc: 1.0000\n",
      "Epoch 1861/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2534e-06 - acc: 1.0000Epoch 01861: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.1742e-06 - acc: 1.0000 - val_loss: 2.4159e-04 - val_acc: 1.0000\n",
      "Epoch 1862/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4493e-06 - acc: 1.0000Epoch 01862: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 2.2855e-06 - acc: 1.0000 - val_loss: 3.4042e-04 - val_acc: 1.0000\n",
      "Epoch 1863/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1802e-07 - acc: 1.0000Epoch 01863: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.8275e-07 - acc: 1.0000 - val_loss: 2.3224e-04 - val_acc: 1.0000\n",
      "Epoch 1864/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8021e-06 - acc: 1.0000Epoch 01864: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7923e-06 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9949\n",
      "Epoch 1865/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8750e-07 - acc: 1.0000Epoch 01865: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 2.9923e-07 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9949\n",
      "Epoch 1866/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.3523e-07 - acc: 1.0000Epoch 01866: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 7.8490e-07 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9949\n",
      "Epoch 1867/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.5436e-05 - acc: 1.0000Epoch 01867: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 6.1209e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9949\n",
      "Epoch 1868/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1318e-06 - acc: 1.0000Epoch 01868: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 1.0612e-06 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 1869/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8873e-06 - acc: 1.0000Epoch 01869: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 1.7644e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1870/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6528e-05 - acc: 1.0000Epoch 01870: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 2.4661e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 1871/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2775e-07 - acc: 1.0000Epoch 01871: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 3.3972e-07 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9949\n",
      "Epoch 1872/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7904e-07 - acc: 1.0000Epoch 01872: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 4.5375e-07 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 1873/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.2526e-07 - acc: 1.0000Epoch 01873: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 6.8241e-07 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 1874/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.3648e-06 - acc: 1.0000Epoch 01874: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.7877e-06 - acc: 1.0000 - val_loss: 7.6623e-04 - val_acc: 1.0000\n",
      "Epoch 1875/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0047e-06 - acc: 1.0000Epoch 01875: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 9.4252e-07 - acc: 1.0000 - val_loss: 7.3034e-04 - val_acc: 1.0000\n",
      "Epoch 1876/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1661e-06 - acc: 1.0000Epoch 01876: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.1087e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1877/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5617e-06 - acc: 1.0000Epoch 01877: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 2.4662e-06 - acc: 1.0000 - val_loss: 8.6446e-04 - val_acc: 1.0000\n",
      "Epoch 1878/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7146e-07 - acc: 1.0000Epoch 01878: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6438e-07 - acc: 1.0000 - val_loss: 6.0574e-04 - val_acc: 1.0000\n",
      "Epoch 1879/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5352e-05 - acc: 1.0000Epoch 01879: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 3.2965e-05 - acc: 1.0000 - val_loss: 5.3701e-04 - val_acc: 1.0000\n",
      "Epoch 1880/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8538e-05 - acc: 1.0000Epoch 01880: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 2.6543e-05 - acc: 1.0000 - val_loss: 6.9237e-04 - val_acc: 1.0000\n",
      "Epoch 1881/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0209e-04 - acc: 1.0000Epoch 01881: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.5198e-05 - acc: 1.0000 - val_loss: 9.2764e-04 - val_acc: 1.0000\n",
      "Epoch 1882/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.2390e-05 - acc: 1.0000Epoch 01882: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 8.5874e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1883/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.7342e-06 - acc: 1.0000Epoch 01883: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 4.4201e-06 - acc: 1.0000 - val_loss: 8.9740e-04 - val_acc: 1.0000\n",
      "Epoch 1884/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.8356e-07 - acc: 1.0000Epoch 01884: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.4381e-07 - acc: 1.0000 - val_loss: 7.6664e-04 - val_acc: 1.0000\n",
      "Epoch 1885/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.3085e-07 - acc: 1.0000Epoch 01885: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 6.8775e-07 - acc: 1.0000 - val_loss: 5.3571e-04 - val_acc: 1.0000\n",
      "Epoch 1886/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4910e-06 - acc: 1.0000Epoch 01886: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 2.3278e-06 - acc: 1.0000 - val_loss: 8.6151e-04 - val_acc: 1.0000\n",
      "Epoch 1887/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2784e-06 - acc: 1.0000Epoch 01887: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2041e-06 - acc: 1.0000 - val_loss: 9.4862e-04 - val_acc: 1.0000\n",
      "Epoch 1888/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5911e-07 - acc: 1.0000Epoch 01888: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 4.3546e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1889/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.7901e-06 - acc: 1.0000Epoch 01889: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 7.2477e-06 - acc: 1.0000 - val_loss: 5.8301e-04 - val_acc: 1.0000\n",
      "Epoch 1890/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7253e-07 - acc: 1.0000Epoch 01890: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 3.5537e-07 - acc: 1.0000 - val_loss: 8.2394e-04 - val_acc: 1.0000\n",
      "Epoch 1891/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5056e-06 - acc: 1.0000Epoch 01891: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 4.1958e-06 - acc: 1.0000 - val_loss: 8.6338e-04 - val_acc: 1.0000\n",
      "Epoch 1892/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5701e-06 - acc: 1.0000Epoch 01892: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4716e-06 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1893/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.8113e-07 - acc: 1.0000Epoch 01893: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 9.2832e-07 - acc: 1.0000 - val_loss: 3.7571e-04 - val_acc: 1.0000\n",
      "Epoch 1894/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6740e-07 - acc: 1.0000Epoch 01894: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 2.5167e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1895/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8837e-07 - acc: 1.0000Epoch 01895: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.8378e-07 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 1896/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4282e-06 - acc: 1.0000Epoch 01896: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 2.1284e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1897/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1890e-07 - acc: 1.0000Epoch 01897: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 2.1690e-07 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9949\n",
      "Epoch 1898/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0975e-06 - acc: 1.0000Epoch 01898: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 4.0793e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1899/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0805e-05 - acc: 1.0000Epoch 01899: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 1.9344e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 1900/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3163e-06 - acc: 1.0000Epoch 01900: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 3.6160e-06 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9949\n",
      "Epoch 1901/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6403e-06 - acc: 1.0000Epoch 01901: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 2.4620e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1902/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2403e-06 - acc: 1.0000Epoch 01902: val_loss did not improve\n",
      "792/792 [==============================] - 1s 968us/step - loss: 3.0209e-06 - acc: 1.0000 - val_loss: 9.9719e-04 - val_acc: 1.0000\n",
      "Epoch 1903/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6032e-07 - acc: 1.0000Epoch 01903: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 4.4140e-07 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1904/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1518e-07 - acc: 1.0000Epoch 01904: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2690e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1905/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.0674e-07 - acc: 1.0000Epoch 01905: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 9.5159e-06 - acc: 1.0000 - val_loss: 7.1535e-04 - val_acc: 1.0000\n",
      "Epoch 1906/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3553e-05 - acc: 1.0000Epoch 01906: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1213e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1907/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2832e-07 - acc: 1.0000Epoch 01907: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.3370e-07 - acc: 1.0000 - val_loss: 9.4900e-04 - val_acc: 1.0000\n",
      "Epoch 1908/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.7152e-07 - acc: 1.0000Epoch 01908: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4014e-07 - acc: 1.0000 - val_loss: 6.7509e-04 - val_acc: 1.0000\n",
      "Epoch 1909/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.8296e-06 - acc: 1.0000Epoch 01909: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 3.5734e-06 - acc: 1.0000 - val_loss: 7.6974e-04 - val_acc: 1.0000\n",
      "Epoch 1910/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0015e-06 - acc: 1.0000Epoch 01910: val_loss did not improve\n",
      "792/792 [==============================] - 1s 961us/step - loss: 9.4146e-07 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1911/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2832e-06 - acc: 1.0000Epoch 01911: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.2009e-06 - acc: 1.0000 - val_loss: 3.5097e-04 - val_acc: 1.0000\n",
      "Epoch 1912/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3387e-05 - acc: 1.0000Epoch 01912: val_loss did not improve\n",
      "792/792 [==============================] - 1s 982us/step - loss: 4.9636e-05 - acc: 1.0000 - val_loss: 2.4507e-04 - val_acc: 1.0000\n",
      "Epoch 1913/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3840e-05 - acc: 1.0000Epoch 01913: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 1.2881e-05 - acc: 1.0000 - val_loss: 2.4732e-04 - val_acc: 1.0000\n",
      "Epoch 1914/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.7254e-06 - acc: 1.0000Epoch 01914: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 2.5819e-06 - acc: 1.0000 - val_loss: 3.2419e-04 - val_acc: 1.0000\n",
      "Epoch 1915/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8230e-07 - acc: 1.0000Epoch 01915: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.7194e-07 - acc: 1.0000 - val_loss: 5.2418e-04 - val_acc: 1.0000\n",
      "Epoch 1916/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.3614e-07 - acc: 1.0000Epoch 01916: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.1385e-06 - acc: 1.0000 - val_loss: 3.7990e-04 - val_acc: 1.0000\n",
      "Epoch 1917/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.7780e-07 - acc: 1.0000Epoch 01917: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7034e-06 - acc: 1.0000 - val_loss: 4.2319e-04 - val_acc: 1.0000\n",
      "Epoch 1918/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6354e-07 - acc: 1.0000Epoch 01918: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4777e-07 - acc: 1.0000 - val_loss: 2.2859e-04 - val_acc: 1.0000\n",
      "Epoch 1919/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.8452e-05 - acc: 1.0000Epoch 01919: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 7.2915e-05 - acc: 1.0000 - val_loss: 2.4743e-04 - val_acc: 1.0000\n",
      "Epoch 1920/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5084e-06 - acc: 1.0000Epoch 01920: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4159e-06 - acc: 1.0000 - val_loss: 3.2745e-04 - val_acc: 1.0000\n",
      "Epoch 1921/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1056e-06 - acc: 1.0000Epoch 01921: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 6.6389e-06 - acc: 1.0000 - val_loss: 4.9333e-04 - val_acc: 1.0000\n",
      "Epoch 1922/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1617e-07 - acc: 1.0000Epoch 01922: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 3.2429e-07 - acc: 1.0000 - val_loss: 5.7072e-04 - val_acc: 1.0000\n",
      "Epoch 1923/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3731e-07 - acc: 1.0000Epoch 01923: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 3.2527e-07 - acc: 1.0000 - val_loss: 7.8740e-04 - val_acc: 1.0000\n",
      "Epoch 1924/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5334e-07 - acc: 1.0000Epoch 01924: val_loss did not improve\n",
      "792/792 [==============================] - 1s 979us/step - loss: 7.4984e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1925/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.9854e-07 - acc: 1.0000Epoch 01925: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 5.7286e-07 - acc: 1.0000 - val_loss: 5.7856e-04 - val_acc: 1.0000\n",
      "Epoch 1926/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8444e-06 - acc: 1.0000Epoch 01926: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 2.9713e-06 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 1927/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9486e-06 - acc: 1.0000Epoch 01927: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.8226e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1928/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.9310e-07 - acc: 1.0000Epoch 01928: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 3.7788e-07 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1929/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.5712e-06 - acc: 1.0000Epoch 01929: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.3980e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 1930/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.0230e-05 - acc: 1.0000Epoch 01930: val_loss did not improve\n",
      "792/792 [==============================] - 1s 985us/step - loss: 2.8113e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1931/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6763e-07 - acc: 1.0000Epoch 01931: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 4.4442e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1932/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.9369e-06 - acc: 1.0000Epoch 01932: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 1.8119e-06 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 1933/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5565e-07 - acc: 1.0000Epoch 01933: val_loss did not improve\n",
      "792/792 [==============================] - 1s 993us/step - loss: 4.0045e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1934/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2438e-07 - acc: 1.0000Epoch 01934: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.2756e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 1935/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6598e-04 - acc: 1.0000Epoch 01935: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 3.4012e-04 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9949\n",
      "Epoch 1936/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.2783e-07 - acc: 1.0000Epoch 01936: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 6.8555e-07 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9949\n",
      "Epoch 1937/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7762e-06 - acc: 1.0000Epoch 01937: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.7322e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1938/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.8516e-06 - acc: 1.0000Epoch 01938: val_loss did not improve\n",
      "792/792 [==============================] - 1s 989us/step - loss: 2.6620e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 1939/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.0968e-06 - acc: 1.0000Epoch 01939: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 1.0149e-05 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9949\n",
      "Epoch 1940/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1603e-06 - acc: 1.0000Epoch 01940: val_loss did not improve\n",
      "792/792 [==============================] - 1s 987us/step - loss: 2.0302e-06 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9949\n",
      "Epoch 1941/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.1722e-07 - acc: 1.0000Epoch 01941: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.0337e-07 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9949\n",
      "Epoch 1942/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4956e-04 - acc: 1.0000Epoch 01942: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3900e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9949\n",
      "Epoch 1943/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.2929e-07 - acc: 1.0000Epoch 01943: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.1639e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1944/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.6569e-06 - acc: 1.0000Epoch 01944: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.5488e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1945/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.1592e-07 - acc: 1.0000Epoch 01945: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 5.8095e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1946/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.1994e-06 - acc: 1.0000Epoch 01946: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.0525e-06 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9949\n",
      "Epoch 1947/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.6960e-07 - acc: 1.0000Epoch 01947: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 4.6421e-07 - acc: 1.0000 - val_loss: 9.6941e-04 - val_acc: 1.0000\n",
      "Epoch 1948/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.3108e-07 - acc: 1.0000Epoch 01948: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 9.2493e-07 - acc: 1.0000 - val_loss: 8.4317e-04 - val_acc: 1.0000\n",
      "Epoch 1949/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0423e-04 - acc: 1.0000Epoch 01949: val_loss did not improve\n",
      "792/792 [==============================] - 1s 986us/step - loss: 1.8980e-04 - acc: 1.0000 - val_loss: 5.4192e-04 - val_acc: 1.0000\n",
      "Epoch 1950/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.5792e-07 - acc: 1.0000Epoch 01950: val_loss did not improve\n",
      "792/792 [==============================] - 1s 977us/step - loss: 1.6150e-07 - acc: 1.0000 - val_loss: 6.2764e-04 - val_acc: 1.0000\n",
      "Epoch 1951/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.0673e-07 - acc: 1.0000Epoch 01951: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 5.0125e-07 - acc: 1.0000 - val_loss: 1.3241e-04 - val_acc: 1.0000\n",
      "Epoch 1952/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2964e-05 - acc: 1.0000Epoch 01952: val_loss did not improve\n",
      "792/792 [==============================] - 1s 984us/step - loss: 3.9942e-05 - acc: 1.0000 - val_loss: 1.5110e-04 - val_acc: 1.0000\n",
      "Epoch 1953/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.3136e-04 - acc: 1.0000Epoch 01953: val_loss did not improve\n",
      "792/792 [==============================] - 1s 975us/step - loss: 1.2232e-04 - acc: 1.0000 - val_loss: 2.7578e-04 - val_acc: 1.0000\n",
      "Epoch 1954/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.2184e-04 - acc: 1.0000Epoch 01954: val_loss did not improve\n",
      "792/792 [==============================] - 1s 974us/step - loss: 4.8495e-04 - acc: 1.0000 - val_loss: 1.9191e-04 - val_acc: 1.0000\n",
      "Epoch 1955/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.1337e-06 - acc: 1.0000Epoch 01955: val_loss did not improve\n",
      "792/792 [==============================] - 1s 973us/step - loss: 7.5138e-06 - acc: 1.0000 - val_loss: 4.8832e-04 - val_acc: 1.0000\n",
      "Epoch 1956/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7513e-06 - acc: 1.0000Epoch 01956: val_loss did not improve\n",
      "792/792 [==============================] - 1s 976us/step - loss: 3.7719e-06 - acc: 1.0000 - val_loss: 7.3132e-04 - val_acc: 1.0000\n",
      "Epoch 1957/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1002e-06 - acc: 1.0000Epoch 01957: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.1232e-06 - acc: 1.0000 - val_loss: 3.2883e-04 - val_acc: 1.0000\n",
      "Epoch 1958/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2045e-04 - acc: 1.0000Epoch 01958: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 1.1555e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 1959/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2041e-06 - acc: 1.0000Epoch 01959: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 1.1489e-06 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 1960/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.5609e-07 - acc: 1.0000Epoch 01960: val_loss did not improve\n",
      "792/792 [==============================] - 1s 969us/step - loss: 3.7231e-07 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 1961/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.4891e-07 - acc: 1.0000Epoch 01961: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 8.9024e-07 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 1962/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.6713e-07 - acc: 1.0000Epoch 01962: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 4.4260e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1963/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.6869e-05 - acc: 1.0000Epoch 01963: val_loss did not improve\n",
      "792/792 [==============================] - 1s 965us/step - loss: 3.4271e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9949\n",
      "Epoch 1964/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.6127e-05 - acc: 1.0000Epoch 01964: val_loss did not improve\n",
      "792/792 [==============================] - 1s 988us/step - loss: 6.1461e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 1965/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.9981e-07 - acc: 1.0000Epoch 01965: val_loss did not improve\n",
      "792/792 [==============================] - 1s 983us/step - loss: 2.9953e-07 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9949\n",
      "Epoch 1966/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3649e-07 - acc: 1.0000Epoch 01966: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 3.2256e-07 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1967/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3348e-07 - acc: 1.0000Epoch 01967: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.2561e-06 - acc: 1.0000 - val_loss: 2.2138e-04 - val_acc: 1.0000\n",
      "Epoch 1968/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3828e-04 - acc: 1.0000Epoch 01968: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.2144e-04 - acc: 1.0000 - val_loss: 3.6237e-04 - val_acc: 1.0000\n",
      "Epoch 1969/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.4166e-06 - acc: 1.0000Epoch 01969: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.3249e-06 - acc: 1.0000 - val_loss: 5.6065e-04 - val_acc: 1.0000\n",
      "Epoch 1970/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.6431e-06 - acc: 1.0000Epoch 01970: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 5.2530e-06 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9949\n",
      "Epoch 1971/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.4622e-07 - acc: 1.0000Epoch 01971: val_loss did not improve\n",
      "792/792 [==============================] - 1s 992us/step - loss: 7.0309e-07 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9949\n",
      "Epoch 1972/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.9880e-06 - acc: 1.0000Epoch 01972: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.5023e-06 - acc: 1.0000 - val_loss: 4.9152e-04 - val_acc: 1.0000\n",
      "Epoch 1973/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 9.7777e-07 - acc: 1.0000Epoch 01973: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.6457e-06 - acc: 1.0000 - val_loss: 3.8675e-04 - val_acc: 1.0000\n",
      "Epoch 1974/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 6.8399e-07 - acc: 1.0000Epoch 01974: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.4613e-06 - acc: 1.0000 - val_loss: 7.4062e-04 - val_acc: 1.0000\n",
      "Epoch 1975/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8726e-06 - acc: 1.0000Epoch 01975: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.5174e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 1976/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.1018e-06 - acc: 1.0000Epoch 01976: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 3.8896e-06 - acc: 1.0000 - val_loss: 6.8347e-04 - val_acc: 1.0000\n",
      "Epoch 1977/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.7521e-07 - acc: 1.0000Epoch 01977: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.5914e-07 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 1978/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.3000e-07 - acc: 1.0000Epoch 01978: val_loss did not improve\n",
      "792/792 [==============================] - 1s 999us/step - loss: 2.2939e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 1979/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7186e-06 - acc: 1.0000Epoch 01979: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.5147e-06 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1980/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5614e-05 - acc: 1.0000Epoch 01980: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.2109e-05 - acc: 1.0000 - val_loss: 3.1890e-04 - val_acc: 1.0000\n",
      "Epoch 1981/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.4717e-06 - acc: 1.0000Epoch 01981: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 6.9655e-06 - acc: 1.0000 - val_loss: 4.8176e-04 - val_acc: 1.0000\n",
      "Epoch 1982/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.4498e-07 - acc: 1.0000Epoch 01982: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 2.8681e-07 - acc: 1.0000 - val_loss: 3.6671e-04 - val_acc: 1.0000\n",
      "Epoch 1983/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.5551e-07 - acc: 1.0000Epoch 01983: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 5.4678e-07 - acc: 1.0000 - val_loss: 4.1814e-04 - val_acc: 1.0000\n",
      "Epoch 1984/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.4965e-07 - acc: 1.0000Epoch 01984: val_loss did not improve\n",
      "792/792 [==============================] - 1s 994us/step - loss: 4.3126e-07 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 1985/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.7075e-06 - acc: 1.0000Epoch 01985: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 1.6024e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 1986/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 2.0092e-07 - acc: 1.0000Epoch 01986: val_loss did not improve\n",
      "792/792 [==============================] - 1s 995us/step - loss: 1.9650e-07 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 1987/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.8480e-07 - acc: 1.0000Epoch 01987: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 5.1886e-07 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 1988/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 5.8570e-07 - acc: 1.0000Epoch 01988: val_loss did not improve\n",
      "792/792 [==============================] - 1s 981us/step - loss: 5.5799e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1989/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.2026e-06 - acc: 1.0000Epoch 01989: val_loss did not improve\n",
      "792/792 [==============================] - 1s 978us/step - loss: 3.9146e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 1990/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.8983e-06 - acc: 1.0000Epoch 01990: val_loss did not improve\n",
      "792/792 [==============================] - 1s 996us/step - loss: 1.7725e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1991/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.3609e-07 - acc: 1.0000Epoch 01991: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 3.4311e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 1992/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.3426e-07 - acc: 1.0000Epoch 01992: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.1439e-07 - acc: 1.0000 - val_loss: 4.4798e-04 - val_acc: 1.0000\n",
      "Epoch 1993/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.1870e-06 - acc: 1.0000Epoch 01993: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 1.1117e-06 - acc: 1.0000 - val_loss: 5.5283e-04 - val_acc: 1.0000\n",
      "Epoch 1994/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 8.8705e-06 - acc: 1.0000Epoch 01994: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.2534e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 1995/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 4.5353e-07 - acc: 1.0000Epoch 01995: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 4.3297e-07 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 1996/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.7861e-06 - acc: 1.0000Epoch 01996: val_loss did not improve\n",
      "792/792 [==============================] - 1s 1ms/step - loss: 8.9319e-06 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 1997/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 3.4351e-06 - acc: 1.0000Epoch 01997: val_loss did not improve\n",
      "792/792 [==============================] - 1s 991us/step - loss: 3.2062e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 1998/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.0754e-06 - acc: 1.0000Epoch 01998: val_loss did not improve\n",
      "792/792 [==============================] - 1s 998us/step - loss: 1.0323e-06 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 1999/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 1.2553e-05 - acc: 1.0000Epoch 01999: val_loss did not improve\n",
      "792/792 [==============================] - 1s 990us/step - loss: 1.1752e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 2000/2000\n",
      "736/792 [==========================>...] - ETA: 0s - loss: 7.9835e-06 - acc: 1.0000Epoch 02000: val_loss did not improve\n",
      "792/792 [==============================] - 1s 997us/step - loss: 7.4347e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff6cb721240>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "epochs = 2000\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit([train2_images,X_train2], pd.get_dummies(y_train2).values, \n",
    "          validation_data=([val_images,X_val], pd.get_dummies(y_val).values),\n",
    "          epochs=epochs, batch_size=32, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990/990 [==============================] - 0s 380us/step\n",
      "Accuracy Score on training data: 1.0\n",
      "990/990 [==============================] - 0s 378us/step\n",
      "Log Loss Score on training data: 7.2845228741e-06\n",
      "594/594 [==============================] - 0s 363us/step\n",
      "Log loss score on testing data: 0.05\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('weights.best2.hdf5')\n",
    "\n",
    "predictions= model.predict_classes([train_images,X_train])\n",
    "\n",
    "best_accuracy_score = accuracy_score(pd.get_dummies(y_train).columns[predictions],y_train)\n",
    "\n",
    "print(\"Accuracy Score on training data:\", best_accuracy_score)\n",
    "\n",
    "predictions= model.predict_proba([train_images,X_train])\n",
    "\n",
    "best_log_loss_train_score= log_loss(pd.get_dummies(y_train).values,predictions)\n",
    "\n",
    "print(\"Log Loss Score on training data:\", best_log_loss_train_score)\n",
    "\n",
    "predictions= model.predict_proba([test_images,X_test])\n",
    "#predictions.shape\n",
    "\n",
    "#model.\n",
    "submission = pd.DataFrame(predictions,index=X_test.index,columns=pd.get_dummies(y_val).columns)\n",
    "\n",
    "submission.to_csv(r'submission_CNN2.csv')\n",
    "#.619 300 epochs\n",
    "#.219 1000 epochs\n",
    "#.183 2000 epochs\n",
    "\n",
    "# 1600 epochs with scaling\n",
    "# loading best model\n",
    "\n",
    "\n",
    "log_loss_CNN2 = .05\n",
    "print(\"Log loss score on testing data:\", log_loss_CNN2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 435us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6c5565c50>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions= model.predict_classes([val_images,X_val])\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(1-val_images[i,:,:,0],cmap='Greys')\n",
    "    plt.title(\"P: \"+pd.get_dummies(y_val).columns[predictions][i]+\" R: \"+y_val.iloc[i])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
